{
  "hash": "2e25302bef361114a48c01c467780cf9",
  "result": {
    "engine": "knitr",
    "markdown": "---\ntitle: Setup instructions \nauthor: \"Murray Logan\"\ndate: \"19 July, 2024\"\nformat: \n  html:\n    toc: true\n    toc-float: true\n    page-layout: full\n    number-sections: true\n    number-depth: 3\n    embed-resources: true\n    code-fold: false\n    code-tools: true\n    code-summary: \"Show the code\"\n    code-line-numbers: true\n    code-block-border-left: \"#ccc\"\n    code-copy: true\n    highlight-style: atom-one\n    theme: [default, ../resources/tut-style.scss]\n    css: ../resources/tut-style.css\ncrossref:\n  fig-title: '**Figure**'\n  fig-labels: arabic\n  tbl-title: '**Table**'\n  tbl-labels: arabic\nengine: knitr\nbibliography: ../resources/references.bib\noutput_dir: \"docs\"\n---\n\n\n\n\n# Installing R\n\nThe latest version of an R installation binary (or source code) can be\ndownloaded from one of the [Comprehensive R Archive Network (or CRAN)\nmirrors](https://cran.r-project.org/mirrors.html). Having selected one\nof the (Australian) mirrors, follow one of the sets of instructions\nbelow (depending on your operating system).\n\n::: panel-tabset \n\n## Windows\n\n- **Download R:** \n  - Go to the CRAN R-project website <https://cran.r-project.org/> and\n  click on \"Download R for Windows\".\n  - Select the \"base\" subdirectory\n  - Select the \"Download R-X.X.X for Windows\" option (where X.X.X are\n  a series of version and release numbers) to download.\n\n- **Run the installer:** Double-click the downloaded .exe file and\n  follow the installation wizard. Accept the default settings unless\n  you have specific needs.\n\n- **Optional:** Set R as the default: Check the checkbox to set R as\n  the default for R scripts during installation. This allows you to\n  run R scripts by double-clicking them.\n\n- **Verify installation:** \n  - Open a new command prompt (Start > Run > cmd) and type `R`. If the R\n  console opens, the installation was successful.\n  - Alternatively, search for R in the Start menu\n\n## MacOSx\n\n- **Download R:** \n  - Go to the CRAN R-project website (https://cran.r-project.org/) and\n    click on \"Download R for macOS\".\n  - Choose the latest stable version that is appropriate for your\n    architecture.\n- **Open the disk image:** Double-click the downloaded .pkg file and\n  drag the R application icon to your Applications folder.\n  \n- **Verify installation:**\n  - Open Terminal: Go to Applications > Utilities and open Terminal.\n  - Type `R` in the Terminal window. If the R console opens, the\n  installation was successful.\n\n## Linux\n\n- **Open Terminal:** You can access Terminal through your application\n  launcher or search bar.\n\n- **Install R:** The commands vary slightly depending on your Linux distribution. Here are common examples:\n  - Debian/Ubuntu: `sudo apt install r-base`\n  - Fedora/CentOS: `sudo yum install R`\n  - Arch Linux: `sudo pacman -S R`\n\n- **Verify installation:** Type `R` in the Terminal window. If the R\n  console opens, the installation was successful.\n\n:::\n\n# Installing Rstudio\n\n:::: panel-tabset\n\n#### Installing RStudio on Windows:\n\n1. **Download R:** \n    - RStudio requires R to be installed. If you have not already done\n      so, download and install R from the official CRAN website.\n\n2. **Download RStudio:** \n    - Visit the [RStudio Download\n    page](https://www.rstudio.com/products/rstudio/download/) and\n    select the \"RStudio Desktop\" version compatible with your Windows\n    operating system.\n\n3. **Install RStudio:** \n    - Run the downloaded RStudio installer and follow the installation\n      wizard. \n    - Accept the default settings unless you have specific\n      preferences. \n\n4. **Launch RStudio:**\n    - After installation, launch RStudio from the Start menu or\n      desktop shortcut.\n\n#### Installing RStudio on macOS:\n\n1. **Download R:**\n    - If you have not already done so, download and install R on macOS\n      from the official CRAN website.\n\n2. **Download RStudio:**\n    - Navigate to the [RStudio Download\n      page](https://www.rstudio.com/products/rstudio/download/) and\n      choose the \"RStudio Desktop\" version for macOS.\n\n3. **Install RStudio:**\n    - Run the downloaded RStudio package, and macOS will guide you\n      through the installation process.\n\n4. **Launch RStudio:**\n    - Open RStudio from the Applications folder or use Spotlight to\n      search for it.\n      \n#### Installing RStudio on Linux:\n\n1. **Download R:**\n    - If you have not already done so, install R on your Linux\n      distribution using the package manager. For example, on Ubuntu,\n      run:\n\n\n\n::: {.cell .bash}\n\n```{.bash .cell-code}\nsudo apt-get install r-base\n```\n:::\n\n\n\n2. **Download RStudio:**\n    - Visit the RStudio Download page and choose the appropriate\n      RStudio Desktop version for your Linux distribution.\n\n3. **Install RStudio:**\n    - Run the downloaded RStudio package, and follow any additional instructions based on your Linux distribution.\n\n4. **Launch RStudio:**\n    - Open a terminal and type rstudio to launch RStudio.\n\n::::\n\n\n# Installating git\n\n::: panel-tabset \n\n## Windows\n\nGit Bash (Command Line Version):\n\n1. Download the Git for Windows installer from [Git for Windows](https://gitforwindows.org/)\n   - Click the Download button\n   - Select the latest version from the list of `Assets`\n2. Run the installer and follow the installation prompts.\n3. Choose the default options unless you have specific preferences.\n4. Select the default text editor (usually Vim) or choose another\n   editor like Nano or Notepad++.\n5. Choose to use Git from the Windows Command Prompt (recommended).\n6. Complete the installation.\n\n## MacOSx\n\nUsing Homebrew:\n\n1. Open Terminal.\n2. Install Homebrew if not installed:\n\n:::: {.indented}\n\n\n::: {.cell .bash}\n\n```{.bash .cell-code}\n/bin/bash -c \"$(curl -fsSL https://raw.githubusercontent.com/Homebrew/install/HEAD/install.sh)\"\n```\n:::\n\n\n:::\n\n3. Install Git using Homebrew:\n\n:::: {.indented}\n\n\n\n::: {.cell .bash}\n\n```{.bash .cell-code}\nbrew install git\n```\n:::\n\n\n::::\n\n## Linux\n\n1. Open Terminal.\n\n:::: {.indented}\nUbuntu/Debian:\n\n\n\n::: {.cell .bash}\n\n```{.bash .cell-code}\nsudo apt update\nsudo apt install git\n```\n:::\n\n\n::::\n\n:::: {.indented}\nFedora:\n\n\n\n::: {.cell .bash}\n\n```{.bash .cell-code}\nsudo dnf install git\n```\n:::\n\n\n::::\n\n:::: {.indented}\nArch Linux:\n\n\n\n::: {.cell .bash}\n\n```{.bash .cell-code}\nsudo pacman -S git\n```\n:::\n\n\n::::\n\n:::: {.indented}\nLinux (Red Hat/CentOS):\n\n\n\n::: {.cell .bash}\n\n```{.bash .cell-code}\nsudo yum install git\n```\n:::\n\n\n::::\n:::\n\n\nTo verify that the software is installed and accessible, open a\nterminal and issue the following:\n\n\n\n::: {.cell .bash}\n\n```{.bash .cell-code}\ngit --version\n```\n\n\n::: {.cell-output .cell-output-stdout}\n\n```\ngit version 2.45.2\n```\n\n\n:::\n:::\n\n\n\n::: {.callout-tip collapse=\"true\"}\n## Unsure how to open a terminal?\n\n**Windows:**\n\nOn Windows, you can access a terminal via one of the following: \n\n- via the command Prompt:\n  - Press `Win + R` to open the Run dialog.\n  - Type `cmd` and press `Enter`.\n\n- via PowerShell:\n  - Press `Win + X` and select \"Windows PowerShell.\"\n\n- Git Bash (Optional):\n  - if Git is installed (which we are hoping it is!), open \"Git Bash\" for a Unix-like terminal experience.\n\n**MacOS:**\n\n- via Terminal:\n  - Press `Cmd + Space` to open Spotlight.\n  - Type `terminal` and press `Enter`.\n\n**Linux:**\n\nOh please. You cannot seriously tell me that you are using Linux and\ndon't know how to access a terminal.\n:::\n\nIn the command above, pay particular attention to the number of\nhyphens in the above command - there are two in a row and no spaces\nbetween the `--` and the word `version`.\n\nIf you get output similar to above (an indication of what version of\ngit you have on your system), then it is likely to be properly\ninstalled. If instead you get an error message, then it is likely that\ngit is not properly installed and you should try again.\n\n\n# Setup a free github account\n\nTo create a **free** github account:\n\n1. visit <https://github.com> and click \"Sign up for github\"\n2. register by providing your prefered email address, a username and\n   a password when prompted\n3. to complete the account activation, you will need to verify your \n   details via an email sent to your nominated email address\n\nAs of the start of 2024, github now requires Two-Factor Authentication\n(2FA) for enhanced security.  Whenever you login to github (or are\nprompted for a password, you will also need to use 2FA. To setup 2FA:\n\n1. click on your profile picture in the top right corner.\n2. select \"Settings\" from the dropdown menu.\n3. select \"Password and authentication\" in the left sidebar.\n4. under \"Two-factor authentication\" section, click \"Enable\".\n5. choose your preferred method (authenticator app or SMS) and follow \n   the prompts to set it up.\n\nPasswords and Two-Factor Authentication (2FA) are used when you (as a\nhuman) securely login and interact directly with the GitHub website.\nHowever, it is also possible to have other tools (such as `git`)\ninteract with Github on your behalf via an Application Programming\nInterfacet (API).  Passwords/2FA are not appropriate to authenticate \nthese machine to machine communications.  Instead, Github requires the\nuse of a Personal Access Token (PAT). PATs offer a more secure and granular \napproach, allowing users to control access without exposing their\naccount password.\n\nTo generate a Personal Access Token (PAT):\n\n1. click on your profile picture in the top right corner.\n2. select \"Settings\" from the dropdown menu.\n3. select \"Developer settings\" from the bottom of the left sidebar.\n4. select \"Personal access tokens\" from the left sidebar.\n5. select \"Tokens (classic)\" from the dropdown menu\n6. click \"Generate new token\"\n7. select \"Generate new token (classic)\" from the dropdown menu\n8. at this point you will likely be prompted for your password\n9. provide a \"note\" - this is more of a short description of what the\n   token is to be used for (in the example below, I have entered \"git push/pull\"\n   to remind me that this is a simple token for regular push/pull interaction\n   between my local and remote repositories).\n\n    ![](../resources/rstudio_githubtoken1.png)\n\n   You also need to provide an expiration. Although not secure or recommended,\n   I have selected \"No expiration\" as I don't want to have to re-do my PAT\n   across multiple machines too regularly.\n\n   Finally, you also need to indicate **scope** (what activities you are granting permission\n   for the tools to be able to perform).  In this case, I have ticked the \n   \"repo\" box.  This grants general rea/write access to my repositories.  I have \n   not granted permission for more administration like activities such as \n   managing teams, deleting repositories, etc - these activities I am happy to \n   perform myself via the website.\n10. click \"Generate token\" and securely copy the generated token.  Until this is stored\n    safely (see below) do not close the page, because Github will never show you this\n    PAT again.\n\n:::: {.indented}\n::: {.callout-important collapse=\"false\"}\n\nImportant: Store your PAT safely as you won't be able to see it again!\nIdeally, you should store this PAT in a digital wallet. Digital\nwallets vary according to operating systems. R users might like to use\nthe `r` function from the `asdf` package (which you will need to\ninstall prior) as follows in order to store the PAT.\n\n**In an R console, enter:**\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\ngitcreds::gitcreds_set()\n```\n:::\n\n\n\nWhen propted for a password, paste in the copied PAT that hopefully is still in your\nclipboard - else you might need to re-copy it.\n\nTo confirm that you have successfully stored your PAT in your wallet, you can:\n\n\n::: {.cell}\n\n```{.r .cell-code}\ngitcreds::gitcreds_get()\n```\n:::\n\n\n\nand confirm that it indicates that there is a hidden password.\n\n\n:::\n::::\n\n\n# Installing stan (for Bayesian modelling)\n\n::: panel-tabset \n\n## Windows\n\n1. Install and setup **Rtools** (a collection of R focused build tools\n   for windows)\n   - go to CRAN Rtools website\n     <https://cran.r-project.org/bin/windows/Rtools/>\n   - click on the Rtools version that matches the major version of R\n     you are using.\n   - click on the installer link (midway down the page) to download the installer\n   - run the installer\n   - follow all defaults during the installation process\n2. Install **cmdstan** (an implementation of the STAN language)\n   - using selected instructions from <https://mc-stan.org/cmdstanr/articles/cmdstanr.html>\n     - open a new R session and issue the following\n\n\n       ::: {.cell}\n       \n       ```{.r .cell-code}\n       install.packages(\"cmdstanr\", repos = c(\"https://mc-stan.org/r-packages/\", getOption(\"repos\")))\n       ```\n       :::\n\n\n     - make sure the package loads\n\n\n       ::: {.cell}\n       \n       ```{.r .cell-code}\n       library(cmdstanr)\n       ```\n       \n       ::: {.cell-output .cell-output-stderr}\n       \n       ```\n       This is cmdstanr version 0.8.1.9000\n       ```\n       \n       \n       :::\n       \n       ::: {.cell-output .cell-output-stderr}\n       \n       ```\n       - CmdStanR documentation and vignettes: mc-stan.org/cmdstanr\n       ```\n       \n       \n       :::\n       \n       ::: {.cell-output .cell-output-stderr}\n       \n       ```\n       - CmdStan path: /home/runner/.cmdstan/cmdstan-2.35.0\n       ```\n       \n       \n       :::\n       \n       ::: {.cell-output .cell-output-stderr}\n       \n       ```\n       - CmdStan version: 2.35.0\n       ```\n       \n       \n       :::\n       :::\n\n\n     - ensure that the c++ toolchain (from Rtools) is correctly\n       installed and configured\n\n\n       ::: {.cell}\n       \n       ```{.r .cell-code}\n       check_cmdstan_toolchain()\n       ```\n       :::\n\n\n     - if the toolchain is correctly configured, install cmdstan\n\n\n       ::: {.cell}\n       \n       ```{.r .cell-code}\n       install_cmdstan(cores = 2)\n       ```\n       :::\n\n\n3. Ensure that cmdstan is properly configured by compiling a built in example\n\n\n   ::: {.cell}\n   \n   ```{.r .cell-code}\n   file <- file.path(cmdstan_path(), \"examples\", \"bernoulli\", \"bernoulli.stan\")\n   mod <- cmdstan_model(file)\n   data_list <- list(N = 10, y = c(0,1,0,0,0,0,0,0,0,1))\n   \n   fit <- mod$sample(\n     data = data_list,\n     seed = 123,\n     chains = 4,\n     parallel_chains = 4,\n     refresh = 500 # print update every 500 iters\n   )\n   ```\n   \n   ::: {.cell-output .cell-output-stdout}\n   \n   ```\n   Running MCMC with 4 parallel chains...\n   \n   Chain 1 Iteration:    1 / 2000 [  0%]  (Warmup) \n   Chain 1 Iteration:  500 / 2000 [ 25%]  (Warmup) \n   Chain 1 Iteration: 1000 / 2000 [ 50%]  (Warmup) \n   Chain 1 Iteration: 1001 / 2000 [ 50%]  (Sampling) \n   Chain 1 Iteration: 1500 / 2000 [ 75%]  (Sampling) \n   Chain 1 Iteration: 2000 / 2000 [100%]  (Sampling) \n   Chain 2 Iteration:    1 / 2000 [  0%]  (Warmup) \n   Chain 2 Iteration:  500 / 2000 [ 25%]  (Warmup) \n   Chain 2 Iteration: 1000 / 2000 [ 50%]  (Warmup) \n   Chain 2 Iteration: 1001 / 2000 [ 50%]  (Sampling) \n   Chain 2 Iteration: 1500 / 2000 [ 75%]  (Sampling) \n   Chain 2 Iteration: 2000 / 2000 [100%]  (Sampling) \n   Chain 3 Iteration:    1 / 2000 [  0%]  (Warmup) \n   Chain 3 Iteration:  500 / 2000 [ 25%]  (Warmup) \n   Chain 3 Iteration: 1000 / 2000 [ 50%]  (Warmup) \n   Chain 3 Iteration: 1001 / 2000 [ 50%]  (Sampling) \n   Chain 3 Iteration: 1500 / 2000 [ 75%]  (Sampling) \n   Chain 3 Iteration: 2000 / 2000 [100%]  (Sampling) \n   Chain 4 Iteration:    1 / 2000 [  0%]  (Warmup) \n   Chain 4 Iteration:  500 / 2000 [ 25%]  (Warmup) \n   Chain 4 Iteration: 1000 / 2000 [ 50%]  (Warmup) \n   Chain 4 Iteration: 1001 / 2000 [ 50%]  (Sampling) \n   Chain 4 Iteration: 1500 / 2000 [ 75%]  (Sampling) \n   Chain 4 Iteration: 2000 / 2000 [100%]  (Sampling) \n   Chain 1 finished in 0.0 seconds.\n   Chain 2 finished in 0.0 seconds.\n   Chain 3 finished in 0.0 seconds.\n   Chain 4 finished in 0.0 seconds.\n   \n   All 4 chains finished successfully.\n   Mean chain execution time: 0.0 seconds.\n   Total execution time: 0.3 seconds.\n   ```\n   \n   \n   :::\n   :::\n\n\n   If you get output resembling the above, then cmdstan is setup correctly.\n4. Install the **brms** - an R package that provides a more familiar R\n   model fitting interface to `STAN`.\n   - install the package\n\n\n     ::: {.cell}\n     \n     ```{.r .cell-code}\n     install.packages(\"brms\")\n     ```\n     :::\n\n\n     <!--\n\n\n     ::: {.cell}\n     \n     :::\n\n\n     -->\n     \n   - test whether the whole tool chain works\n\n\n     ::: {.cell}\n     \n     ```{.r .cell-code}\n     library(cmdstanr)\n     library(brms)\n     dat <- data.frame(y = rnorm(10), x = rnorm(10))\n     brm(y ~ x, data = dat, backend = \"cmdstanr\")\n     ```\n     :::\n\n     ::: {.cell}\n     ::: {.cell-output .cell-output-stderr}\n     \n     ```\n     Loading required package: StanHeaders\n     ```\n     \n     \n     :::\n     \n     ::: {.cell-output .cell-output-stderr}\n     \n     ```\n     \n     rstan version 2.32.2 (Stan version 2.32.2)\n     ```\n     \n     \n     :::\n     \n     ::: {.cell-output .cell-output-stderr}\n     \n     ```\n     For execution on a local, multicore CPU with excess RAM we recommend calling\n     options(mc.cores = parallel::detectCores()).\n     To avoid recompilation of unchanged Stan programs, we recommend calling\n     rstan_options(auto_write = TRUE)\n     For within-chain threading using `reduce_sum()` or `map_rect()` Stan functions,\n     change `threads_per_chain` option:\n     rstan_options(threads_per_chain = 1)\n     ```\n     \n     \n     :::\n     \n     ::: {.cell-output .cell-output-stderr}\n     \n     ```\n     Loading required package: Rcpp\n     ```\n     \n     \n     :::\n     \n     ::: {.cell-output .cell-output-stderr}\n     \n     ```\n     Loading 'brms' package (version 2.21.0). Useful instructions\n     can be found by typing help('brms'). A more detailed introduction\n     to the package is available through vignette('brms_overview').\n     ```\n     \n     \n     :::\n     \n     ::: {.cell-output .cell-output-stderr}\n     \n     ```\n     \n     Attaching package: 'brms'\n     ```\n     \n     \n     :::\n     \n     ::: {.cell-output .cell-output-stderr}\n     \n     ```\n     The following object is masked from 'package:rstan':\n     \n         loo\n     ```\n     \n     \n     :::\n     \n     ::: {.cell-output .cell-output-stderr}\n     \n     ```\n     The following object is masked from 'package:stats':\n     \n         ar\n     ```\n     \n     \n     :::\n     \n     ::: {.cell-output .cell-output-stderr}\n     \n     ```\n     Compiling Stan program...\n     ```\n     \n     \n     :::\n     \n     ::: {.cell-output .cell-output-stderr}\n     \n     ```\n     Start sampling\n     ```\n     \n     \n     :::\n     \n     ::: {.cell-output .cell-output-stdout}\n     \n     ```\n     \n     SAMPLING FOR MODEL 'anon_model' NOW (CHAIN 1).\n     Chain 1: \n     Chain 1: Gradient evaluation took 1.3e-05 seconds\n     Chain 1: 1000 transitions using 10 leapfrog steps per transition would take 0.13 seconds.\n     Chain 1: Adjust your expectations accordingly!\n     Chain 1: \n     Chain 1: \n     Chain 1: Iteration:    1 / 2000 [  0%]  (Warmup)\n     Chain 1: Iteration:  200 / 2000 [ 10%]  (Warmup)\n     Chain 1: Iteration:  400 / 2000 [ 20%]  (Warmup)\n     Chain 1: Iteration:  600 / 2000 [ 30%]  (Warmup)\n     Chain 1: Iteration:  800 / 2000 [ 40%]  (Warmup)\n     Chain 1: Iteration: 1000 / 2000 [ 50%]  (Warmup)\n     Chain 1: Iteration: 1001 / 2000 [ 50%]  (Sampling)\n     Chain 1: Iteration: 1200 / 2000 [ 60%]  (Sampling)\n     Chain 1: Iteration: 1400 / 2000 [ 70%]  (Sampling)\n     Chain 1: Iteration: 1600 / 2000 [ 80%]  (Sampling)\n     Chain 1: Iteration: 1800 / 2000 [ 90%]  (Sampling)\n     Chain 1: Iteration: 2000 / 2000 [100%]  (Sampling)\n     Chain 1: \n     Chain 1:  Elapsed Time: 0.013 seconds (Warm-up)\n     Chain 1:                0.014 seconds (Sampling)\n     Chain 1:                0.027 seconds (Total)\n     Chain 1: \n     \n     SAMPLING FOR MODEL 'anon_model' NOW (CHAIN 2).\n     Chain 2: \n     Chain 2: Gradient evaluation took 3e-06 seconds\n     Chain 2: 1000 transitions using 10 leapfrog steps per transition would take 0.03 seconds.\n     Chain 2: Adjust your expectations accordingly!\n     Chain 2: \n     Chain 2: \n     Chain 2: Iteration:    1 / 2000 [  0%]  (Warmup)\n     Chain 2: Iteration:  200 / 2000 [ 10%]  (Warmup)\n     Chain 2: Iteration:  400 / 2000 [ 20%]  (Warmup)\n     Chain 2: Iteration:  600 / 2000 [ 30%]  (Warmup)\n     Chain 2: Iteration:  800 / 2000 [ 40%]  (Warmup)\n     Chain 2: Iteration: 1000 / 2000 [ 50%]  (Warmup)\n     Chain 2: Iteration: 1001 / 2000 [ 50%]  (Sampling)\n     Chain 2: Iteration: 1200 / 2000 [ 60%]  (Sampling)\n     Chain 2: Iteration: 1400 / 2000 [ 70%]  (Sampling)\n     Chain 2: Iteration: 1600 / 2000 [ 80%]  (Sampling)\n     Chain 2: Iteration: 1800 / 2000 [ 90%]  (Sampling)\n     Chain 2: Iteration: 2000 / 2000 [100%]  (Sampling)\n     Chain 2: \n     Chain 2:  Elapsed Time: 0.012 seconds (Warm-up)\n     Chain 2:                0.012 seconds (Sampling)\n     Chain 2:                0.024 seconds (Total)\n     Chain 2: \n     \n     SAMPLING FOR MODEL 'anon_model' NOW (CHAIN 3).\n     Chain 3: \n     Chain 3: Gradient evaluation took 3e-06 seconds\n     Chain 3: 1000 transitions using 10 leapfrog steps per transition would take 0.03 seconds.\n     Chain 3: Adjust your expectations accordingly!\n     Chain 3: \n     Chain 3: \n     Chain 3: Iteration:    1 / 2000 [  0%]  (Warmup)\n     Chain 3: Iteration:  200 / 2000 [ 10%]  (Warmup)\n     Chain 3: Iteration:  400 / 2000 [ 20%]  (Warmup)\n     Chain 3: Iteration:  600 / 2000 [ 30%]  (Warmup)\n     Chain 3: Iteration:  800 / 2000 [ 40%]  (Warmup)\n     Chain 3: Iteration: 1000 / 2000 [ 50%]  (Warmup)\n     Chain 3: Iteration: 1001 / 2000 [ 50%]  (Sampling)\n     Chain 3: Iteration: 1200 / 2000 [ 60%]  (Sampling)\n     Chain 3: Iteration: 1400 / 2000 [ 70%]  (Sampling)\n     Chain 3: Iteration: 1600 / 2000 [ 80%]  (Sampling)\n     Chain 3: Iteration: 1800 / 2000 [ 90%]  (Sampling)\n     Chain 3: Iteration: 2000 / 2000 [100%]  (Sampling)\n     Chain 3: \n     Chain 3:  Elapsed Time: 0.013 seconds (Warm-up)\n     Chain 3:                0.013 seconds (Sampling)\n     Chain 3:                0.026 seconds (Total)\n     Chain 3: \n     \n     SAMPLING FOR MODEL 'anon_model' NOW (CHAIN 4).\n     Chain 4: \n     Chain 4: Gradient evaluation took 3e-06 seconds\n     Chain 4: 1000 transitions using 10 leapfrog steps per transition would take 0.03 seconds.\n     Chain 4: Adjust your expectations accordingly!\n     Chain 4: \n     Chain 4: \n     Chain 4: Iteration:    1 / 2000 [  0%]  (Warmup)\n     Chain 4: Iteration:  200 / 2000 [ 10%]  (Warmup)\n     Chain 4: Iteration:  400 / 2000 [ 20%]  (Warmup)\n     Chain 4: Iteration:  600 / 2000 [ 30%]  (Warmup)\n     Chain 4: Iteration:  800 / 2000 [ 40%]  (Warmup)\n     Chain 4: Iteration: 1000 / 2000 [ 50%]  (Warmup)\n     Chain 4: Iteration: 1001 / 2000 [ 50%]  (Sampling)\n     Chain 4: Iteration: 1200 / 2000 [ 60%]  (Sampling)\n     Chain 4: Iteration: 1400 / 2000 [ 70%]  (Sampling)\n     Chain 4: Iteration: 1600 / 2000 [ 80%]  (Sampling)\n     Chain 4: Iteration: 1800 / 2000 [ 90%]  (Sampling)\n     Chain 4: Iteration: 2000 / 2000 [100%]  (Sampling)\n     Chain 4: \n     Chain 4:  Elapsed Time: 0.013 seconds (Warm-up)\n     Chain 4:                0.013 seconds (Sampling)\n     Chain 4:                0.026 seconds (Total)\n     Chain 4: \n     ```\n     \n     \n     :::\n     \n     ::: {.cell-output .cell-output-stdout}\n     \n     ```\n      Family: gaussian \n       Links: mu = identity; sigma = identity \n     Formula: y ~ x \n        Data: dat (Number of observations: 10) \n       Draws: 4 chains, each with iter = 2000; warmup = 1000; thin = 1;\n              total post-warmup draws = 4000\n     \n     Regression Coefficients:\n               Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS\n     Intercept    -0.11      0.39    -0.87     0.66 1.00     2598     1970\n     x             0.09      0.40    -0.73     0.88 1.00     2713     2358\n     \n     Further Distributional Parameters:\n           Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS\n     sigma     1.21      0.34     0.74     2.05 1.00     2467     2031\n     \n     Draws were sampled using sampling(NUTS). For each parameter, Bulk_ESS\n     and Tail_ESS are effective sample size measures, and Rhat is the potential\n     scale reduction factor on split chains (at convergence, Rhat = 1).\n     ```\n     \n     \n     :::\n     :::\n\n\n\n     Again, if you get output similar to that above, then the complete\n     Bayesian toolchain is correctly configured and ready for use.\n\n## MacOSx\n\n1. Install and setup **Xcode** (a collection of build tools for\n   MacOSX)\n   - open a terminal and enter\n\n\n   ::: {.cell .bash}\n   \n   ```{.bash .cell-code}\n   xcode-select --install\n   ```\n   :::\n\n\n\n2. Install **cmdstan** (an implementation of the STAN language)\n   - using selected instructions from <https://mc-stan.org/cmdstanr/articles/cmdstanr.html>\n     - open a new R session and issue the following\n\n\n       ::: {.cell}\n       \n       ```{.r .cell-code}\n       install.packages(\"cmdstanr\", repos = c(\"https://mc-stan.org/r-packages/\", getOption(\"repos\")))\n       ```\n       :::\n\n\n     - make sure the package loads\n\n\n       ::: {.cell}\n       \n       ```{.r .cell-code}\n       library(cmdstanr)\n       ```\n       :::\n\n\n     - ensure that the c++ toolchain (from Rtools) is correctly\n       installed and configured\n\n\n       ::: {.cell}\n       \n       ```{.r .cell-code}\n       check_cmdstan_toolchain()\n       ```\n       :::\n\n\n     - if the toolchain is correctly configured, install cmdstan\n\n\n       ::: {.cell}\n       \n       ```{.r .cell-code}\n       install_cmdstan(cores = 2)\n       ```\n       :::\n\n\n3. Ensure that cmdstan is properly configured by compiling a built in example\n\n\n   ::: {.cell}\n   \n   ```{.r .cell-code}\n   file <- file.path(cmdstan_path(), \"examples\", \"bernoulli\", \"bernoulli.stan\")\n   mod <- cmdstan_model(file)\n   data_list <- list(N = 10, y = c(0,1,0,0,0,0,0,0,0,1))\n   \n   fit <- mod$sample(\n     data = data_list,\n     seed = 123,\n     chains = 4,\n     parallel_chains = 4,\n     refresh = 500 # print update every 500 iters\n   )\n   ```\n   \n   ::: {.cell-output .cell-output-stdout}\n   \n   ```\n   Running MCMC with 4 parallel chains...\n   \n   Chain 1 Iteration:    1 / 2000 [  0%]  (Warmup) \n   Chain 1 Iteration:  500 / 2000 [ 25%]  (Warmup) \n   Chain 1 Iteration: 1000 / 2000 [ 50%]  (Warmup) \n   Chain 1 Iteration: 1001 / 2000 [ 50%]  (Sampling) \n   Chain 1 Iteration: 1500 / 2000 [ 75%]  (Sampling) \n   Chain 1 Iteration: 2000 / 2000 [100%]  (Sampling) \n   Chain 2 Iteration:    1 / 2000 [  0%]  (Warmup) \n   Chain 2 Iteration:  500 / 2000 [ 25%]  (Warmup) \n   Chain 2 Iteration: 1000 / 2000 [ 50%]  (Warmup) \n   Chain 2 Iteration: 1001 / 2000 [ 50%]  (Sampling) \n   Chain 2 Iteration: 1500 / 2000 [ 75%]  (Sampling) \n   Chain 2 Iteration: 2000 / 2000 [100%]  (Sampling) \n   Chain 3 Iteration:    1 / 2000 [  0%]  (Warmup) \n   Chain 3 Iteration:  500 / 2000 [ 25%]  (Warmup) \n   Chain 3 Iteration: 1000 / 2000 [ 50%]  (Warmup) \n   Chain 3 Iteration: 1001 / 2000 [ 50%]  (Sampling) \n   Chain 3 Iteration: 1500 / 2000 [ 75%]  (Sampling) \n   Chain 3 Iteration: 2000 / 2000 [100%]  (Sampling) \n   Chain 4 Iteration:    1 / 2000 [  0%]  (Warmup) \n   Chain 4 Iteration:  500 / 2000 [ 25%]  (Warmup) \n   Chain 4 Iteration: 1000 / 2000 [ 50%]  (Warmup) \n   Chain 4 Iteration: 1001 / 2000 [ 50%]  (Sampling) \n   Chain 4 Iteration: 1500 / 2000 [ 75%]  (Sampling) \n   Chain 4 Iteration: 2000 / 2000 [100%]  (Sampling) \n   Chain 1 finished in 0.0 seconds.\n   Chain 2 finished in 0.0 seconds.\n   Chain 3 finished in 0.0 seconds.\n   Chain 4 finished in 0.0 seconds.\n   \n   All 4 chains finished successfully.\n   Mean chain execution time: 0.0 seconds.\n   Total execution time: 0.3 seconds.\n   ```\n   \n   \n   :::\n   :::\n\n\n   If you get output resembling the above, then cmdstan is setup correctly.\n4. Install the **brms** - an R package that provides a more familiar R\n   model fitting interface to `STAN`.\n   - install the package\n\n\n     ::: {.cell}\n     \n     ```{.r .cell-code}\n     install.packages(\"brms\")\n     ```\n     :::\n\n\n   - test whether the whole tool chain works\n\n\n     ::: {.cell}\n     \n     ```{.r .cell-code}\n     library(rstan)\n     library(brms)\n     dat <- data.frame(y = rnorm(10), x = rnorm(10))\n     brm(y ~ x, data = dat, backend = \"rstan\")\n     ```\n     \n     ::: {.cell-output .cell-output-stderr}\n     \n     ```\n     Compiling Stan program...\n     ```\n     \n     \n     :::\n     \n     ::: {.cell-output .cell-output-stderr}\n     \n     ```\n     Start sampling\n     ```\n     \n     \n     :::\n     \n     ::: {.cell-output .cell-output-stdout}\n     \n     ```\n     \n     SAMPLING FOR MODEL 'anon_model' NOW (CHAIN 1).\n     Chain 1: \n     Chain 1: Gradient evaluation took 7e-06 seconds\n     Chain 1: 1000 transitions using 10 leapfrog steps per transition would take 0.07 seconds.\n     Chain 1: Adjust your expectations accordingly!\n     Chain 1: \n     Chain 1: \n     Chain 1: Iteration:    1 / 2000 [  0%]  (Warmup)\n     Chain 1: Iteration:  200 / 2000 [ 10%]  (Warmup)\n     Chain 1: Iteration:  400 / 2000 [ 20%]  (Warmup)\n     Chain 1: Iteration:  600 / 2000 [ 30%]  (Warmup)\n     Chain 1: Iteration:  800 / 2000 [ 40%]  (Warmup)\n     Chain 1: Iteration: 1000 / 2000 [ 50%]  (Warmup)\n     Chain 1: Iteration: 1001 / 2000 [ 50%]  (Sampling)\n     Chain 1: Iteration: 1200 / 2000 [ 60%]  (Sampling)\n     Chain 1: Iteration: 1400 / 2000 [ 70%]  (Sampling)\n     Chain 1: Iteration: 1600 / 2000 [ 80%]  (Sampling)\n     Chain 1: Iteration: 1800 / 2000 [ 90%]  (Sampling)\n     Chain 1: Iteration: 2000 / 2000 [100%]  (Sampling)\n     Chain 1: \n     Chain 1:  Elapsed Time: 0.013 seconds (Warm-up)\n     Chain 1:                0.018 seconds (Sampling)\n     Chain 1:                0.031 seconds (Total)\n     Chain 1: \n     \n     SAMPLING FOR MODEL 'anon_model' NOW (CHAIN 2).\n     Chain 2: \n     Chain 2: Gradient evaluation took 3e-06 seconds\n     Chain 2: 1000 transitions using 10 leapfrog steps per transition would take 0.03 seconds.\n     Chain 2: Adjust your expectations accordingly!\n     Chain 2: \n     Chain 2: \n     Chain 2: Iteration:    1 / 2000 [  0%]  (Warmup)\n     Chain 2: Iteration:  200 / 2000 [ 10%]  (Warmup)\n     Chain 2: Iteration:  400 / 2000 [ 20%]  (Warmup)\n     Chain 2: Iteration:  600 / 2000 [ 30%]  (Warmup)\n     Chain 2: Iteration:  800 / 2000 [ 40%]  (Warmup)\n     Chain 2: Iteration: 1000 / 2000 [ 50%]  (Warmup)\n     Chain 2: Iteration: 1001 / 2000 [ 50%]  (Sampling)\n     Chain 2: Iteration: 1200 / 2000 [ 60%]  (Sampling)\n     Chain 2: Iteration: 1400 / 2000 [ 70%]  (Sampling)\n     Chain 2: Iteration: 1600 / 2000 [ 80%]  (Sampling)\n     Chain 2: Iteration: 1800 / 2000 [ 90%]  (Sampling)\n     Chain 2: Iteration: 2000 / 2000 [100%]  (Sampling)\n     Chain 2: \n     Chain 2:  Elapsed Time: 0.012 seconds (Warm-up)\n     Chain 2:                0.012 seconds (Sampling)\n     Chain 2:                0.024 seconds (Total)\n     Chain 2: \n     \n     SAMPLING FOR MODEL 'anon_model' NOW (CHAIN 3).\n     Chain 3: \n     Chain 3: Gradient evaluation took 3e-06 seconds\n     Chain 3: 1000 transitions using 10 leapfrog steps per transition would take 0.03 seconds.\n     Chain 3: Adjust your expectations accordingly!\n     Chain 3: \n     Chain 3: \n     Chain 3: Iteration:    1 / 2000 [  0%]  (Warmup)\n     Chain 3: Iteration:  200 / 2000 [ 10%]  (Warmup)\n     Chain 3: Iteration:  400 / 2000 [ 20%]  (Warmup)\n     Chain 3: Iteration:  600 / 2000 [ 30%]  (Warmup)\n     Chain 3: Iteration:  800 / 2000 [ 40%]  (Warmup)\n     Chain 3: Iteration: 1000 / 2000 [ 50%]  (Warmup)\n     Chain 3: Iteration: 1001 / 2000 [ 50%]  (Sampling)\n     Chain 3: Iteration: 1200 / 2000 [ 60%]  (Sampling)\n     Chain 3: Iteration: 1400 / 2000 [ 70%]  (Sampling)\n     Chain 3: Iteration: 1600 / 2000 [ 80%]  (Sampling)\n     Chain 3: Iteration: 1800 / 2000 [ 90%]  (Sampling)\n     Chain 3: Iteration: 2000 / 2000 [100%]  (Sampling)\n     Chain 3: \n     Chain 3:  Elapsed Time: 0.013 seconds (Warm-up)\n     Chain 3:                0.013 seconds (Sampling)\n     Chain 3:                0.026 seconds (Total)\n     Chain 3: \n     \n     SAMPLING FOR MODEL 'anon_model' NOW (CHAIN 4).\n     Chain 4: \n     Chain 4: Gradient evaluation took 3e-06 seconds\n     Chain 4: 1000 transitions using 10 leapfrog steps per transition would take 0.03 seconds.\n     Chain 4: Adjust your expectations accordingly!\n     Chain 4: \n     Chain 4: \n     Chain 4: Iteration:    1 / 2000 [  0%]  (Warmup)\n     Chain 4: Iteration:  200 / 2000 [ 10%]  (Warmup)\n     Chain 4: Iteration:  400 / 2000 [ 20%]  (Warmup)\n     Chain 4: Iteration:  600 / 2000 [ 30%]  (Warmup)\n     Chain 4: Iteration:  800 / 2000 [ 40%]  (Warmup)\n     Chain 4: Iteration: 1000 / 2000 [ 50%]  (Warmup)\n     Chain 4: Iteration: 1001 / 2000 [ 50%]  (Sampling)\n     Chain 4: Iteration: 1200 / 2000 [ 60%]  (Sampling)\n     Chain 4: Iteration: 1400 / 2000 [ 70%]  (Sampling)\n     Chain 4: Iteration: 1600 / 2000 [ 80%]  (Sampling)\n     Chain 4: Iteration: 1800 / 2000 [ 90%]  (Sampling)\n     Chain 4: Iteration: 2000 / 2000 [100%]  (Sampling)\n     Chain 4: \n     Chain 4:  Elapsed Time: 0.013 seconds (Warm-up)\n     Chain 4:                0.013 seconds (Sampling)\n     Chain 4:                0.026 seconds (Total)\n     Chain 4: \n     ```\n     \n     \n     :::\n     \n     ::: {.cell-output .cell-output-stdout}\n     \n     ```\n      Family: gaussian \n       Links: mu = identity; sigma = identity \n     Formula: y ~ x \n        Data: dat (Number of observations: 10) \n       Draws: 4 chains, each with iter = 2000; warmup = 1000; thin = 1;\n              total post-warmup draws = 4000\n     \n     Regression Coefficients:\n               Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS\n     Intercept    -0.13      0.40    -0.92     0.66 1.00     2866     1798\n     x             0.08      0.42    -0.76     0.92 1.00     2682     2089\n     \n     Further Distributional Parameters:\n           Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS\n     sigma     1.23      0.36     0.74     2.12 1.00     2245     2181\n     \n     Draws were sampled using sampling(NUTS). For each parameter, Bulk_ESS\n     and Tail_ESS are effective sample size measures, and Rhat is the potential\n     scale reduction factor on split chains (at convergence, Rhat = 1).\n     ```\n     \n     \n     :::\n     :::\n\n\n\n     Again, if you get output similar to that above, then the complete\n     Bayesian toolchain is correctly configured and ready for use.\n     \n## Linux\n\n1. Ensure that you have installed (via your package manager) the\n   following dependencies:\n   - build-essential\n   - g++\n   - gcc\n   - curl\n   - libcurl4-openssl-dev\n\n2. Install **cmdstan** (an implementation of the STAN language)\n   - using selected instructions from <https://mc-stan.org/cmdstanr/articles/cmdstanr.html>\n     - open a new R session and issue the following\n\n\n       ::: {.cell}\n       \n       ```{.r .cell-code}\n       install.packages(\"cmdstanr\", repos = c(\"https://mc-stan.org/r-packages/\", getOption(\"repos\")))\n       ```\n       :::\n\n\n     - make sure the package loads\n\n\n       ::: {.cell}\n       \n       ```{.r .cell-code}\n       library(cmdstanr)\n       ```\n       :::\n\n\n     - ensure that the c++ toolchain (from Rtools) is correctly\n       installed and configured\n\n\n       ::: {.cell}\n       \n       ```{.r .cell-code}\n       check_cmdstan_toolchain()\n       ```\n       :::\n\n\n     - if the toolchain is correctly configured, install cmdstan\n\n\n       ::: {.cell}\n       \n       ```{.r .cell-code}\n       install_cmdstan(cores = 2)\n       ```\n       :::\n\n\n3. Ensure that cmdstan is properly configured by compiling a built in example\n\n\n   ::: {.cell}\n   \n   ```{.r .cell-code}\n   file <- file.path(cmdstan_path(), \"examples\", \"bernoulli\", \"bernoulli.stan\")\n   mod <- cmdstan_model(file)\n   data_list <- list(N = 10, y = c(0,1,0,0,0,0,0,0,0,1))\n   \n   fit <- mod$sample(\n     data = data_list,\n     seed = 123,\n     chains = 4,\n     parallel_chains = 4,\n     refresh = 500 # print update every 500 iters\n   )\n   ```\n   \n   ::: {.cell-output .cell-output-stdout}\n   \n   ```\n   Running MCMC with 4 parallel chains...\n   \n   Chain 1 Iteration:    1 / 2000 [  0%]  (Warmup) \n   Chain 1 Iteration:  500 / 2000 [ 25%]  (Warmup) \n   Chain 1 Iteration: 1000 / 2000 [ 50%]  (Warmup) \n   Chain 1 Iteration: 1001 / 2000 [ 50%]  (Sampling) \n   Chain 1 Iteration: 1500 / 2000 [ 75%]  (Sampling) \n   Chain 1 Iteration: 2000 / 2000 [100%]  (Sampling) \n   Chain 2 Iteration:    1 / 2000 [  0%]  (Warmup) \n   Chain 2 Iteration:  500 / 2000 [ 25%]  (Warmup) \n   Chain 2 Iteration: 1000 / 2000 [ 50%]  (Warmup) \n   Chain 2 Iteration: 1001 / 2000 [ 50%]  (Sampling) \n   Chain 2 Iteration: 1500 / 2000 [ 75%]  (Sampling) \n   Chain 2 Iteration: 2000 / 2000 [100%]  (Sampling) \n   Chain 3 Iteration:    1 / 2000 [  0%]  (Warmup) \n   Chain 3 Iteration:  500 / 2000 [ 25%]  (Warmup) \n   Chain 3 Iteration: 1000 / 2000 [ 50%]  (Warmup) \n   Chain 3 Iteration: 1001 / 2000 [ 50%]  (Sampling) \n   Chain 3 Iteration: 1500 / 2000 [ 75%]  (Sampling) \n   Chain 3 Iteration: 2000 / 2000 [100%]  (Sampling) \n   Chain 4 Iteration:    1 / 2000 [  0%]  (Warmup) \n   Chain 4 Iteration:  500 / 2000 [ 25%]  (Warmup) \n   Chain 4 Iteration: 1000 / 2000 [ 50%]  (Warmup) \n   Chain 4 Iteration: 1001 / 2000 [ 50%]  (Sampling) \n   Chain 4 Iteration: 1500 / 2000 [ 75%]  (Sampling) \n   Chain 4 Iteration: 2000 / 2000 [100%]  (Sampling) \n   Chain 1 finished in 0.0 seconds.\n   Chain 2 finished in 0.0 seconds.\n   Chain 3 finished in 0.0 seconds.\n   Chain 4 finished in 0.0 seconds.\n   \n   All 4 chains finished successfully.\n   Mean chain execution time: 0.0 seconds.\n   Total execution time: 0.3 seconds.\n   ```\n   \n   \n   :::\n   :::\n\n\n   If you get output resembling the above, then cmdstan is setup correctly.\n4. Install the **brms** - an R package that provides a more familiar R\n   model fitting interface to `STAN`.\n   - install the package\n\n\n     ::: {.cell}\n     \n     ```{.r .cell-code}\n     install.packages(\"brms\")\n     ```\n     :::\n\n\n   - test whether the whole tool chain works\n\n\n     ::: {.cell}\n     \n     ```{.r .cell-code}\n     library(rstan)\n     library(brms)\n     dat <- data.frame(y = rnorm(10), x = rnorm(10))\n     brm(y ~ x, data = dat, backend = \"rstan\")\n     ```\n     \n     ::: {.cell-output .cell-output-stderr}\n     \n     ```\n     Compiling Stan program...\n     ```\n     \n     \n     :::\n     \n     ::: {.cell-output .cell-output-stderr}\n     \n     ```\n     Start sampling\n     ```\n     \n     \n     :::\n     \n     ::: {.cell-output .cell-output-stdout}\n     \n     ```\n     \n     SAMPLING FOR MODEL 'anon_model' NOW (CHAIN 1).\n     Chain 1: \n     Chain 1: Gradient evaluation took 7e-06 seconds\n     Chain 1: 1000 transitions using 10 leapfrog steps per transition would take 0.07 seconds.\n     Chain 1: Adjust your expectations accordingly!\n     Chain 1: \n     Chain 1: \n     Chain 1: Iteration:    1 / 2000 [  0%]  (Warmup)\n     Chain 1: Iteration:  200 / 2000 [ 10%]  (Warmup)\n     Chain 1: Iteration:  400 / 2000 [ 20%]  (Warmup)\n     Chain 1: Iteration:  600 / 2000 [ 30%]  (Warmup)\n     Chain 1: Iteration:  800 / 2000 [ 40%]  (Warmup)\n     Chain 1: Iteration: 1000 / 2000 [ 50%]  (Warmup)\n     Chain 1: Iteration: 1001 / 2000 [ 50%]  (Sampling)\n     Chain 1: Iteration: 1200 / 2000 [ 60%]  (Sampling)\n     Chain 1: Iteration: 1400 / 2000 [ 70%]  (Sampling)\n     Chain 1: Iteration: 1600 / 2000 [ 80%]  (Sampling)\n     Chain 1: Iteration: 1800 / 2000 [ 90%]  (Sampling)\n     Chain 1: Iteration: 2000 / 2000 [100%]  (Sampling)\n     Chain 1: \n     Chain 1:  Elapsed Time: 0.013 seconds (Warm-up)\n     Chain 1:                0.018 seconds (Sampling)\n     Chain 1:                0.031 seconds (Total)\n     Chain 1: \n     \n     SAMPLING FOR MODEL 'anon_model' NOW (CHAIN 2).\n     Chain 2: \n     Chain 2: Gradient evaluation took 3e-06 seconds\n     Chain 2: 1000 transitions using 10 leapfrog steps per transition would take 0.03 seconds.\n     Chain 2: Adjust your expectations accordingly!\n     Chain 2: \n     Chain 2: \n     Chain 2: Iteration:    1 / 2000 [  0%]  (Warmup)\n     Chain 2: Iteration:  200 / 2000 [ 10%]  (Warmup)\n     Chain 2: Iteration:  400 / 2000 [ 20%]  (Warmup)\n     Chain 2: Iteration:  600 / 2000 [ 30%]  (Warmup)\n     Chain 2: Iteration:  800 / 2000 [ 40%]  (Warmup)\n     Chain 2: Iteration: 1000 / 2000 [ 50%]  (Warmup)\n     Chain 2: Iteration: 1001 / 2000 [ 50%]  (Sampling)\n     Chain 2: Iteration: 1200 / 2000 [ 60%]  (Sampling)\n     Chain 2: Iteration: 1400 / 2000 [ 70%]  (Sampling)\n     Chain 2: Iteration: 1600 / 2000 [ 80%]  (Sampling)\n     Chain 2: Iteration: 1800 / 2000 [ 90%]  (Sampling)\n     Chain 2: Iteration: 2000 / 2000 [100%]  (Sampling)\n     Chain 2: \n     Chain 2:  Elapsed Time: 0.012 seconds (Warm-up)\n     Chain 2:                0.012 seconds (Sampling)\n     Chain 2:                0.024 seconds (Total)\n     Chain 2: \n     \n     SAMPLING FOR MODEL 'anon_model' NOW (CHAIN 3).\n     Chain 3: \n     Chain 3: Gradient evaluation took 3e-06 seconds\n     Chain 3: 1000 transitions using 10 leapfrog steps per transition would take 0.03 seconds.\n     Chain 3: Adjust your expectations accordingly!\n     Chain 3: \n     Chain 3: \n     Chain 3: Iteration:    1 / 2000 [  0%]  (Warmup)\n     Chain 3: Iteration:  200 / 2000 [ 10%]  (Warmup)\n     Chain 3: Iteration:  400 / 2000 [ 20%]  (Warmup)\n     Chain 3: Iteration:  600 / 2000 [ 30%]  (Warmup)\n     Chain 3: Iteration:  800 / 2000 [ 40%]  (Warmup)\n     Chain 3: Iteration: 1000 / 2000 [ 50%]  (Warmup)\n     Chain 3: Iteration: 1001 / 2000 [ 50%]  (Sampling)\n     Chain 3: Iteration: 1200 / 2000 [ 60%]  (Sampling)\n     Chain 3: Iteration: 1400 / 2000 [ 70%]  (Sampling)\n     Chain 3: Iteration: 1600 / 2000 [ 80%]  (Sampling)\n     Chain 3: Iteration: 1800 / 2000 [ 90%]  (Sampling)\n     Chain 3: Iteration: 2000 / 2000 [100%]  (Sampling)\n     Chain 3: \n     Chain 3:  Elapsed Time: 0.013 seconds (Warm-up)\n     Chain 3:                0.013 seconds (Sampling)\n     Chain 3:                0.026 seconds (Total)\n     Chain 3: \n     \n     SAMPLING FOR MODEL 'anon_model' NOW (CHAIN 4).\n     Chain 4: \n     Chain 4: Gradient evaluation took 3e-06 seconds\n     Chain 4: 1000 transitions using 10 leapfrog steps per transition would take 0.03 seconds.\n     Chain 4: Adjust your expectations accordingly!\n     Chain 4: \n     Chain 4: \n     Chain 4: Iteration:    1 / 2000 [  0%]  (Warmup)\n     Chain 4: Iteration:  200 / 2000 [ 10%]  (Warmup)\n     Chain 4: Iteration:  400 / 2000 [ 20%]  (Warmup)\n     Chain 4: Iteration:  600 / 2000 [ 30%]  (Warmup)\n     Chain 4: Iteration:  800 / 2000 [ 40%]  (Warmup)\n     Chain 4: Iteration: 1000 / 2000 [ 50%]  (Warmup)\n     Chain 4: Iteration: 1001 / 2000 [ 50%]  (Sampling)\n     Chain 4: Iteration: 1200 / 2000 [ 60%]  (Sampling)\n     Chain 4: Iteration: 1400 / 2000 [ 70%]  (Sampling)\n     Chain 4: Iteration: 1600 / 2000 [ 80%]  (Sampling)\n     Chain 4: Iteration: 1800 / 2000 [ 90%]  (Sampling)\n     Chain 4: Iteration: 2000 / 2000 [100%]  (Sampling)\n     Chain 4: \n     Chain 4:  Elapsed Time: 0.013 seconds (Warm-up)\n     Chain 4:                0.013 seconds (Sampling)\n     Chain 4:                0.026 seconds (Total)\n     Chain 4: \n     ```\n     \n     \n     :::\n     \n     ::: {.cell-output .cell-output-stdout}\n     \n     ```\n      Family: gaussian \n       Links: mu = identity; sigma = identity \n     Formula: y ~ x \n        Data: dat (Number of observations: 10) \n       Draws: 4 chains, each with iter = 2000; warmup = 1000; thin = 1;\n              total post-warmup draws = 4000\n     \n     Regression Coefficients:\n               Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS\n     Intercept    -0.13      0.40    -0.92     0.66 1.00     2866     1798\n     x             0.08      0.42    -0.76     0.92 1.00     2682     2089\n     \n     Further Distributional Parameters:\n           Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS\n     sigma     1.23      0.36     0.74     2.12 1.00     2245     2181\n     \n     Draws were sampled using sampling(NUTS). For each parameter, Bulk_ESS\n     and Tail_ESS are effective sample size measures, and Rhat is the potential\n     scale reduction factor on split chains (at convergence, Rhat = 1).\n     ```\n     \n     \n     :::\n     :::\n\n\n\n     Again, if you get output similar to that above, then the complete\n     Bayesian toolchain is correctly configured and ready for use.\n:::\n\n\n\n",
    "supporting": [],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}