{
  "hash": "af35f1c47a158d7d1c0368cfebe6b30f",
  "result": {
    "engine": "knitr",
    "markdown": "---\ntitle: Generalised linear models\nauthor: \"Murray Logan\"\ndate: \"16 July, 2024\"\nformat: \n  html:\n    toc: true\n    toc-float: true\n    page-layout: full\n    number-sections: true\n    number-depth: 3\n    embed-resources: true\n    code-fold: false\n    code-tools: true\n    code-summary: \"Show the code\"\n    code-line-numbers: true\n    code-block-border-left: \"#ccc\"\n    code-copy: true\n    highlight-style: atom-one\n    theme: [default, ../resources/tut-style.scss]\n    css: ../resources/tut-style.css\ncrossref:\n  fig-title: '**Figure**'\n  fig-labels: arabic\n  tbl-title: '**Table**'\n  tbl-labels: arabic\nengine: knitr\nbibliography: ../resources/references.bib\noutput_dir: \"docs\"\n---\n\n\n\n\n\n# Preparations\n\nLoad the necessary libraries\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(tidyverse)   #for data wrangling and plotting\nlibrary(gganimate)   #for animations\nlibrary(gridExtra)   #for additional plotting routines\nlibrary(ggfortify)   #for regression diagnostics (autoplot)\nlibrary(DHARMa)      #for simulated residuals\nlibrary(performance) #for model diagnostics\nlibrary(see)         #for model diagnostics\nlibrary(glmmTMB)     #for GLM(M)'s\nlibrary(gmodels)     #for additional statistics\nlibrary(MASS)        #for neg binom glm\n```\n:::\n\n\n\n# Preamble\n\nStatistics is a branch of mathematics. Therefore it is inevitable that\nthis tutorial WILL visit numerous mathematical concepts and present\nmathematical numenclature. In an attempt to constain the dread felt by\nreaders who have long seen off the tortorous high school mathematics\nlessons, I will try to introduce these elements as gently as possible\nand will attempt to maintain a consistent use of symbology throughout.\nKeep in mind, that although it is possible to fit linear models\nwithout understanding the underlying mathematics, a more solid\ngrounding will help ensure that models are fit and interpreted\ncorrectly.\n\n# Statistical models\n\nBefore we get into the details of statistical models, it is important\nthat we establish the purpose of statistical models. Broadly speaking,\nthe purpose of statistical models is:\n\n- **estimate** (quantify) the effects (associations, relationships,\n  impacts) of various potential influences on a system. For example,\n  to quantify the magnitude of change in total fish biomass resulting\n  from a ban on fishing activity in an area. Another example might be\n  for estimating the rate at which clutch size increases for every\n  unit increase in body size in a species of bird.\n\n- testing **inferences** about specific apriori hypotheses. These a\n  probabilistic conclusions about the strength of evidence in support\n  of a hypothesis. For example, whether there is \"significant\"\n  evidence that fishing exclusion zones increases fish biomass\n\n- guide **decision making** and **prediction** about future outcomes\n  under different scenarios. For example, forcasting fish biomass\n  increases in an area slated to become a new fishing exclusion zone.\n\nIt should be noted that different statistical procedures differ in the\ndegree to which they support the above purposes and so it is important\nto match the statistical procedure to the research question and data\ncontext. For example, linear models (the subject of this tutorial) are\nintentionally low dimensional representations of a complex system. By\nlow dimensional I mean that a linear model should be restricted to\njust a small number of parameters (or dimensions, such as the effects\nof fishing exclusion) out of an almost infinite number of effects\n(dimensions) that could effect fish biomass. In so doing, the focus on\nestimating the effect of these potential influences over and above\n(that is marginalising) all other influences. Whilst such an approach\nis very effective for estimation, inference testing and predicting the\nrelative change in a response, the low dimensionality makes such an\napproach unsuitable for absolute prediction (of say the biomass of\nfish an a specific location at a specific point in time).\n\nOn the other hand, machine learning models trained on a very large set\nof cases and potential influences can often predict new cases with\nvery high accuracy (since they incorporate many dimensions), yet are\noften unable to attribute which exact influences drive the predictions\nand by how much. That is, these approaches are very good at\nprediction, but unsuitable for estimation and inference testing.\n\n\n# Overview of linear models\n\nCorrelation and regression are techniques used to examine associations\nand relationships between continuous variables collected on the same\nset of sampling or experimental units. Specifically, correlation is\nused to investigate the degree to which variables change or vary\ntogether (covary). In correlation, there is no distinction between\ndependent (response) and independent (predictor) variables and there\nis no attempt to prescribe or interpret the causality of the\nassociation.\n\nFor example, there may be an association between arm and leg length in\nhumans, whereby individuals with longer arms generally have longer\nlegs. Neither variable directly causes the change in the other.\nRather, they are both influenced by other variables to which they both\nhave similar responses. Hence correlations apply mainly to survey\ndesigns where each variable is measured rather than specifically set\nor manipulated by the investigator.\n\nRegression is used to investigate the nature of a relationship between\nvariables in which the magnitude and changes in one or more variables\n(known as the **independent**, **predictors** or **covariates**) are\nassumed to be directly responsible for the magnitude and changes in\nanother variable (**dependent** or **response** variable). Regression\nanalyses apply to both survey and experimental designs. Whilst for\nexperimental designs, the direction of causality is established and\ndictated by the experiment, for surveys the direction of causality is\nsomewhat discretionary and based on prior knowledge or intuition.\n\nFor example, although it is possible that ambient temperature effects\nthe growth rate of a species of plant, the reverse is not logical. As\nan example of regression, we could experimentally investigate the\nrelationship between algal cover on rocks and molluscan grazer density\nby directly manipulating the density of snails in different\nspecifically control plots and measuring the cover of algae therein.\nAny established relationship must be driven by snail density, as this\nwas the controlled variable. Alternatively the relationship could be\ninvestigated via a field survey in which the density of snails and\ncover of algae could be measured from random locations across a rock\nplatform. In this case, the direction of causality (or indeed the\nassumption of causality) may be more difficult to defend.\n\n<!--\nIn addition to examining the strength and significance of a\nrelationship (for which correlation and regression are equivalent),\nregression analysis also explores the functional nature of the\nrelationship. In particular, it estimates the rate at which a change\nin an independent variable is reflected in a change in a dependent\nvariable as well as the expected value of the dependent variable when\nthe independent variable is equal to zero. These estimates can be used\nto construct a predictive model (equation) that relates the magnitude\nof a dependent variable to the magnitude of an independent variable,\nand thus permit new responses to be predicted from new values of the\nindependent variable.  \n-->\n\n\nAs stated above, one of the main goals of fitting a statistical model\nis to use a sample of observed data to be able to gain some insights\ninto the presence or nature of relationships between a response and\npredictors in a defined population. This is achieved by first\nproposing one or more (deterministic) mathematical representations of\npossible relationships and then challenge the representation with\ndata.\n\nFor example, we might propose that an increase in a predictor ($x$) will be\nassociated with a linear increase in a response ($y$).\n\n:::: {.columns}\n\n::: {.column width=\"45%\"}\n\n\n\n::: {.cell}\n::: {.cell-output-display}\n![](30_glm_files/figure-html/mod1-1.png){width=288}\n:::\n:::\n\n\n\n:::\n\n::: {.column width=\"45%\"}\n\nThe general mathematical equation of the linear line is:\n\n$$\ny_i = \\beta_0 + \\beta x_i\n$$\n\nwhere:\n\n- $y_i$ represents a vector (think single variable) of response values\n  (the subset $i$ is a way to indicate that there are multiple values), \n- $x_i$ represents the value of the $ith$ observed predictor value.  \n- $\\beta_0$ represents a single y-intercept (expected value of $y$ when $x$=0),\n- $\\beta$ represents the __slope__ of the linear line (this is the rate of\n  change in $y$ associated with 1 unit change in $x$).\n\n\n:::\n::::\n\nThe above expression can be re-written as:\n$$\ny_i = \\beta_0\\times 1 + \\beta_1\\times x_i\n$$\n\nwhich we can visualize in vector/matrix form as:\n$$\n\\underbrace{\\begin{bmatrix}\ny_1\\\\\ny_2\\\\\ny_3\\\\\n...\\\\\ny_i\n\\end{bmatrix}}_{Y} = \n\\underbrace{\\begin{bmatrix}\n1&x_1\\\\\n1&x_2\\\\\n1&x_3\\\\\n...\\\\\n1&x_i\n\\end{bmatrix}}_{\\boldsymbol{X}}\n\\underbrace{\\vphantom{\\begin{bmatrix}\ny_1\\\\\ny_2\\\\\ny_3\\\\\n...\\\\\ny_i\n\\end{bmatrix}}\\begin{bmatrix}\n\\beta_0&\\beta\n\\end{bmatrix}}_{\\boldsymbol{\\beta}}\n$$\n\n\nSo given a sample of observed response ($y$) and predictor ($x$) values, we want\nto be able to estimate the two unknowns ($\\beta_0$ and $\\beta$) in the above\nmathematical expression.  If we assume that there is no uncertainty in the data,\nwe can easily calculate the necessary value of $\\beta_0$ and $\\beta$ using any\ntwo data pairs and solving simultaneous equations.\n\n\n::: {.callout-note collapse=\"true\"}\n### Simultaneous equations solution\n$$\n\\begin{align}\n7 =& \\beta_0 + \\beta 1~~and~~12 = \\beta_0 + \\beta 2\\\\\n\\beta_0 =& 7 - \\beta ~~(\\text{isolate }\\beta_0\\text{ from the first equation})\\\\\n\\beta =& 5 ~~(\\text{solve for }\\beta)\\\\\n\\beta_0 =& 2 ~~(\\text{substitute }\\beta\\text{ and solve for }\\beta_0)\\\\\n\\end{align}\n$$\n:::\n\nThe above model is a deterministic or mathematical model - it suggests\ncomplete confidence in the relationship. As already indicated, the\npoint of statistical modelling is to formulate the equation in the\npresence of a sample of data drawn from the actual population. The\nmodels themselves are always a low-dimensional representation of\nreality. They cannot hope to capture all the complexity contained in\nthe system and nor do they want to. They just want to provide insights\ninto a very small fraction of this complexity.\n\nSince a set of observed responses is likely to be the result of a\nlarge (if not infinite) number of interacting processes, the chances\nthat all observed responses will respond to the predictor in exactly\nthe same way is highly unlikely. Therefore, in all data there is\nnoise. In modelling, we want to see if there is any detectable signal\namongst all the noise.\n\nStatistical models include both a deterministic component (a\nmathematical expression that relates a response to one or more\npredictors) as well as a stochastic component (representing\nuncertaintly). For example, the following figures highlight the\ndistinction between a purely deterministic (mathematical) model (left\nhand figure) and a statistical model (right hand figure).\n\n\n\n::: {.cell}\n::: {.cell-output-display}\n![](30_glm_files/figure-html/compareModels,-1.png){width=576}\n:::\n:::\n\n\n\nThe statistical model captures the stochastic component\n($\\varepsilon$) which represents the degree to which each observed\nvalue differs from what would be expected in the absence of any noise\n(uncertainty). These differences between observed and expected values\nare called **residuals**.\n\n\n\n\n::: {.cell}\n::: {.cell-output-display}\n![](30_glm_files/figure-html/residuals,-1.png){width=288}\n:::\n:::\n\n\n\nSo one way to write out this linear model would be:\n\n$$\ny_i = \\beta_0 + \\beta_1 x_i + \\varepsilon_i\n$$\n\nAgain, in vector and matrix form, this would be:\n\n$$\n\\underbrace{\\begin{bmatrix}\ny_1\\\\\ny_2\\\\\ny_3\\\\\n...\\\\\ny_i\n\\end{bmatrix}}_{Y} = \n\\underbrace{\\begin{bmatrix}\n1&x_1\\\\\n1&x_2\\\\\n1&x_3\\\\\n...\\\\\n1&x_i\n\\end{bmatrix}}_{\\boldsymbol{X}}\n\\underbrace{\\vphantom{\\begin{bmatrix}\ny_1\\\\\ny_2\\\\\ny_3\\\\\n...\\\\\ny_i\n\\end{bmatrix}}\\begin{bmatrix}\n\\beta_0&\\beta\n\\end{bmatrix}}_{\\boldsymbol{\\beta}} + \n\\underbrace{\\begin{bmatrix}\n\\varepsilon_1\\\\\n\\varepsilon_2\\\\\n\\varepsilon_3\\\\\n...\\\\\n\\varepsilon_i\n\\end{bmatrix}}_{\\boldsymbol{\\varepsilon}}\n$$\n\n- $Y$ represents a column vector of the observed data\n- $\\boldsymbol{X}$ represents what is called the _model matrix_. In\n  this case, that is just a single column matrix of 1s. The ones\n  indicate that there is an intercept. In matrix algebra, matrices are\n  multiplied, so a column of ones just ensures that the thing being\n  multiplied does exist.\n- $\\boldsymbol{\\beta}$ represents a vector of parameters to be\n  estimated. In this case, there is only one.\n- $\\boldsymbol{\\varepsilon}$ represents a column vector or residuals.  \n\nThis could all be summarised as: \n\n$$ Y = \\boldsymbol{X}\\boldsymbol{\\beta} + \\boldsymbol{\\varepsilon} $$\n\nTo help with naming conventions, I will present the above matrix\nnotation again, yet with more general labels:\n\n$$\n\\underbrace{\\begin{pmatrix}\n  0\\\\1\\\\2\\\\4\\\\7\\\\10\n\\end{pmatrix}}_\\text{Response values} = \n\\underbrace{\\begin{pmatrix}\n\t1&1\\\\1&2\\\\1&3\\\\1&4\\\\1&5\\\\1&6\n\\end{pmatrix}}_\\text{Model matrix} \\times\n\\underbrace{\\begin{pmatrix}\n\t\\beta_0\\\\\\beta_1\n\\end{pmatrix}}_\\text{Parameter vector} + \n\\underbrace{\\begin{pmatrix}\n\t\\varepsilon_1\\\\\\varepsilon_2\\\\\\varepsilon_3\\\\\\varepsilon_4&\\\\\\varepsilon_5\\\\\\varepsilon_6\n\\end{pmatrix}}_\\text{Residual vector}\n$$\n\n\nThe **model matrix** (also known as the design matrix) contains the\n\"weights\" for each parameter for each of the sampling units. The above\nmatrix notation also isolates and thus highlights the \"unknown\"\nregression parameters ($\\beta_0$ and $\\beta_1$) from the observed data\nfrom which they are estimated.\n\n## Categorical predictors\n\nThe model structure for linear models containing a single categorical\npredictor variable (known as a <i>factor</i>) with two or more\ntreatment levels (groups) is similar in form to the multiple linear\nregression model (listed immediately above) with the overall mean\n($\\mu$) replacing the y-intercept ($\\beta_0$). The factor levels\n(groups) are represented in the model by binary (contain only of 0s\nand 1s, see Table below) <i>indicator</i> (or `dummy') variables and\ntheir associated estimable parameters ($\\beta_1,~\\beta_2,~...$). \n\nFor a data set comprising of $p$ groups and $n$ replicates within each\ngroup, the linear model is: $$y_{ij} = \\mu + \\beta_1(dummy_1)_{ij} +\n\\beta_2(dummy_2)_{ij} + .... + \\varepsilon_{ij}$$ where $j$ represents\nthe treatment levels (from 1 to $p$) and $i$ represents the set of\nreplicates (from 1 to $n$) within the $j^{th}$ group. Hence, $y_{ij}$\nrepresents the $i^{th}$ observation of the response variable within\nthe $j^{th}$ group and $(dummy_1)_{ij}$ represents the dummy code for\nthe $i^{th}$ replicate within the $j^{th}$ group of the first dummy\nvariable (first treatment level). \n\n::: {.columns}\n\n:::: {.column width=\"20%\"}\n\n**Raw data**\n\n| Y  | Group |\n|----|-------|\n| 2  | G1    |\n| 3  | G1    |\n| 4  | G1    |\n| 6  | G2    |\n| 7  | G2    |\n| 8  | G2    |\n| 10 | G3    |\n| 11 | G3    |\n| 12 | G3    |\n\n: {.sm .paperTable tbl-colwidths=\"[50,50]\"}\n\n::::\n\n:::: {.column width=\"60%\"}\n\n**Dummy coded data**\n\n| y  | $dummy_1$ | $dummy_2$ | $dummy_3$ |\n|----|-----------|-----------|-----------|\n| 2  | 1         | 0         | 0         |\n| 3  | 1         | 0         | 0         |\n| 4  | 1         | 0         | 0         |\n| 6  | 0         | 1         | 0         |\n| 7  | 0         | 1         | 0         |\n| 8  | 0         | 1         | 0         |\n| 10 | 0         | 0         | 1         |\n| 11 | 0         | 0         | 1         |\n| 12 | 0         | 0         | 1         |\n\n: {.sm .paperTable tbl-colwidths=\"[25,25, 25, 25]\"}\n\n::::\n\n:::\n\nThe dummy variable for a particular treatment level contains all 0s\nexcept in the rows that correspond to observations that received that\ntreatment level. The table above illustrates the dummy coding for a\nsingle factor with three levels (`G1', `G2', `G3') each with three\nreplicates. Note that a linear model of the form:\n\n$$y_{ij}=\\beta_0+\\beta_1(dummy_1)_{ij} + \\beta_2(dummy_2)_{ij}\n+\\beta_3(dummy_3)_{ij} + \\varepsilon_{ij}$$ \n\nis **over-parameterized** (as we are attempting to estimate four\nparameters from three populations, see [the tutorial on\nestimation](22_estimation.html).\n\nAn effects model for a factor with $p$ groups, will have $p+1$\nparameters (the overall mean $\\mu$ plus the $p$ $\\beta$ parameters),\nand thus the linear effects model is considered to be\n**over-parameterized**. Given that $\\beta_j=\\mu_j - \\mu$, it is only\npossible to estimate $p-1$ orthogonal (independent) parameters. For\nexample, once $\\mu$ and $p-1$ of the effects parameters have been\nestimated, the final effects parameter is no longer _free to vary_ and\ntherefore cannot be independently estimated. Likewise, if the full\nlinear model contains as many dummy variables as there are treatment\ngroups, then it too is over-parameterized.\n\nIn order to obtain parameter estimates, the model must be reduced to a\ntotal of $p$ parameters. Over-parameterization can be resolved by one\nof two alternative parameterizations:\n\n- **means parameterization** - removing one of the parameters from the\n  effects model (either the overall mean ($\\mu$) or one of the\n  treatment effects ($\\beta_j$) parameters - a procedure rarely used\n  in a frequentist framework in biology). When it is the overall mean\n  that is removed, then each of the regression parameters represent\n  the mean of a group.\n\n  $$y_{ij} = \\beta_j+\\varepsilon_{ij}, \\hspace{2cm}\\text{where}~j= 1:\\text{number of levels of the factor}$$\n  $$\\begin{pmatrix}\n    2\\\\3\\\\4\\\\6\\\\7\\\\8\\\\10\\\\11\\\\12\n  \\end{pmatrix} = \n  \\begin{pmatrix}\n\t1&0&0\\\\1&0&0\\\\1&0&0\\\\0&1&0\\\\0&1&0\\\\0&1&0\\\\0&0&1\\\\0&0&1\\\\0&0&1\n  \\end{pmatrix} \\times\n  \\begin{pmatrix}\n\t\\beta_1\\\\\\beta_2\\\\\\beta_3\n  \\end{pmatrix} + \n  \\begin{pmatrix}\t\\varepsilon_1\\\\\\varepsilon_2\\\\\\varepsilon_3\\\\\\varepsilon_4&\\\\\\varepsilon_5\\\\\\varepsilon_6\\\\\\varepsilon_7&\\\\\\varepsilon_8\\\\\\varepsilon_9\n  \\end{pmatrix}\n  $$\n\n- **effects parameterization** - generating a new set ($p-1$) of\n  effects parameters ($\\beta_{j}$, where $j$ represents the set of\n  orthogonal parameters from 1 to $p-1$) each of which represent a\n  linear combination of groups rather than a single group effect. That\n  is, each $\\beta$ can include varying contributions from any number\n  of the groups and are not restricted to a single contrast of\n  ($=\\beta_j-\\beta$). For example, one of the parameters might\n  represent the difference in means between two groups or the\n  difference in means between one group and the average of two other\n  groups. $$y_{ij} = \\beta_0+\\beta_j+\\varepsilon_{ij},\n  \\hspace{2cm}\\text{where}~j= 1:(p-1)$$ In the effects\n  parameterization, $\\mu$ typically represents the mean of one of the\n  groups (a reference group) and each of the $\\beta$ effects represent\n  the difference between subsequent group means and the reference\n  group.\n\n  $$\\begin{pmatrix}\n    2\\\\3\\\\4\\\\6\\\\7\\\\8\\\\10\\\\11\\\\12\n  \\end{pmatrix} = \n  \\begin{pmatrix}\n\t1&0&0\\\\1&0&0\\\\1&0&0\\\\1&1&0\\\\1&1&0\\\\1&1&0\\\\1&0&1\\\\1&0&1\\\\1&0&1\n  \\end{pmatrix} \\times\n  \\begin{pmatrix}\n\t\\beta_0\\\\\\beta_1\\\\\\beta_2\\\\\\beta_3\n  \\end{pmatrix} + \n  \\begin{pmatrix}\t\\varepsilon_1\\\\\\varepsilon_2\\\\\\varepsilon_3\\\\\\varepsilon_4&\\\\\\varepsilon_5\\\\\\varepsilon_6\\\\\\varepsilon_7&\\\\\\varepsilon_8\\\\\\varepsilon_9\n  \\end{pmatrix}\n  $$\n\nThe reduced number of effects parameters are defined through the use\nof a matrix of **contrast coefficients**. Note, the new set of effects\nparameters should incorporate the overall relational effects of each\nof the groups equally such that each group maintains an equal\ncontribution to the overall model fit. The contrast coefficients are\nresponsible for determining how the model is re-parameterized into an\northogonal model matrix.\n\nA number of _pre-fabricated_, contrast matrices exist (to yield\ncommonly used model matrices), each of which estimate a different set\nof specific comparisons between treatment combinations. We will\nexplore each of these with Motivating example 3 in subsequent sections\non fitting linear models.\n\n<!--\nTo compare the\ncommon forms of model parameterization, lets create the above data\nwithin R.\n-->\n<!--\nMore typically however, statistical models that include one or more\nfactors (categorical variables) are expressed as **effects models** in\nwhich $\\beta_9$ represents the mean response within the first\ntreatment group and the remaining $p-1$ $\\beta$ parameters (e.g.\n$\\beta_1$, $\\beta_2$ etc) represent the effects (differences) between\n$\\beta_0$ and the means of each other group. For a data set comprised\nof $p$ groups and $n$ replicates within each group, the linear effects\nmodel is:\n\n$$y_{ij} = \\beta_0 + \\beta_{j} + \\varepsilon_{ij}$$\n\nwhere $j$ represents the set of treatments (from 1 to $p$) and $i$\nrepresents the set of replicates (from 1 to $n$) within the $j^{th}$\ngroup. Hence, $y_{ij}$ represents the $i^{th}$ observation of the\nresponse variable within the $j^{th}$ group of the factor.\n\n- $\\mu$ is the overall population mean of the response variable ($Y$)\n  and is equivalent to the intercept.\n- $\\beta_j$ represents the effect of the $j^{th}$ group calculated as\n  the difference between each of the group means and the overall mean\n  ($\\beta_j=\\mu_j - \\mu$).\n-->\n\n\n# Example data\n\nThis tutorial will blend theoretical discussions with actual\ncalculations and model fits. I believe that by bridging the divide\nbetween theory and application, we all gain better understanding. The\napplied components of this tutorial will be motivated by numerous\nfabricated data sets. The advantage of simulated data over real data\nis that with simulated data, we know the 'truth' and can therefore\ngauge the accuracy of estimates.\n\nThe motivating examples are:\n\n- **Example 1** - simulated samples drawn from a Gaussian (normal)\n  distribution reminiscent of data collected on measurements (such as\n  body mass)\n- **Example 2** - simulated Gaussian samples drawn three different\n  populations representing three different treatment levels (e.g. body\n  masses of three different species)\n- **Example 3** - simulated samples drawn from a Poisson distribution\n  reminiscent of count data (such as number of individuals of a\n  species within quadrats)\n- **Example 4** - simulated samples drawn from a Negative Binomial\n  distribution reminiscent of over-dispersed count data (such as\n  number of individuals of a species that tends to aggregate in\n  groups)\n- **Example 5** - simulated samples drawn from a Bernoulli (binomial\n  with $n = 1$) distribution reminiscent of binary data (such as the\n  presence/absence of a species within sites)\n- **Example 6** - simulated samples drawn from a Binomial distribution\n  reminiscent of proportional data (such as counts of a particular\n  taxa out of a total number of individuals)\n\n::: {.panel-tabset}\n\n## Example 1 (Gaussian data)\n\nLets formally simulate the data illustrated above. The underlying\nprocess dictates that on average a one unit change in the predictor\n(`x`) will be associated with a five unit change in response (`y`) and\nwhen the predictor has a value of 0, the response will typically be 2.\nHence, the response (`y`) will be related to the predictor (`x`) via\nthe following:\n\n$$\ny = 2 + 5x\n$$\n\nThis is a deterministic model, it has no uncertainty. In order to\nsimulate actual data, we need to add some random noise. We will assume\nthat the residuals are drawn from a Gaussian distribution with a mean\nof zero and standard deviation of 4. The predictor will comprise of 10\nuniformly distributed integer values between 1 and 10. We will round\nthe response to two decimal places.\n\nFor repeatability, a seed will be employed on the random number\ngenerator. Note, the smaller the dataset, the less it is likely to\nrepresent the underlying deterministic equation, so we should keep\nthis in mind when we look at how closely our estimated parameters\napproximate the 'true' values. Hence, the seed has been chosen to\nyield data that maintain a general trend that is consistent with the\ndefining parameters.\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nset.seed(234)\ndat <- data.frame(x = 1:10) |>\n    mutate(y = round(2 + 5*x + rnorm(n = 10, mean = 0, sd = 4), digits = 2))\ndat\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n    x     y\n1   1  9.64\n2   2  3.79\n3   3 11.00\n4   4 27.88\n5   5 32.84\n6   6 32.56\n7   7 37.84\n8   8 29.86\n9   9 45.05\n10 10 47.65\n```\n\n\n:::\n\n```{.r .cell-code}\nggplot(data = dat) + \ngeom_point(aes(y = y, x = x))\n```\n\n::: {.cell-output-display}\n![](30_glm_files/figure-html/sim-1.png){width=288}\n:::\n:::\n\n\n\nWe will use these data in two ways. Firstly, to estimate the mean and\nvariance of the reponse (`y`) ignoring the predcitor (`x`) and\nsecondly to estimate the relationship between the reponse and\npredictor.\n\nFor the former, we know that the mean and variance of the response\n(`y`) can be calculated as:\n\n$$\n\\begin{align}\n\\bar{y} =& \\frac{1}{n}\\sum^n_{i=1}y_i\\\\\nvar(y) =& \\frac{1}{n}\\sum^n_{i=1}(y-\\bar{y})^2\\\\\nsd(y) =& \\sqrt{var(y)}\n\\end{align}\n$$\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nmean(dat$y)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n[1] 27.811\n```\n\n\n:::\n\n```{.r .cell-code}\nvar(dat$y)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n[1] 225.9111\n```\n\n\n:::\n\n```{.r .cell-code}\nsd(dat$y)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n[1] 15.03034\n```\n\n\n:::\n:::\n\n\n\n## Example 2 (categorical predictor)\n\nAs previously described, categorical predictors are transformed into\ndummy codes prior to the fitting of the linear model. We will simulate\na small data set with a single categorical predictor comprising a\ncontrol and two treatment levels ('mediam', 'high'). To simplify\nthings we will assume a Gaussian distribution, however most of the\nmodelling steps would be the same regardless of the chosen\ndistribution.\n\nThe data will be drawn from three Gaussian distributions with a\nstandard deviation of 4 and means of 20, 15 and 10. We will draw a\ntotal of 12 observations, four from each of the three populations.\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nset.seed(123)\nbeta_0 <- 20\nbeta <- c(-5, -10)\nsigma <- 4\nn <- 12\nx <- gl(3, 4, 12, labels = c('control', 'medium', 'high'))\ny <- (model.matrix(~x) %*% c(beta_0, beta)) + rnorm(12, 0, sigma)\ndat2 <- data.frame(x = x, y = y)\ndat2\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n         x         y\n1  control 17.758097\n2  control 19.079290\n3  control 26.234833\n4  control 20.282034\n5   medium 15.517151\n6   medium 21.860260\n7   medium 16.843665\n8   medium  9.939755\n9     high  7.252589\n10    high  8.217352\n11    high 14.896327\n12    high 11.439255\n```\n\n\n:::\n\n```{.r .cell-code}\nggplot(data = dat2) + \ngeom_point(aes(y = y, x = x)) \n```\n\n::: {.cell-output-display}\n![](30_glm_files/figure-html/sim2-1.png){width=288}\n:::\n:::\n\n\n\n## Example 3 (Poisson data)\n\nThe Poisson distribution is only parameterized by a single parameter\n($\\lambda$) which represents both the mean and variance. Furthermore,\nPoisson data can only be positive integers.  \n\nUnlike simple trend between two Gaussian or uniform distributions,\nmodelling against a Poisson distribution alters the scale to\nlogarithms. This needs to be taken into account when we simulate the\ndata. The parameters that we used to simulate the underlying processes\nneed to either be on a logarithmic scale, or else converted to a\nlogarithmic scale prior to using them for generating the random data.\n\nMoreover, for any model that involves a non-identity link function\n(such as a logarithmic link function for Poisson models), 'slope' is\nonly constant on the scale of the link function. When it is back\ntransformed onto the natural scale (scale of the data), it takes on a\ndifferent meaning and interpretation.\n\nWe will chose $\\beta_0$ to represent a value of 1 when `x=0`. As for\nthe 'effect' of the predictor on the response, lets say that for every\none unit increase in the predictor the response increases by 40% (on\nthe natural scale). Hence, on the log scale, the slope will be\n$log(1.5)=$ 0.3364722.\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nset.seed(123)\nbeta <- c(1, 1.40)\nbeta <- log(beta)\nn <- 10\ndat3 <- data.frame(x=seq(from = 1, to = 10, len = n)) |>\n    mutate(y = rpois(n, lambda = exp(beta[1] + beta[2]*x)))\ndat3\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n    x  y\n1   1  1\n2   2  3\n3   3  2\n4   4  6\n5   5  9\n6   6  3\n7   7 10\n8   8 15\n9   9 28\n10 10 31\n```\n\n\n:::\n\n```{.r .cell-code}\nggplot(data = dat3) + \ngeom_point(aes(y = y, x = x)) \n```\n\n::: {.cell-output-display}\n![](30_glm_files/figure-html/sim3-1.png){width=288}\n:::\n:::\n\n\n\n## Example 4 (NB data)\n\nIn theory, count data should follow a Poisson distribution and\ntherefore have properties like mean equal to variance (e.g.\n$\\textnormal{Dispersion}=\\frac{\\sigma}{\\mu}=1$). However as simple\nlinear models are low dimensional representations of a system, it is\noften unlikely that such a simple model can capture all the\nvariability in the response (counts). For example, if we were\nmodelling the abundance of a species of intertidal snail within\nquadrats in relation to water depth, it is highly likely that water\ndepth alone drives snail abundance. There are countless other\ninfluences that the model has not accounted for. As a result, the\nobserved data might be more variable than a Poisson (of a particular\nmean) would expect and in such cases, the model is over-dispersed\n(more variance than expected).\n\nOver dispersed models under-estimate the variability and thus\nprecision in estimates resulting in inflated confidence in outcomes\n(elevated Type I errors).\n\nThere are numerous causes of over-dispersed count data (one of which\nis eluded to above). These are:\n\n- additional sources of variability not being accounted for in the\n  model (see above)\n- when the items being counted aggregate together. Although the\n  underlying items may have been generated by a Poisson process, the\n  items clump together. When the items are counted, they are more\n  likely to be in either in relatively low or relatively high\n  numbers - hence the data are more varied than would be expected from\n  their overall mean.\n- imperfect detection resulting in excessive zeros. Again the\n  underlying items may have been generated by a Poisson process,\n  however detecting and counting the items might not be completely\n  straight forward (particularly for more cryptic items). Hence, the\n  researcher may have recorded no individuals in a quadrat and yet\n  there was one or more present, they were just not obvious and were\n  not detected. That is, layered over the Poisson process is another\n  process that determines the detectability. So while the Poisson\n  might expect a certain proportion of zeros, the observed data might\n  have a substantially higher proportion of zeros - and thus higher\n  variance.\n\nThis example will generate data that is drawn from a negative binomial\ndistribution so as to broadly represent any one of the above causes.\n\nWe will chose $\\beta_0$ to represent a value of 1 when `x=0`. As for\nthe 'effect' of the predictor on the response, lets say that for every\none unit increase in the predictor the response increases by 40% (on\nthe natural scale). Hence, on the log scale, the slope will be\n$log(1.5)=$ 0.3364722. Finally, the dispersion parameter (ratio of\nvariance to mean) will be 10.\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nset.seed(234)\nbeta <- c(1, 1.40)\nbeta <- log(beta)\nn <- 10\nsize <- 10\ndat4 <- data.frame(x = seq(from = 1, to = 10, len = n)) |>\n    mutate(\n        mu = exp(beta[1] + beta[2] * x),\n        y = rnbinom(n, size = size, mu =  mu)\n    )\ndat4\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n    x        mu  y\n1   1  1.400000  0\n2   2  1.960000  3\n3   3  2.744000  7\n4   4  3.841600  3\n5   5  5.378240  5\n6   6  7.529536  9\n7   7 10.541350 13\n8   8 14.757891 10\n9   9 20.661047 17\n10 10 28.925465 26\n```\n\n\n:::\n\n```{.r .cell-code}\nggplot(data = dat4) + \ngeom_point(aes(y = y, x = x)) \n```\n\n::: {.cell-output-display}\n![](30_glm_files/figure-html/sim4-1.png){width=288}\n:::\n:::\n\n\n\n## Example 5 (Binary data)\n\nBinary data (presence/absence, dead/alive, yes/no, heads/tails, etc)\npose unique challenges for linear modeling. Linear regression,\ndesigned for continuous outcomes, may not be directly applicable to\nbinary responses. The nature of binary data violates assumptions of\nnormality and homoscedasticity, which are fundamental to linear\nregression. Furthermore, linear models may predict probabilities\noutside the [0, 1] range, leading to unrealistic predictions.\n\nThis example will generate data that is drawn from a bernoulli\ndistribution so as to broadly represent presence/absence data.\n\nWe will chose $\\beta_0$ to represent the odds of a value of 1 when\n$x=0$ equal to $0.02$. This is equivalent to a probability of $y$\nbeing zero when $x=0$ of $\\frac{0.02}{1+0.02}=0.0196$. E.g., at low\n$x$, the response is likely to be close to 0. For every one unit\nincrease in $x$, we will stipulate a 2 times increase in odds that\nthe expected response is equal to 1.\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nset.seed(234)\nbeta <- c(0.02, 2)\nbeta <- log(beta)\nn <- 10\ndat5 <- data.frame(x = seq(from = 1, to = 10, len = n)) |>\n    mutate(\n        y = as.numeric(rbernoulli(n, p = plogis(beta[1] + beta[2] * x)))\n    )\ndat5\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n    x y\n1   1 0\n2   2 0\n3   3 0\n4   4 1\n5   5 0\n6   6 1\n7   7 1\n8   8 1\n9   9 1\n10 10 1\n```\n\n\n:::\n\n```{.r .cell-code}\nggplot(data = dat5) + \ngeom_point(aes(y = y, x = x)) \n```\n\n::: {.cell-output-display}\n![](30_glm_files/figure-html/sim5-1.png){width=288}\n:::\n:::\n\n\n\n## Example 6 (Binomial data)\n\nSimilar to binary data, proportional (binomial) data tend to violate\nnormality and homogeneity of variance (particularly as mean\nproportions approach either 0% or 100%.\n\nThis example will generate data that is drawn from a binomial\ndistribution so as to broadly represent proportion data.\n\nWe will chose $\\beta_0$ to represent the odds of a particular trial\n(e.g. an individual) being of a particular type (e.g. species 1) when\n$x=0$ and to equal to $0.02$. This is equivalent to a probability of\n$y$ being of the focal type when $x=0$ of\n$\\frac{0.02}{1+0.02}=0.0196$. E.g., at low $x$, the the probability\nthat an individual is taxa 1 is likely to be close to 0. For every one\nunit increase in $x$, we will stipulate a 2.5 times increase in odds\nthat the expected response is equal to 1.\n\nFor this example, we will also convert the counts into proportions\n($y2$) by division with the number of trials ($5$).\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nset.seed(123)\nbeta <- c(0.02, 2.5)\nbeta <- log(beta)\nn <- 10\ntrials <- 5\ndat6 <- data.frame(x = seq(from = 1, to = 10, len = n)) |>\n    mutate(\n      count = as.numeric(rbinom(n, size = trials, prob = plogis(beta[1] + beta[2] * x))),\n      total = trials,\n      y = count/total\n    )\ndat6\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n    x count total   y\n1   1     0     5 0.0\n2   2     1     5 0.2\n3   3     1     5 0.2\n4   4     4     5 0.8\n5   5     2     5 0.4\n6   6     5     5 1.0\n7   7     5     5 1.0\n8   8     4     5 0.8\n9   9     5     5 1.0\n10 10     5     5 1.0\n```\n\n\n:::\n\n```{.r .cell-code}\nggplot(data = dat6) + \ngeom_point(aes(y = y, x = x)) \n```\n\n::: {.cell-output-display}\n![](30_glm_files/figure-html/sim6-1.png){width=288}\n:::\n:::\n\n\n\n\n:::\n\n# Exploratory data analysis\n\nStatistical models utilize data and the inherent statistical\nproperties of distributions to discern patterns, relationships, and\ntrends, enabling the extraction of meaningful insights, predictions,\nor inferences about the phenomena under investigation. To do so,\nstatistical models make assumptions about the likely distributions\nfrom which the data were collected. Consequently, the reliability and\nvalidity of any statistical model depend upon adherence to these\nunderlying assumptions.\n\nExploratory Data Analysis (EDA) and assumption checking therefore play\npivotal roles in the process of statistical analysis, offering\nessential tools to glean insights, assess the reliability of\nstatistical methods, and ensure the validity of conclusions drawn from\ndata. EDA involves visually and statistically examining datasets to\nunderstand their underlying patterns, distributions, and potential\noutliers. These initial steps provides an intuitive understanding of\nthe data's structure and guides subsequent analyses. By scrutinizing\nassumptions, such as normality, homoscedasticity, and independence,\nresearchers can identify potential limitations or violations that may\nimpact the accuracy and reliability of their findings.\n\nExploratory Data Analysis within the context of ecological statistical\nmodels usually comprise a set of targetted graphical summaries. They\nare not to be considered definitive diagnostics of the model\nassumptions, but rather a first pass to assess the obvious violations\nprior to the fitting of models. More definitive diagnostics can only\nbe achieved after a model has been fit. \n\nIn addition to graphical summaries, there are numerous statistical\ntests to help explore possible violations of various statistical\nassumptions. These tests are less commonly used in ecology since they\nare often more sensitive to deviations from ideal than are the models\nthat we are seeking to ensure. \n\nSimple classic regression models are often the easiest models to fit\nand interpret and as such often represent a standard by which other\nalternate models are gauged. As you will see later in this tutorial,\nsuch models can actually be fit using closed form (exact solution)\nmatrix algebra that can be performed by hand. Nevertheless, and\nperhaps as a result, they also impose some of the strictest\nassumptions. Although these collective assumptions are specific to\ngaussian models, they do provide a good introduction to model\nassumptions in general, so we will use them to motivate the more wider\ndiscussion.\n\nSimple (gaussian) linear models (represented below) make the following\nassumptions:\n\n::: {.columns}\n\n:::: {.column width=\"65%\"}\n\n\n\n::: {.cell}\n::: {.cell-output-display}\n![](30_glm_files/figure-html/model1-1.png){width=576}\n:::\n:::\n\n\n \n\n::::\n\n:::: {.column width=\"35%\"}\n\n\n\n::: {.cell}\n::: {.cell-output-display}\n![](30_glm_files/figure-html/assumptions,-1.png){width=288}\n:::\n:::\n\n\n\n::::\n\n:::\n\n\n::: {.callout-note collapse=\"true\"}\n### Notes on the data depicted above\nThe data depicted above where generated using the following R codes:\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nset.seed(234)\nx <- 1:10\ny <- 2 + (5*x) + rnorm(10,0,4)\n```\n:::\n\n\n\nThe observations represent\n\n- single observations drawn from 10 normal populations\n- each population had a standard deviation of 4\n- the mean of each population varied linearly according to the value of x ($2 + 5x$)\n:::\n\n- **normality**: the residuals (and thus observations) must be drawn\n  from populations that are normal distribution. _The right hand figure\n  underlays the ficticious normally distributed populations from which\n  the observed values have been sampled_.\n  \n:::: {.indented}\n\n::: {.callout-note collapse=\"true\"}\n### More information about assessing normality\n\nEstimation and inference testing in linear regression assumes that the\nresponse is normally distributed in each of the populations. In this\ncase, the populations are all possible measurements that could be\ncollected at each level of $x$ - hence there are 16 populations.\nTypically however, we only collect a single observation from each\npopulation (as is also the case here). How then can be evaluate\nwhether each of these populations are likely to have been normal?\n\n::::: {.columns}\n\n:::::: {.column width=\"45%\"}\n\n\n\n::: {.cell}\n::: {.cell-output-display}\n![](30_glm_files/figure-html/assumptions1a-1.png){width=384}\n:::\n:::\n\n\n\n::::::\n\n:::::: {.column width=\"45%\"}\n\n\n\n::: {.cell}\n::: {.cell-output-display}\n![](30_glm_files/figure-html/assumptions1b-1.png){width=384}\n:::\n:::\n\n\n\n::::::\n:::::\n\nFor a given response, the population distributions should follow much\nthe same distribution shapes. Therefore provided the single samples\nfrom each population are unbiased representations of those\npopulations, a boxplot of all observations should reflect the\npopulation distributions.\n\nThe two figures above show the relationships between the individual\npopulation distributions and the overall distribution. The left hand\nfigure shows a distribution drawn from single representatives of each\nof the 16 populations. Since the 16 individual populations were\nnormally distributed, the distribution of the 16 observations is also\nnormal.\n\nBy contrast, the right hand figure shows 16 log-normally distributed\npopulations and the resulting distribution of 16 single observations\ndrawn from these populations. The overall boxplot mirrors each of the\nindividual population distributions.\n\nWhilst traditionally, non-normal data would typically be\n**normalised** via a scale transformation (such as a logarithmic\ntransformation), these days it is arguably more appropriate to attempt\nto match the data to a more suitable distribution (see later in this\ntutorial).\n\nYou may have noticed that we have only explored the distribution of\nthe response (y-axis). What about the distribution of the predictor\n(independent, x-axis) variable, does it matter? The distribution\nassumption applies to the residuals (which as purely in the direction\nof the y-axis). Indeed technically, it is assumed that there is no\nuncertainty associated with the predictor variable. They are assumed\nto be set and thus there is no error associated with the values\nobserved. Whilst this might not always be reasonable, it is an\nassumption.\n\nGiven that the predictor values are expected to be _set_ rather than\n_measured_, we actually assume that they are **uniformly**\ndistributed. In practice, the exact distribution of predictor values\nis not that important provided it is reasonably symmetrical and no\noutliers (unusually small or large values) are created as a result of\nthe distribution.\n\nAs with exploring the distribution of the response variable, boxplots,\nhistograms and density plots can be useful means of exploring the\ndistribution of predictor variable(s). When such diagnostics reveal\ndistributional issues, scale transformations (such as logarithmic\ntransformations) are appropriate.\n\n:::\n\n::::\n\n\n\n- **homogeneity of variance**: the residuals (and thus observations)\n  must be drawn from populations that are equally varied. The model as\n  shown only estimates a single variance ($\\sigma^2$) parameter - it is\n  assumed that this is a good overall representation of all underlying\n  populations. _The right hand figure underlays the ficticious normally\n  distributed and equally varied populations from which the\n  observations have been sampled_.\n  \n  Moreover, since the expected values (obtained by solving the\n  deterministic component of the model) and the variance must be\n  estimated from the same data, they need to be independent (not\n  related one another)\n\n:::: {.indented}\n\n::: {.callout-note collapse=\"true\"}\n### More information about assessing homogeneity of variance\n\nSimple linear regression also assumes that each of the populations are\nequally varied. Actually, it is the prospect of a relationship between\nthe mean and variance of y-values across x-values that is of the\ngreatest concern. Strictly the assumption is that the distribution of\ny values at each x value are equally varied and that there is no\nrelationship between mean and variance.\n\nHowever, as we only have a single y-value for each x-value, it is\ndifficult to directly determine whether the assumption of homogeneity\nof variance is likely to have been violated (mean of one value is\nmeaningless and variability can't be assessed from a single value).\nThe figure below depicts the ideal (and almost never realistic)\nsituation in which (left hand figure) the populations are all equally\nvaried. The middle figure simulates drawing a single observation from\neach of the populations. When the populations are equally varied, the\nspread of observed values around the trend line is fairly even - that\nis, there is no trend in the spread of values along the line.\n\nIf we then plot the residuals (difference between observed values and\nthose predicted by the trendline) against the predict values, there is\na definite lack of pattern. This lack of pattern is indicative of a\nlack of issues with homogeneity of variance.\n\n::::: {.columns}\n\n:::::: {.column width=\"32%\"}\n\n\n\n::: {.cell}\n::: {.cell-output-display}\n![](30_glm_files/figure-html/assumptions2a-1.png){width=240}\n:::\n:::\n\n\n\n::::::\n\n:::::: {.column width=\"32%\"}\n\n\n\n::: {.cell}\n::: {.cell-output-display}\n![](30_glm_files/figure-html/assumptions2b-1.png){width=240}\n:::\n:::\n\n\n\n::::::\n\n:::::: {.column width=\"32%\"}\n\n\n\n::: {.cell}\n::: {.cell-output-display}\n![](30_glm_files/figure-html/assumptions2c-1.png){width=240}\n:::\n:::\n\n\n\n::::::\n:::::\n\nIf we now contrast the above to a situation where the population\nvariance is related to the mean (unequal variance), we see that the\nobservations drawn from these populations are not evenly distributed\nalong the trendline (they get more spread out as the mean predicted\nvalue increase). This pattern is emphasized in the residual plot which\ndisplays a characteristic \"wedge\"-shape pattern.\n\n::::: {.columns}\n\n:::::: {.column width=\"32%\"}\n\n\n\n::: {.cell}\n::: {.cell-output-display}\n![](30_glm_files/figure-html/assumptions2d-1.png){width=240}\n:::\n:::\n\n\n\n::::::\n\n:::::: {.column width=\"32%\"}\n\n\n\n::: {.cell}\n::: {.cell-output-display}\n![](30_glm_files/figure-html/assumptions2e-1.png){width=240}\n:::\n:::\n\n\n\n::::::\n\n:::::: {.column width=\"32%\"}\n\n\n\n::: {.cell}\n::: {.cell-output-display}\n![](30_glm_files/figure-html/assumptions2f-1.png){width=240}\n:::\n:::\n\n\n\n::::::\n:::::\n\nHence looking at the spread of values around a trendline on a\nscatterplot of $y$ against $x$ is a useful way of identifying gross\nviolations of homogeneity of variance. Residual plots provide an even\nbetter diagnostic. The presence of a wedge shape is indicative that\nthe population mean and variance are related.\n:::\n\n::::\n\n- **linearity**: the underlying relationships must be simple linear\n  trends, since the line of best fit through the data (of which the\n  slope is estimated) is linear. _The right hand figure depicts a\n  linear trend through the underlying populations_.\n\n:::: {.indented}\n\n::: {.callout-note collapse=\"true\"}\n### More information about assessing linearity\n\nIt is important to disclose the meaning of the word \"linear\" in the\nterm \"linear regression\". Technically, it refers to a _linear_\ncombination of regression coefficients. For example, the following are\nexamples of linear models:\n\n- $y_i = \\beta_0 + \\beta_1 x_i$\n- $y_i = \\beta_0 + \\beta_1 x_i + \\beta_2 z_i$\n- $y_i = \\beta_0 + \\beta_1 x_i + \\beta_2 x^2_i$\n\nAll the coefficients ($\\beta_0$, $\\beta_1$, $\\beta_2$) are linear\nterms. Note that the last of the above examples, is a linear model,\nhowever it describes a non-linear trend. Contrast the above models\nwith the following non-linear model:\n\n- $y_i = \\beta_0 + x_i^{\\beta_1}$\n\nIn that case, the coefficients are not linear combinations (one of\nthem is a power term).\n\n\nThat said, a simple linear regression usually fits a straight (linear)\nline through the data. Therefore, prior to fitting such a model, it is\nnecessary to establish whether this really is the most sensible way of\ndescribing the relationship. That is, does the relationship appear to\nbe linearly related or could some other non-linear function describe\nthe relationship better. Scatterplots and residual plots are useful\ndiagnostics.\n\nTo see how a residual plot could be useful, consider the following.\nThe first row of figures illustrate the residuals resulting from data\ndrawn from a linear trend. The residuals are effectively random noise.\nBy contrast, the second row show the residuals resulting from data\ndrawn from a non-normal relationship that have nevertheless been\nmodelled as a linear trend. There is still a clear pattern remaining\nin the residuals.\n\n::::: {.columns}\n\n:::::: {.column width=\"32%\"}\n\n\n\n::: {.cell}\n::: {.cell-output-display}\n![](30_glm_files/figure-html/assumptions2a-1.png){width=240}\n:::\n:::\n\n\n\n::::::\n\n:::::: {.column width=\"32%\"}\n\n\n\n::: {.cell}\n::: {.cell-output-display}\n![](30_glm_files/figure-html/assumptions2b-1.png){width=240}\n:::\n:::\n\n\n\n::::::\n\n:::::: {.column width=\"32%\"}\n\n\n\n::: {.cell}\n::: {.cell-output-display}\n![](30_glm_files/figure-html/assumptions2c-1.png){width=240}\n:::\n:::\n\n\n\n::::::\n:::::\n\n::::: {.columns}\n\n:::::: {.column width=\"32%\"}\n\n\n\n::: {.cell}\n::: {.cell-output-display}\n![](30_glm_files/figure-html/assumptions2a2-1.png){width=240}\n:::\n:::\n\n\n\n::::::\n\n:::::: {.column width=\"32%\"}\n\n\n\n::: {.cell}\n::: {.cell-output-display}\n![](30_glm_files/figure-html/assumptions2b2-1.png){width=240}\n:::\n:::\n\n\n\n::::::\n\n:::::: {.column width=\"32%\"}\n\n\n\n::: {.cell}\n::: {.cell-output-display}\n![](30_glm_files/figure-html/assumptions2c2-1.png){width=240}\n:::\n:::\n\n\n\n::::::\n:::::\n\nThe above might be an obvious and somewhat overly contrived example,\nyet it does illustrate the point - that a pattern in the residuals\ncould point to a mis-specified model.\n\nIf non-linearity does exist (as in the second case above) , then\nfitting a straight line through what is obviously not a straight\nrelationship is likely to poorly represent the true nature of the\nrelationship. There are numerous causes of non-linearity:\n\n1. underlying distributional issues can result in non-linearity. For\n   example, if we are assuming a gaussian distribution and the data\n   are non-normal, often the relationships will appear non-linear.\n   Addressing the distributional issues can therefore resolve the\n   linearity issues\n2. the underlying relationship might truly be non-linear in which case\n   this should be reflected in some way by the model formula. If the\n   model formula fails to describe the non-linear trend, then problems\n   will persist.\n3. the model proposed is missing an important covariate that might\n   help standardise the data in a way that results in linearity\n\n\n:::\n\n::::\n\n- **independence**: the residuals (and thus observations) must be\n  independently drawn from the populations. That is, the correlation\n  between all the observations is assumed to be 0 (off-diagonals in\n  the covariance matrix). More practically, there should be no\n  pattern to the correlations between observations.\n\n  Random sampling and random treatment assignment are experimental\n  design elements that are intended to mitigate many types of sampling\n  biases that cause dependencies between observations. Nevertheless,\n  there are aspects of sampling designs that are either logistically\n  difficult to randomise or in some cases not logically possible. For\n  example, the residuals from observations sampled closer together in\n  space and time will likely be more similar to one another than those\n  of observations more spaced apart. Since neither space nor time can\n  be randomised, data collected from sampling designs that involve\n  sampling over space and/or time need to be assess for spatial and\n  temporal dependencies. These concepts will be explored in the\n  context of introducing susceptible designs in a later tutorial.\n\nThe above is only a very brief overview of the model assumptions that\napply to just one specific model (simple linear gaussian regression).\nFor the remainder of this section, we will graphically explore the two\nmotivating example data sets so as gain insights into what\ndistributional assumptions might be most valid, and thus help guide\nmodelling choices. Similarly, for subsequent tutorials in this series\n(that introduce progressively more complex models), all associated\nassumptions will be explored and detailed.\n\n::: {.panel-tabset}\n\n## Example 1 (Gaussian data)\n\n:::: {.panel-tabset}\n\n### Normality\n\n::::: {.columns}\n:::::: {.column width=\"48%\"}\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\ndat |> \n  ggplot(aes(y = y)) +\n  geom_boxplot()\n```\n\n::: {.cell-output-display}\n![](30_glm_files/figure-html/eda1a-1.png){width=288}\n:::\n:::\n\n\n\n:::::: \n\n:::::: {.column width=\"48%\"}\n**Conclusions**\n\n- there is no strong evidence of non-normality\n- to be convincing evidence of non-normality, each segment of the\n  boxplot should get progressively larger\n\n:::::: \n::::: \n\n### Homogeneity of variance\n\n::::: {.columns}\n:::::: {.column width=\"48%\"}\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\ndat |> \n  ggplot(aes(y = y, x = x)) +\n  geom_smooth(method = \"lm\") +\n  geom_point()\n```\n\n::: {.cell-output .cell-output-stderr}\n\n```\n`geom_smooth()` using formula = 'y ~ x'\n```\n\n\n:::\n\n::: {.cell-output-display}\n![](30_glm_files/figure-html/eda1b-1.png){width=288}\n:::\n:::\n\n\n\n:::::: \n\n:::::: {.column width=\"48%\"}\n**Conclusions**\n\n- the spread of values around the trendline seems fairly even (hence\n  it there is no evidence of non-homogeneity\n\n:::::: \n::::: \n\n### Linearity\n\n::::: {.columns}\n:::::: {.column width=\"48%\"}\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\ndat |> \n  ggplot(aes(y = y, x = x)) +\n  geom_smooth(method = \"lm\") +\n  geom_point()\n```\n\n::: {.cell-output .cell-output-stderr}\n\n```\n`geom_smooth()` using formula = 'y ~ x'\n```\n\n\n:::\n\n::: {.cell-output-display}\n![](30_glm_files/figure-html/eda1c-1.png){width=288}\n:::\n:::\n\n\n\n:::::: \n\n:::::: {.column width=\"48%\"}\n**Conclusions**\n\n- the data seems well represented by the linear trendline.\n  Furthermore, the lowess smoother does not appear to have a\n  consistent shift trajectory.\n\n:::::: \n::::: \n::::\n\n\n**Conclusions**\n\n- there are no obvious violations of the linear regression model assumptions\n- we can now fit the suggested model\n- full confirmation about the model's goodness of fit should be\n  reserved until after exploring the additional diagnostics that are\n  only available after fitting the model.\n\n\n## Example 2 (categorical predictor)\n\n:::: {.panel-tabset}\n\n### Normality\n\n::::: {.columns}\n:::::: {.column width=\"48%\"}\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\ndat2 |> \n  ggplot(aes(y = y, x = x)) +\n  geom_boxplot()\n```\n\n::: {.cell-output-display}\n![](30_glm_files/figure-html/eda2a-1.png){width=288}\n:::\n:::\n\n\n::::::\n:::::: {.column width=\"48%\"}\n**Conclusions**\n\n- there is no consitent evidence of non-normality across all groups\n- even though the control group demonstrates some evidence of\n  non-normality\n:::::: \n:::::\n\n### Homogeneity of variance\n\n::::: {.columns}\n:::::: {.column width=\"48%\"}\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\ndat2 |> \n  ggplot(aes(y = y, x = x)) +\n  geom_boxplot()\n```\n\n::: {.cell-output-display}\n![](30_glm_files/figure-html/eda2b-1.png){width=288}\n:::\n:::\n\n\n\n:::::: \n\n:::::: {.column width=\"48%\"}\n**Conclusions**\n\n- the spread of noise in each group seems reasonably similar\n- more importantly, there does not seem to be a relationship between\n  the mean (as approximated by the position of the boxplots along the\n  y-axis) and the variance (as approximated by the spread of the\n  boxplots).\n- that is, the size of the boxplots do not vary with the elevation of\n  the boxplots.\n\n:::::: \n::::: \n\n### Linearity\n\nLinearity is not an issue for categorical predictors since it is\neffectively fitting separate lines between pairs of points (and a line\nbetween two points can only ever be linear)....\n\n::::\n\n**Conclusions**\n\n- no evidence of non-normality\n- no evidence of non-homogeneity of variance\n\n\n## Example 3 (Poisson data)\n\n:::: {.panel-tabset}\n\n### Normality\n\n::::: {.columns}\n:::::: {.column width=\"48%\"}\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\ndat3 |> \n  ggplot(aes(y = y)) +\n  geom_boxplot()\n```\n\n::: {.cell-output-display}\n![](30_glm_files/figure-html/eda3a-1.png){width=288}\n:::\n:::\n\n\n\n:::::: \n\n:::::: {.column width=\"48%\"}\n**Conclusions**\n\n- there is strong evidence of non-normality\n- each segment of the boxplot should get progressively larger\n\n:::::: \n::::: \n\n### Homogeneity of variance\n\n::::: {.columns}\n:::::: {.column width=\"48%\"}\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\ndat3 |> \n  ggplot(aes(y = y, x = x)) +\n  geom_smooth(method = \"lm\") +\n  geom_point()\n```\n\n::: {.cell-output .cell-output-stderr}\n\n```\n`geom_smooth()` using formula = 'y ~ x'\n```\n\n\n:::\n\n::: {.cell-output-display}\n![](30_glm_files/figure-html/eda3b-1.png){width=288}\n:::\n:::\n\n\n\n:::::: \n\n:::::: {.column width=\"48%\"}\n**Conclusions**\n\n- the spread of noise does not look random along the line of best fit.\n- homogeneity of variance is difficult to assess in the presence of\n  distributional issues (such as non-normality in this case) as they\n  can result in non-linearity (apparent here)\n\n:::::: \n::::: \n\n### Linearity\n\n::::: {.columns}\n:::::: {.column width=\"48%\"}\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\ndat3 |> \n  ggplot(aes(y = y, x = x)) +\n  geom_smooth(method = \"lm\") +\n  geom_point()\n```\n\n::: {.cell-output .cell-output-stderr}\n\n```\n`geom_smooth()` using formula = 'y ~ x'\n```\n\n\n:::\n\n::: {.cell-output-display}\n![](30_glm_files/figure-html/eda3c-1.png){width=288}\n:::\n:::\n\n\n\n:::::: \n\n:::::: {.column width=\"48%\"}\n**Conclusions**\n\n- the data do not appear to be linear\n\n:::::: \n::::: \n::::\n\n\n**Conclusions**\n\n- there are obvious violations of the linear regression model assumptions\n- we should consider a different model that does not assume normality\n\n\n## Example 4 (NB data)\n\n:::: {.panel-tabset}\n\n### Normality\n\n::::: {.columns}\n:::::: {.column width=\"48%\"}\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\ndat4 |> \n  ggplot(aes(y = y)) +\n  geom_boxplot()\n```\n\n::: {.cell-output-display}\n![](30_glm_files/figure-html/eda4a-1.png){width=288}\n:::\n:::\n\n\n\n:::::: \n\n:::::: {.column width=\"48%\"}\n**Conclusions**\n\n- there is strong evidence of non-normality\n- each segment of the boxplot should get progressively larger\n\n:::::: \n::::: \n\n### Homogeneity of variance\n\n::::: {.columns}\n:::::: {.column width=\"48%\"}\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\ndat4 |> \n  ggplot(aes(y = y, x = x)) +\n  geom_smooth(method = \"lm\") +\n  geom_point()\n```\n\n::: {.cell-output .cell-output-stderr}\n\n```\n`geom_smooth()` using formula = 'y ~ x'\n```\n\n\n:::\n\n::: {.cell-output-display}\n![](30_glm_files/figure-html/eda4b-1.png){width=288}\n:::\n:::\n\n\n\n:::::: \n\n:::::: {.column width=\"48%\"}\n**Conclusions**\n\n- the spread of noise does not look random along the line of best fit.\n- homogeneity of variance is difficult to assess in the presence of\n  distributional issues (such as non-normality in this case) as they\n  can result in non-linearity (apparent here)\n\n:::::: \n::::: \n\n### Linearity\n\n::::: {.columns}\n:::::: {.column width=\"48%\"}\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\ndat4 |> \n  ggplot(aes(y = y, x = x)) +\n  geom_smooth(method = \"lm\") +\n  geom_point()\n```\n\n::: {.cell-output .cell-output-stderr}\n\n```\n`geom_smooth()` using formula = 'y ~ x'\n```\n\n\n:::\n\n::: {.cell-output-display}\n![](30_glm_files/figure-html/eda4c-1.png){width=288}\n:::\n:::\n\n\n\n:::::: \n\n:::::: {.column width=\"48%\"}\n**Conclusions**\n\n- the data do not appear to be linear\n\n:::::: \n::::: \n::::\n\n\n**Conclusions**\n\n- there are obvious violations of the linear regression model assumptions\n- we should consider a different model that does not assume normality\n\n## Example 5 (Binary data)\n\n:::: {.panel-tabset}\n\n### Normality\n\n::::: {.columns}\n:::::: {.column width=\"48%\"}\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\ndat5 |> \n  ggplot(aes(y = y)) +\n  geom_boxplot()\n```\n\n::: {.cell-output-display}\n![](30_glm_files/figure-html/eda5a-1.png){width=288}\n:::\n:::\n\n\n\n:::::: \n\n:::::: {.column width=\"48%\"}\n**Conclusions**\n\n- clearly a set of 0's and 1's cant be normally distributied.\n\n:::::: \n::::: \n\n### Homogeneity of variance\n\n::::: {.columns}\n:::::: {.column width=\"48%\"}\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\ndat5 |> \n  ggplot(aes(y = y, x = x)) +\n  geom_smooth(method = \"lm\") +\n  geom_point()\n```\n\n::: {.cell-output .cell-output-stderr}\n\n```\n`geom_smooth()` using formula = 'y ~ x'\n```\n\n\n:::\n\n::: {.cell-output-display}\n![](30_glm_files/figure-html/eda5b-1.png){width=288}\n:::\n:::\n\n\n\n:::::: \n\n:::::: {.column width=\"48%\"}\n**Conclusions**\n\n- the spread of noise does not look random (or equal) along the line\n  of best fit.\n\n:::::: \n::::: \n\n### Linearity\n\n::::: {.columns}\n:::::: {.column width=\"48%\"}\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\ndat5 |> \n  ggplot(aes(y = y, x = x)) +\n  geom_smooth(method = \"lm\") +\n  geom_point()\n```\n\n::: {.cell-output .cell-output-stderr}\n\n```\n`geom_smooth()` using formula = 'y ~ x'\n```\n\n\n:::\n\n::: {.cell-output-display}\n![](30_glm_files/figure-html/eda5c-1.png){width=288}\n:::\n:::\n\n\n\n:::::: \n\n:::::: {.column width=\"48%\"}\n**Conclusions**\n\n- the data are clearly not linear\n\n:::::: \n::::: \n::::\n\n\n**Conclusions**\n\n- there are obvious violations of the linear regression model assumptions\n- we should consider a different model that does not assume normality\n\n## Example 6 (Binomial data)\n\n:::: {.panel-tabset}\n\n### Normality\n\n::::: {.columns}\n:::::: {.column width=\"48%\"}\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\ndat6 |> \n  ggplot(aes(y = y)) +\n  geom_boxplot()\n```\n\n::: {.cell-output-display}\n![](30_glm_files/figure-html/eda6a-1.png){width=288}\n:::\n:::\n\n\n\n:::::: \n\n:::::: {.column width=\"48%\"}\n**Conclusions**\n\n- distribution is not normal and is truncated\n\n:::::: \n::::: \n\n### Homogeneity of variance\n\n::::: {.columns}\n:::::: {.column width=\"48%\"}\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\ndat6 |> \n  ggplot(aes(y = y, x = x)) +\n  geom_smooth(method = \"lm\") +\n  geom_point()\n```\n\n::: {.cell-output .cell-output-stderr}\n\n```\n`geom_smooth()` using formula = 'y ~ x'\n```\n\n\n:::\n\n::: {.cell-output-display}\n![](30_glm_files/figure-html/eda6b-1.png){width=288}\n:::\n:::\n\n\n\n:::::: \n\n:::::: {.column width=\"48%\"}\n**Conclusions**\n\n- the spread of noise does not look random (or equal) along the line\n  of best fit.\n\n:::::: \n::::: \n\n### Linearity\n\n::::: {.columns}\n:::::: {.column width=\"48%\"}\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\ndat6 |> \n  ggplot(aes(y = y, x = x)) +\n  geom_smooth(method = \"lm\") +\n  geom_point()\n```\n\n::: {.cell-output .cell-output-stderr}\n\n```\n`geom_smooth()` using formula = 'y ~ x'\n```\n\n\n:::\n\n::: {.cell-output-display}\n![](30_glm_files/figure-html/eda6c-1.png){width=288}\n:::\n:::\n\n\n\n:::::: \n\n:::::: {.column width=\"48%\"}\n**Conclusions**\n\n- although there is no evidence of non-linearity from this small data\n  set, it is worth noting that the line of best fit does extend\n  outside the logical response range [0.1] within the range of\n  observed $x$ values. That is, a simple linear model would predict\n  proportions higher than 100% at high values of $x$\n\n:::::: \n::::: \n::::\n\n\n**Conclusions**\n\n- there are obvious violations of the linear regression model assumptions\n- we should consider a different model that does not assume normality\n:::\n\n# Data standardisation\n\nData **centering** involves subtracting the mean of data from each\nobservation thereby resulting in the value of zero being in the center\nof the data. We can take this further and **standardise** (scale) the\ndata such that it has a mean of zero (as with centering) and a\nstandard deviation of one. Again, the spacing and order of the data\nare unaffected.\n\nConsider the three figures below. They each present the same data,\nhowever the data in the middle figure has been centered (it now has a\nmean of 0) and the data in the right hand figure has been\nstandardized. Note that in each case, the order and spacing of the\ndata has not changed, it is just that the number line has been shifted\nto the right (and squashed in the case of the standardised data).\n\n\n::: {.columns}\n:::: {.column width=\"32%\"}\n\n\n::: {.cell}\n::: {.cell-output-display}\n![](30_glm_files/figure-html/scaling1-1.png){width=240}\n:::\n:::\n\n\n\n::::\n\n:::: {.column width=\"32%\"}\n\n\n::: {.cell}\n::: {.cell-output-display}\n![](30_glm_files/figure-html/scaling2-1.png){width=240}\n:::\n:::\n\n\n::::\n\n:::: {.column width=\"32%\"}\n\n\n::: {.cell}\n::: {.cell-output-display}\n![](30_glm_files/figure-html/scaling4-1.png){width=240}\n:::\n:::\n\n\n::::\n\n:::\n\nSo what is the point I hear you ask. Data standardisation can greatly\nenhance the performance and stability of statistical models:\n\n- **improves numerical stability** - many statistical models involve\n  mathematical operations that can be very sensitive to large numbers\n  or scale imbalances. Statistical models (particularly those that\n  involve optimisation algorithms) work far better (and are more\n  likely to converge) when all data are on a standardised scale.\n- **allows effect sizes to be compared** - effect parameters are\n  usually some form of slope which is calculated as the change in $y$\n  divided by the change in $x$. The magnitude of the slope is\n  therefore determined by the scale of both $y$ and $x$. If a model\n  has multiple predictors, each of which are on vastly different\n  scales, then it is very difficult to assess which has the largest\n  effect on $y$ - since any differences in relative effects will be\n  masked by differences in their $x$ scales. For example, one\n  predictor might have a slope twice as large as another either\n  because its effect on $y$ is twice as much or because the scale of\n  its values is twice that of the other (or some combination of the\n  two reasons).\n- **enhances interpretation** - recall that the y-intercept is the\n  expected value of $y$ when $x$ is equal to zero. In many\n  applications, an x value of zero is outside the range of the sampled\n  data (as well as that of the population). For example, in the\n  example of bird body mass and its effect on clutch size, a bird body\n  mass of zero is not going to be within the domain of collectable\n  data. A bird that has no mass does not exist. In such cases, the\n  y-intercept has no practical interpretation.\n  \n  If however, the data are centered (or standardised), an $x$ value of\n  zero represents the mean value of $y$. Hence, the y-intercept is\n  then interpreted as the expected value of $y$ at the average $x$ -\n  now a meaningful interpretation.\n- **mitigates collinearity in multiplicative models** - when a model\n  contains multiple continuous predictors along with their\n  interactions, unless the data are centered (or standardised), the\n  main effects will be correlated to the interactions and thus\n  impossible to interpret correctly.\n\n# Ordinary Least Squares (OLS)\n\nThe following tabbed content will work through fitting OLS to each of\nthe example data sets. Only the first two example data sets (Example\n1 - Gaussian and Example 2 - categorical) satisfy the assumptions of\nOLS. The other examples are included primarily so that we can see\nwhat the model diagnostics look like when one or more assumptions are\nviolated.\n\nFor Example 1 - Gaussian, we will fit the model three ways (on raw\npredictor values, on centered predictor values and on standardised\npredictor values). The purpose of this is to illustrate how these\nchoices impact on the diagnostics and interpretation of the model. \n\n::: {.panel-tabset}\n\n## Example 1 (Gaussian data)\n\nThe Ordinary Least Squares (**OLS**) estimate of a **parameter** (e.g\nthe mean, $\\mu$) is the value of this parameter that minimize the sum\nof the square residuals (e.g. $(y_i-\\mu)^2$). That is, it minimize the\ntotal difference between the observed values ($x_i$) and those\nexpected ($\\mu$). \n\n:::: {.callout-note collapse=\"true\"}\n### Details about performing regression via long methods\nIn this section, I am bypassing the usually essential assumption\nchecking and diagnostic steps so as to focus on the underpinning\nmechanisms of parameter estimation.\n\n::::: {.panel-tabset}\n\n### Intercept via brute force method\n\nWe __could__ calculate the residual sum of squares\n(RSS) for a large number of combinations of potential parameter values\nin order to find the 'optimum' parameter values (those that minimize\nRSS).\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nmu <- seq(15,40,len=1000)\nrss <- vector('numeric', length(mu))\nfor (i in 1:length(mu)) {\n    rss[i] <- sum((dat$y - mu[i])^2)\n}\nmu[which(rss == min(rss))]\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n[1] 27.81281\n```\n\n\n:::\n\n```{.r .cell-code}\nggplot(data = NULL) + \ngeom_line(aes(y = rss, x = mu))\n```\n\n::: {.cell-output-display}\n![](30_glm_files/figure-html/olsSim-1.png){width=288}\n:::\n:::\n\n\n\nThis minimum is very close to that calculated with the simple formula (as\napplied with the `mean()` _function_).\n\n### Intercept via matrix algebra\n\nNow this is all fine and well, but what if we need to estimate multiple\nparameters.  Lets see how we could estimate the mean via matrix algebra as a\nstepping stone towards solving more complex problems.\n\nWe start by expressing the problem as a linear equation.\n\n$$\ny_i = \\beta_0 + \\varepsilon_i\n$$\n\nHere, we are saying that our observed values, can be considered to be equal to\nthe mean of the values plus the individual deviations (residuals) of each of the\nvalues from the mean.  Note, in the context of a linear model, this is just an\nintercept only model.\n\nRecall that the typical linear model might look like:\n\n$$\ny_i = \\beta_0 + \\beta_1 x_i + \\varepsilon_i\n$$\n\nWhich is the same as:\n$$\ny_i = \\beta_0\\times 1 + \\beta_1\\times x_i + \\varepsilon_i\n$$\n\nReturning to our intercept only model then:\n$$\ny_i = \\beta_0\\times 1 + \\varepsilon_i\n$$\n\nAnd in matrix form, this would be:\n$$\n\\underbrace{\\begin{bmatrix}\ny_1\\\\\ny_2\\\\\ny_3\\\\\n...\\\\\ny_n\n\\end{bmatrix}}_{Y} = \n\\underbrace{\\begin{bmatrix}\n1\\\\\n1\\\\\n1\\\\\n...\\\\\n1\n\\end{bmatrix}}_{\\boldsymbol{X}}\n\\underbrace{\\vphantom{\\begin{bmatrix}\ny_1\\\\\ny_2\\\\\ny_3\\\\\n...\\\\\ny_n\n\\end{bmatrix}}\\begin{bmatrix}\n\\beta_0\n\\end{bmatrix}}_{\\boldsymbol{\\beta}} + \n\\underbrace{\\begin{bmatrix}\n\\varepsilon_1\\\\\n\\varepsilon_2\\\\\n\\varepsilon_3\\\\\n...\\\\\n\\varepsilon_n\n\\end{bmatrix}}_{\\boldsymbol{\\varepsilon}}\n$$\n\n- $Y$ represents a column vector of the observed data\n- $\\boldsymbol{X}$ represents what is called the _model matrix_.  In this case,\n  that is just a single column matrix of 1s.  The ones indicate that there is an\n  intercept.  In matrix algebra, matrices are multiplied, so a column of ones\n  just ensures that the thing being multiplied does exist.\n- $\\boldsymbol{\\beta}$ represents a vector of parameters to be estimated.  In\n  this case, there is only one.\n- $\\boldsymbol{\\varepsilon}$ represents a column vector or residuals.  \n\nThis could all be summarised as:\n\n$$\nY = \\boldsymbol{X}\\boldsymbol{\\beta} + \\boldsymbol{\\varepsilon}\n$$\n\nIf we assume that the residuals ($\\varepsilon$) are (independently and identically\ndistributed, _iid_) all independently drawn from the same normal distribution\nwith a mean of 0 and a constant variance, then there is a rather elegant\nsolution for solving for $\\boldsymbol{\\beta}$.\n\nRecall that OLS estimates the value of the unknown parameters\n($\\boldsymbol{\\beta}$) as the values that minimize the sum of the squared\nresiduals.  So lets start by expressing the above equation in terms of\n$\\boldsymbol{\\varepsilon}$.\n\n$$\n\\boldsymbol{\\varepsilon} = Y - \\boldsymbol{X}\\boldsymbol{\\beta}\n$$\n\nVia matrix algebra, we can calulate the sum of square residuals as\n($\\boldsymbol{\\varepsilon}'\\boldsymbol{\\varepsilon}$), where  $\\boldsymbol{\\varepsilon}'$ is the transpose of $\\boldsymbol{\\varepsilon}$,\nso $\\boldsymbol{\\varepsilon}'\\boldsymbol{\\varepsilon}$ is just:\n\n$$\n\\begin{bmatrix}\n\\varepsilon_1 & \\varepsilon_2 & \\varepsilon_3 &...& \\varepsilon_n\n\\end{bmatrix}\n\\begin{bmatrix}\n\\varepsilon_1\\\\\n\\varepsilon_2\\\\\n\\varepsilon_3\\\\\n...\\\\\n\\varepsilon_n\\\\\n\\end{bmatrix} = \n\\begin{bmatrix}\n\\varepsilon_1\\times\\varepsilon_1 + \\varepsilon_2\\times\\varepsilon_2 + \\varepsilon_3\\times\\varepsilon_3 + ... + \\varepsilon_n\\times\\varepsilon_n\n\\end{bmatrix}\n$$\n\nBased on all this, we could re-write $\\boldsymbol{\\varepsilon}^T\\boldsymbol{\\varepsilon}$ as:\n\n$$\n\\boldsymbol{\\varepsilon}^T\\boldsymbol{\\varepsilon} = (Y - \\boldsymbol{X}\\boldsymbol{\\beta})^T(Y - \\boldsymbol{X}\\boldsymbol{\\beta})\n$$\n\nIf we then take the derivatives of the above with respect to\n$\\boldsymbol{\\beta}$, we will obtain the values of $\\boldsymbol{\\beta}$ that\nminimizes the sum of square residuals.\nAltimately, we arrive at:\n\n$$\n\\boldsymbol{\\beta} = \\underbrace{(\\boldsymbol{X}^T\\boldsymbol{X})^{-1}}_{\\frac{1}{n}} \\underbrace{\\boldsymbol{X}^T Y}_{\\sum^n_{i=1}y_i}\n$$\n\nwhere $(\\boldsymbol{X}^T\\boldsymbol{X})^{-1}$ is the inverse of\n$(\\boldsymbol{X}^T\\boldsymbol{X})$.  In matrix algebra, matrices are never\ndivided, only multiplied.  Therefore, to divide by\n$(\\boldsymbol{X}^T\\boldsymbol{X})$, it is necessary to multiply by the inverse of\n$(\\boldsymbol{X}^T\\boldsymbol{X})^{-1}$, in the same way that dividing by $n$ is\nthe same as multiplying by the inverse of $n$ which is of course $\\frac{1}{n}$.\n\nIn the above equation, we can see how the matrix form translates directly into\nthe simple calculation of a mean.  $(\\boldsymbol{X}^T\\boldsymbol{X})^{-1}$\nequates to $\\frac{1}{n}$ and $\\boldsymbol{X}^T Y$ equates to $\\sum^n_{i=1}y_i$.\n\nSo to estimate $\\boldsymbol{\\beta}$, all we have to do is perform the above\nmatrix multiplications.  Unfortunately, matrix inversion (e.g. calculating\n$(\\boldsymbol{X}^T\\boldsymbol{X})^{-1}$) is not always straight forward. _Note in\nthis case it is straight forward, because the matrix only has a single value_).\n\nIn order to be able to invert a matrix, the following must be satisfied:\n\n- the matrix must be square (have the same number of rows as columns)\n- be full rank, that is the number of independent columns (the _rank_) must be\n  equal to the number of columns.\n\nIf these are the case, then we can obtain the inverse by decomposing the square matrix into two parts:\n\n- the inverse (i.e. what we are after)\n- an identity matrix (a bi-product that is typically thrown away)\n\nIn R, this can be achieved via the `solve()` (or `qr.solve()`) _functions_.\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\n## Generate the single column matrix of 1s\nX <- cbind(rep(1,length(dat$y)))\n## perform the matrix multiplications to solve for beta\n## beta = (X'X)^-1 X'Y\nbeta <- solve(t(X) %*% X) %*% t(X) %*% dat$y\nbeta\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n       [,1]\n[1,] 27.811\n```\n\n\n:::\n:::\n\n\n\nThis is the same as the empirical mean we calculated for the brute force method.\n\n\n### Linear regression via matrix algebra\n\nRecall the motivating example 1 data as:\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\ndat\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n    x     y\n1   1  9.64\n2   2  3.79\n3   3 11.00\n4   4 27.88\n5   5 32.84\n6   6 32.56\n7   7 37.84\n8   8 29.86\n9   9 45.05\n10 10 47.65\n```\n\n\n:::\n:::\n\n\n\nSo the statistical model might be:\n\n$$\n\\begin{align}\ny_i =& \\beta_0 + \\beta_1 x_i + \\varepsilon_i\\\\\nY =& \\boldsymbol{X}\\boldsymbol{\\beta} + \\boldsymbol{\\varepsilon}\n\\end{align}\n$$\n\nwhich can be represented in matrix form as:\n\n$$\n\\begin{bmatrix}\n9.64\\\\\n3.79\\\\\n11\\\\\n...\\\\\n\\end{bmatrix} = \n\\underbrace{\\begin{bmatrix}\n1&1\\\\\n1&2\\\\\n1&3\\\\\n...\\\\\n\\end{bmatrix}}_{\\text{model matrix}}\n\\begin{bmatrix}\n\\beta_0\\\\\n\\beta_1\n\\end{bmatrix} + \n\\begin{bmatrix}\n\\varepsilon_1\\\\\n\\varepsilon_2\\\\\n\\varepsilon_3\\\\\n...\\\\\n\\end{bmatrix}\n$$\n\nSo, the response is represented by a vector and this is related to the _model matrix_ (a matrix representing the predictor(s)), a vector of parameters to\nestimate ($\\beta_0$: the intercept and $\\beta_1$: the slope) and a vector of\nresiduals (random noise).\n\nRecall that in order to estimate $\\boldsymbol{\\beta}$, we solve the following:\n                                   \n$$\n\\boldsymbol{\\beta} = (\\boldsymbol{X}^T\\boldsymbol{X})^{-1} \\boldsymbol{X}^T Y\n$$\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\n## Generate the model matrix\nX = model.matrix(~x, data=dat)\n## Solve for beta\nbeta = solve(t(X) %*% X) %*% t(X) %*% dat$y\nbeta\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n                [,1]\n(Intercept) 2.650667\nx           4.574606\n```\n\n\n:::\n:::\n\n\n:::::\n\n::::\n\n\n::::::: {.panel-tabset .nav-pills}\n\n## Raw predictor\n\n:::: {.panel-tabset}\n\n\n\n### Fit model via `lm()`\n\n$$\ny_i = \\beta_0+\\beta_1\\times x_i+\\varepsilon_i \\hspace{1cm}\\varepsilon_i\\sim{}\\mathcal{N}(0, \\sigma^2)\n$$\n\n\nThis whole process, can be more conveniently wrapped into a simple function within R called `lm()`. \n\n\n\n::: {.cell}\n\n```{.r .cell-code}\ndat.lm <- lm(y~x, data = dat)\ndat.lm\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n\nCall:\nlm(formula = y ~ x, data = dat)\n\nCoefficients:\n(Intercept)            x  \n      2.651        4.575  \n```\n\n\n:::\n:::\n\n\n\n### Model diagnostics\n\nHaving fit the model, it is vital that we review a range of regression\ndiagnostics so as to assess the goodness of fit of the model. This\nstep definitively confirms the model assumptions.\n\n\n::::: {.panel-tabset}\n\n### Autoplot\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\ndat.lm |> \n  autoplot(which = 1:6, ncol = 2, label.size = 3)\n```\n\n::: {.cell-output-display}\n![](30_glm_files/figure-html/lm_diagnostics1a-1.png){width=672}\n:::\n:::\n\n\n\nWhen supplied with a fitted linear model, the `autoplot()` function generates a\nset of standard diagnostic regression plots:\n\n- the top left plot is a residual plot: Ideally, there should not be\n  any patterns in the residual plot. Of particular concern would be if\n  there was a wedge (funnel) shape (indicative of unequal variances)\n  or some curved shape (indicative of having fit a linear trend\n  through non-linear data).\n- the top right plot is a Q-Q normal plot: This figure plots the\n  quantiles of the residuals against the quantiles that would be\n  expected if the data were drawn from a normal distribution. Ideally,\n  the points should be close to the dashed line. Deviations from this\n  line at the tails signify potential non-normality.\n- the middle left plot is a standardised residual plot. This has a\n  similar interpretation to the residual plot.\n- the middle right plot displays the cooks distance values associated\n  with each observation. Cook's distance is a measure of the influence\n  of each point on the estimated parameter values. This is a\n  combination of residuals (measure of outlierness along the y-axis)\n  and leverage (measure of outlierness along the x-axis). Essentially,\n  it estimates variations in regression coefficients after removing\n  each observation (one by one). Ideally, all the values should be\n  under 0.8. Numbers above the bars indicate the observation number -\n  this can be useful to identify which observations are influential.\n- the bottom left plot displays the trend between residuals and\n  leverage. In the event of large Cook's distance, this can help\n  identify whether the issues are due to residuals or leverage.\n- the bottom right plot displays the trend between Cook's distance and\n  leverage.\n  \n### Influence measures\n\nStatistical models assume that all observations have the same\ninfluence (weight) on the estimates. Outliers (unusually small or\nlarge observations) are problematic as they tend to have higher\ninfluence on estimates. They tend to \"pull\" the estimates (that is\nbias the estimates) towards themselves.\n\nThere are numerous measures of observation influence.\n\n- **residuals** - the deviations (along the y-axis) between observed\n  and expected values. Observations that have relatively large\n  residuals (an order of magnitude greater than the others) can be\n  viewed as potentially overly influential.\n- **leverage** - the deviations along the x-axis. That is, how unusual\n  is each predictor observation. For experimental designs, this is\n  usually not an issue since the observed values of predictors are\n  under the control of the experiment (we set what values of the\n  predictor we wish to explore a response to). However, for natural\n  experiments (e.g. surveys), the experimenter has less control over\n  the range of predictor values observed.\n- **Cook's distance** - this is a metric of influence that combines\n  together residuals and leverage. The values can range from 0\n  (typical influence) to 1 (highly influential). Values greater than\n  **0.8** should be viewed as overly influential and scrutinised further.\n\nCook's distance (`cook.d`) and leverage (`hat`) are displayed in\ntabular form.\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\ndat.lm |> influence.measures()\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nInfluence measures of\n\t lm(formula = y ~ x, data = dat) :\n\n    dfb.1_   dfb.x  dffit cov.r  cook.d   hat inf\n1   0.3312 -0.2802  0.332 1.881 0.06131 0.345   *\n2  -0.9249  0.7304 -0.945 0.905 0.36812 0.248    \n3  -0.4086  0.2881 -0.439 1.243 0.09745 0.176    \n4   0.3878 -0.2187  0.473 1.008 0.10468 0.127    \n5   0.2680 -0.0756  0.441 0.945 0.08939 0.103    \n6   0.0409  0.0231  0.135 1.393 0.01012 0.103    \n7   0.0000  0.0923  0.199 1.387 0.02186 0.127    \n8   0.2080 -0.5868 -0.894 0.672 0.29732 0.176    \n9  -0.0483  0.0954  0.123 1.715 0.00865 0.248    \n10  0.0505 -0.0855 -0.101 1.984 0.00586 0.345   *\n```\n\n\n:::\n\n```{.r .cell-code}\ndat.lm |> fortify()\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n       y  x      .hat   .sigma     .cooksd   .fitted     .resid  .stdresid\n1   9.64  1 0.3454545 6.522628 0.061314588  7.225273  2.4147273  0.4820270\n2   3.79  2 0.2484848 5.623285 0.368122762 11.799879 -8.0098788 -1.4922110\n3  11.00  3 0.1757576 6.229844 0.097452765 16.374485 -5.3744848 -0.9560542\n4  27.88  4 0.1272727 5.996167 0.104682723 20.949091  6.9309091  1.1981856\n5  32.84  5 0.1030303 5.940710 0.089394162 25.523697  7.3163030  1.2476017\n6  32.56  6 0.1030303 6.546155 0.010120337 30.098303  2.4616970  0.4197772\n7  37.84  7 0.1272727 6.494260 0.021858264 34.672909  3.1670909  0.5475130\n8  29.86  8 0.1757576 5.342608 0.297318395 39.247515 -9.3875152 -1.6699226\n9  45.05  9 0.2484848 6.597780 0.008650710 43.822121  1.2278788  0.2287493\n10 47.65 10 0.3454545 6.610265 0.005863429 48.396727 -0.7467273 -0.1490614\n```\n\n\n:::\n:::\n\n\n\nIn this case, no observations would be considered overly influential.\n\n### Performance model checking\n\n\nThe `performance` package provides a similar set of visual diagnostics:\n\n- the top left plot is a \"Posterior predictive plot\"\". This plot\n  features the density of the observed response (thick green line)\n  along with a collection of random realisations predicted from the\n  model. The point of this diagnostic is to see whether the\n  predictions are broadly consistent with the input data. If the\n  densities of realisations and observed data are not well aligned, it\n  might imply that the model is not a good fit.\n- the top right and middle left two plots are residual and standard\n  residual plots. Ideally, these should show no patterns in the\n  residuals\n- the middle right plot is an influence plot that plots residuals\n  against leverage with contours to help identify large Cook's D\n  values. Points should not fall outside the 0.8 contours (if\n  present).\n- the bottom left plot is a form of Q-Q plot that plots the distribution\n  (density) of the residuals from observed data (y-axis) against those\n  based on an exact normal (or other nominated) distribution. Ideally,\n  the points should all lay along the green horizontal line.\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\ndat.lm |> performance::check_model()\n```\n\n::: {.cell-output-display}\n![](30_glm_files/figure-html/validateModela1-1.png){width=768}\n:::\n\n```{.r .cell-code}\ndat.lm |> performance::check_outliers()\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nOK: No outliers detected.\n- Based on the following method and threshold: cook (0.8).\n- For variable: (Whole model)\n```\n\n\n:::\n:::\n\n\n\n**Conclusions**:\n\n- there are no alarming signs from any of the diagnostics\n\n### DHARMa (simulated) residuals\n\nAlthough an exploration of model residuals can provide important insights into\nthe goodness of fit and conformity of a model to the underlying assumptions,\ndiagnosing issues is a bit of a fine art.  This difficulty is exacerbated when\nthe residuals are being calculated from some models (e.g logistic regression\nmodels) where it is difficult to separate out nefarious patterns from the\nspecific patterns expected of the specific model.\n\nThe `DHARMa` package generates standardised residuals via simulation and uses\nthese as the basis of a range of tools to diagnose common modelling issues\nincluding outliers, heterogeneity, over-dispersion, autocorrelation.\n\nNew observations simulated from the fitted model are used to calculate a\ncumulative density function (CDF) that describes the probability profile of\neach observation. Thereafter, the residual of an observation is calculated as\nthe value of the CDF that corresponds to the actual observed value:\n\n- a value of 0 indicates that the observed value was less than all simulated values\n- a value of 1 indicates that the observed value was greater than all simulated values\n- a value of 0.5 indicates that have the observed value were greater than all\nsimulated values from a correctly specified model, these quantile residuals\nshould be uniformly distributed\n\nThis approach ensures that all residuals have the same interpretation\nirrespective of the model and distribution selected.\n\nExploring DHARMa residuals begins with running the `simulateResiduals()`\nfunction. If this is done with `plot=TRUE`, a pair of diagnostic plots with a\nrange of diagnostic tests will be provided as side effects.\n\n- the left hand plot is a Q-Q plot (ideally all points should be close\n  to the red line).\n  - the KS (Kolmogorov-Smirnov) test tests whether the (in this case\n    simulated) are likely to have been drawn from the nominated\n    distribution (in this case Gaussian).\n  - the Dispersion test tests whether the standard deviation of the\n    data is equal to that of the simulated data\n  - the Outlier test tests for the prevalence of outliers (when\n    observed values are outside the simulated range)\n- the right hand plot is a residual plot. Ideally, there should be no patterns\n  in the residuals. To help identify any patterns, quantile trends are\n  overlayed. Ideally, there should be a flat black line at each of the quantiles\n  of 0.25, 0.5 and 0.75.\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\ndat.resid <- dat.lm |> \n  simulateResiduals(plot = TRUE)\n```\n\n::: {.cell-output-display}\n![](30_glm_files/figure-html/validateModelb1-1.png){width=768}\n:::\n:::\n\n\n\nAlternatively, once the simulated residuals have been generated,\nindividual tests can be explored.\n\n- residuals.  This includes:\n\n  - a Q-Q plot (same as above)\n  - a plot of simulated dispersion values (histogram) as well as the\n    standardised observed dispersion (red line). Dispersion is the\n    ratio of variance to mean and on a non-standardized scale should\n    ideally be 1. Higher values indicate overdispersion. More about\n    this issue will be discussed later on in the tutorial. For the\n    plot, the red line should fall well within the range of the\n    underlying histogram. If the red line is off to the right, it\n    suggests that the model might be over-dispersed. If the red line\n    is to the left, it suggests under-dispersion.\n  - histogram of outliers. The red line (if present) indicates the\n    presence of outliers.\n \n  The figures are accompanied by formal statistical tests. These tests\n  should be reviewed, however, be aware that they are typically more\n  sensitive than the assumptions they seek to explore. So while it is\n  important to review them in order to identify potential issues,\n  significant tests need not be considered indicators of complete\n  model failure.\n  \n\n\n::: {.cell}\n\n```{.r .cell-code}\n## To run tests of KS (uniformity),  dispersion and outliers\ndat.resid |> testResiduals()\n```\n\n::: {.cell-output-display}\n![](30_glm_files/figure-html/validateModelb2-1.png){width=768}\n:::\n\n::: {.cell-output .cell-output-stdout}\n\n```\n$uniformity\n\n\tExact one-sample Kolmogorov-Smirnov test\n\ndata:  simulationOutput$scaledResiduals\nD = 0.152, p-value = 0.949\nalternative hypothesis: two-sided\n\n\n$dispersion\n\n\tDHARMa nonparametric dispersion test via sd of residuals fitted vs.\n\tsimulated\n\ndata:  simulationOutput\ndispersion = 0.90609, p-value = 0.952\nalternative hypothesis: two.sided\n\n\n$outliers\n\n\tDHARMa outlier test based on exact binomial test with approximate\n\texpectations\n\ndata:  simulationOutput\noutliers at both margin(s) = 0, observations = 10, p-value = 1\nalternative hypothesis: true probability of success is not equal to 0.007968127\n95 percent confidence interval:\n 0.0000000 0.3084971\nsample estimates:\nfrequency of outliers (expected: 0.00796812749003984 ) \n                                                     0 \n```\n\n\n:::\n\n::: {.cell-output .cell-output-stdout}\n\n```\n$uniformity\n\n\tExact one-sample Kolmogorov-Smirnov test\n\ndata:  simulationOutput$scaledResiduals\nD = 0.152, p-value = 0.949\nalternative hypothesis: two-sided\n\n\n$dispersion\n\n\tDHARMa nonparametric dispersion test via sd of residuals fitted vs.\n\tsimulated\n\ndata:  simulationOutput\ndispersion = 0.90609, p-value = 0.952\nalternative hypothesis: two.sided\n\n\n$outliers\n\n\tDHARMa outlier test based on exact binomial test with approximate\n\texpectations\n\ndata:  simulationOutput\noutliers at both margin(s) = 0, observations = 10, p-value = 1\nalternative hypothesis: true probability of success is not equal to 0.007968127\n95 percent confidence interval:\n 0.0000000 0.3084971\nsample estimates:\nfrequency of outliers (expected: 0.00796812749003984 ) \n                                                     0 \n```\n\n\n:::\n:::\n\n\n\n- uniformity\n\n\n::: {.cell}\n\n```{.r .cell-code}\ndat.resid |> testUniformity()\n```\n\n::: {.cell-output-display}\n![](30_glm_files/figure-html/validateModelb3-1.png){width=384}\n:::\n\n::: {.cell-output .cell-output-stdout}\n\n```\n\n\tExact one-sample Kolmogorov-Smirnov test\n\ndata:  simulationOutput$scaledResiduals\nD = 0.152, p-value = 0.949\nalternative hypothesis: two-sided\n```\n\n\n:::\n:::\n\n\n- dispersion\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\ndat.resid |> testDispersion()\n```\n\n::: {.cell-output-display}\n![](30_glm_files/figure-html/validateModelb4-1.png){width=384}\n:::\n\n::: {.cell-output .cell-output-stdout}\n\n```\n\n\tDHARMa nonparametric dispersion test via sd of residuals fitted vs.\n\tsimulated\n\ndata:  simulationOutput\ndispersion = 0.90609, p-value = 0.952\nalternative hypothesis: two.sided\n```\n\n\n:::\n:::\n\n\n- outliers\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\ndat.resid |> testOutliers()\n```\n\n::: {.cell-output-display}\n![](30_glm_files/figure-html/validateModelb5-1.png){width=384}\n:::\n\n::: {.cell-output .cell-output-stdout}\n\n```\n\n\tDHARMa outlier test based on exact binomial test with approximate\n\texpectations\n\ndata:  dat.resid\noutliers at both margin(s) = 0, observations = 10, p-value = 1\nalternative hypothesis: true probability of success is not equal to 0.007968127\n95 percent confidence interval:\n 0.0000000 0.3084971\nsample estimates:\nfrequency of outliers (expected: 0.00796812749003984 ) \n                                                     0 \n```\n\n\n:::\n:::\n\n\n- quantiles\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\ndat.resid |> testQuantiles()\n```\n\n::: {.cell-output-display}\n![](30_glm_files/figure-html/validateModelb6-1.png){width=384}\n:::\n\n::: {.cell-output .cell-output-stdout}\n\n```\n\n\tTest for location of quantiles via qgam\n\ndata:  simulationOutput\np-value = 0.8891\nalternative hypothesis: both\n```\n\n\n:::\n\n```{.r .cell-code}\n## The above fits quantile gams at 0.25,  0.5 and 0.75\n## testSpatialAutocorrelation(fert.resid,  x=,  y=) # needs x and y coordinates\n## testTemporalAutocorrelation(fert.resid,  time=) # needs time\n```\n:::\n\n\n\n:::::\n\n### Summarise model\n\nSince the diagnostics do not reveal any issues, we are free to explore\nthe model summaries\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\ndat.lm |> summary()\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n\nCall:\nlm(formula = y ~ x, data = dat)\n\nResiduals:\n   Min     1Q Median     3Q    Max \n-9.387 -4.218  1.821  2.991  7.316 \n\nCoefficients:\n            Estimate Std. Error t value Pr(>|t|)    \n(Intercept)   2.6507     4.2299   0.627 0.548349    \nx             4.5746     0.6817   6.710 0.000151 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 6.192 on 8 degrees of freedom\nMultiple R-squared:  0.8491,\tAdjusted R-squared:  0.8303 \nF-statistic: 45.03 on 1 and 8 DF,  p-value: 0.0001511\n```\n\n\n:::\n\n```{.r .cell-code}\ndat.lm |> confint()\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n                2.5 %    97.5 %\n(Intercept) -7.103503 12.404836\nx            3.002579  6.146633\n```\n\n\n:::\n:::\n\n\n\n**Interpretation**:\n\n- when $x=0$, $y$ is expected to be 2.651 (the y-intercept).\n- for every one unit change in $x$, the expected value of $y$\n  increases by 4.575 (the slope)\n- the slope could be as low as 3.003 or as high as \n  6.147 (95% confidence interval of the slope)\n- as the above interval does not include the value of 0, the linear\n  relationship (slope) can be considered significant\n- we would reject the null hypothesis of no relationship (p-value for\n  slope is less than 0.05)\n- 84.914% of the variance in $y$ is\n  explained by its linear relationship with $x$ (R squared value)\n\n::::\n\n## Centered predictor\n\n:::: {.panel-tabset}\n\n\n### Fit model via `lm()`\n\n$$\ny_i = \\beta_0+\\beta_1\\times (x_i - \\bar{x}) +\\varepsilon_i \\hspace{1cm}\\varepsilon_i\\sim{}\\mathcal{N}(0, \\sigma^2)\n$$\n\n\nThis whole process, can be more conveniently wrapped into a simple function within R called `lm()`. \n\n\n\n::: {.cell}\n\n```{.r .cell-code}\ndat1b.lm <- lm(y ~ scale(x, scale = FALSE), data = dat)\ndat1b.lm\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n\nCall:\nlm(formula = y ~ scale(x, scale = FALSE), data = dat)\n\nCoefficients:\n            (Intercept)  scale(x, scale = FALSE)  \n                 27.811                    4.575  \n```\n\n\n:::\n:::\n\n\n\n### Model diagnostics\n\nHaving fit the model, it is vital that we review a range of regression\ndiagnostics so as to assess the goodness of fit of the model. This\nstep definitively confirms the model assumptions.\n\n\n::::: {.panel-tabset}\n\n### Autoplot\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\ndat1b.lm |> \n  autoplot(which = 1:6, ncol = 2, label.size = 3)\n```\n\n::: {.cell-output-display}\n![](30_glm_files/figure-html/lm_diagnostics1b-1.png){width=672}\n:::\n:::\n\n\n\nWhen supplied with a fitted linear model, the `autoplot()` function generates a\nset of standard diagnostic regression plots:\n\n- the top left plot is a residual plot: Ideally, there should not be\n  any patterns in the residual plot. Of particular concern would be if\n  there was a wedge (funnel) shape (indicative of unequal variances)\n  or some curved shape (indicative of having fit a linear trend\n  through non-linear data).\n- the top right plot is a Q-Q normal plot: This figure plots the\n  quantiles of the residuals against the quantiles that would be\n  expected if the data were drawn from a normal distribution. Ideally,\n  the points should be close to the dashed line. Deviations from this\n  line at the tails signify potential non-normality.\n- the middle left plot is a standardised residual plot. This has a\n  similar interpretation to the residual plot.\n- the middle right plot displays the cooks distance values associated\n  with each observation. Cook's distance is a measure of the influence\n  of each point on the estimated parameter values. This is a\n  combination of residuals (measure of outlierness along the y-axis)\n  and leverage (measure of outlierness along the x-axis). Essentially,\n  it estimates variations in regression coefficients after removing\n  each observation (one by one). Ideally, all the values should be\n  under 0.8. Numbers above the bars indicate the observation number -\n  this can be useful to identify which observations are influential.\n- the bottom left plot displays the trend between residuals and\n  leverage. In the event of large Cook's distance, this can help\n  identify whether the issues are due to residuals or leverage.\n- the bottom right plot displays the trend between Cook's distance and\n  leverage.\n  \n### Influence measures\n\nStatistical models assume that all observations have the same\ninfluence (weight) on the estimates. Outliers (unusually small or\nlarge observations) are problematic as they tend to have higher\ninfluence on estimates. They tend to \"pull\" the estimates (that is\nbias the estimates) towards themselves.\n\nThere are numerous measures of observation influence.\n\n- **residuals** - the deviations (along the y-axis) between observed\n  and expected values. Observations that have relatively large\n  residuals (an order of magnitude greater than the others) can be\n  viewed as potentially overly influential.\n- **leverage** - the deviations along the x-axis. That is, how unusual\n  is each predictor observation. For experimental designs, this is\n  usually not an issue since the observed values of predictors are\n  under the control of the experiment (we set what values of the\n  predictor we wish to explore a response to). However, for natural\n  experiments (e.g. surveys), the experimenter has less control over\n  the range of predictor values observed.\n- **Cook's distance** - this is a metric of influence that combines\n  together residuals and leverage. The values can range from 0\n  (typical influence) to 1 (highly influential). Values greater than\n  **0.8** should be viewed as overly influential and scrutinised further.\n\nCook's distance (`cook.d`) and leverage (`hat`) are displayed in\ntabular form.\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\ndat1b.lm |> influence.measures()\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nInfluence measures of\n\t lm(formula = y ~ scale(x, scale = FALSE), data = dat) :\n\n    dfb.1_ dfb.ss.F  dffit cov.r  cook.d   hat inf\n1   0.1789  -0.2802  0.332 1.881 0.06131 0.345   *\n2  -0.5994   0.7304 -0.945 0.905 0.36812 0.248    \n3  -0.3310   0.2881 -0.439 1.243 0.09745 0.176    \n4   0.4188  -0.2187  0.473 1.008 0.10468 0.127    \n5   0.4342  -0.0756  0.441 0.945 0.08939 0.103    \n6   0.1326   0.0231  0.135 1.393 0.01012 0.103    \n7   0.1767   0.0923  0.199 1.387 0.02186 0.127    \n8  -0.6741  -0.5868 -0.894 0.672 0.29732 0.176    \n9   0.0783   0.0954  0.123 1.715 0.00865 0.248    \n10 -0.0546  -0.0855 -0.101 1.984 0.00586 0.345   *\n```\n\n\n:::\n\n```{.r .cell-code}\ndat1b.lm |> fortify()\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n       y scale(x, scale = FALSE)      .hat   .sigma     .cooksd   .fitted\n1   9.64                    -4.5 0.3454545 6.522628 0.061314588  7.225273\n2   3.79                    -3.5 0.2484848 5.623285 0.368122762 11.799879\n3  11.00                    -2.5 0.1757576 6.229844 0.097452765 16.374485\n4  27.88                    -1.5 0.1272727 5.996167 0.104682723 20.949091\n5  32.84                    -0.5 0.1030303 5.940710 0.089394162 25.523697\n6  32.56                     0.5 0.1030303 6.546155 0.010120337 30.098303\n7  37.84                     1.5 0.1272727 6.494260 0.021858264 34.672909\n8  29.86                     2.5 0.1757576 5.342608 0.297318395 39.247515\n9  45.05                     3.5 0.2484848 6.597780 0.008650710 43.822121\n10 47.65                     4.5 0.3454545 6.610265 0.005863429 48.396727\n       .resid  .stdresid\n1   2.4147273  0.4820270\n2  -8.0098788 -1.4922110\n3  -5.3744848 -0.9560542\n4   6.9309091  1.1981856\n5   7.3163030  1.2476017\n6   2.4616970  0.4197772\n7   3.1670909  0.5475130\n8  -9.3875152 -1.6699226\n9   1.2278788  0.2287493\n10 -0.7467273 -0.1490614\n```\n\n\n:::\n:::\n\n\n\nIn this case, no observations would be considered overly influential.\n\n### Performance model checking\n\n\nThe `performance` package provides a similar set of visual diagnostics:\n\n- the top left plot is a \"Posterior predictive plot\"\". This plot\n  features the density of the observed response (thick green line)\n  along with a collection of random realisations predicted from the\n  model. The point of this diagnostic is to see whether the\n  predictions are broadly consistent with the input data. If the\n  densities of realisations and observed data are not well aligned, it\n  might imply that the model is not a good fit.\n- the top right and middle left two plots are residual and standard\n  residual plots. Ideally, these should show no patterns in the\n  residuals\n- the middle right plot is an influence plot that plots residuals\n  against leverage with contours to help identify large Cook's D\n  values. Points should not fall outside the 0.8 contours (if\n  present).\n- the bottom left plot is a form of Q-Q plot that plots the distribution\n  (density) of the residuals from observed data (y-axis) against those\n  based on an exact normal (or other nominated) distribution. Ideally,\n  the points should all lay along the green horizontal line.\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\ndat1b.lm |> performance::check_model()\n```\n\n::: {.cell-output-display}\n![](30_glm_files/figure-html/validateModela1b-1.png){width=768}\n:::\n\n```{.r .cell-code}\ndat1b.lm |> performance::check_outliers()\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nOK: No outliers detected.\n- Based on the following method and threshold: cook (0.8).\n- For variable: (Whole model)\n```\n\n\n:::\n:::\n\n\n\n**Conclusions**:\n\n- there are no alarming signs from any of the diagnostics\n\n### DHARMa (simulated) residuals\n\nAlthough an exploration of model residuals can provide important insights into\nthe goodness of fit and conformity of a model to the underlying assumptions,\ndiagnosing issues is a bit of a fine art.  This difficulty is exacerbated when\nthe residuals are being calculated from some models (e.g logistic regression\nmodels) where it is difficult to separate out nefarious patterns from the\nspecific patterns expected of the specific model.\n\nThe `DHARMa` package generates standardised residuals via simulation and uses\nthese as the basis of a range of tools to diagnose common modelling issues\nincluding outliers, heterogeneity, over-dispersion, autocorrelation.\n\nNew observations simulated from the fitted model are used to calculate a\ncumulative density function (CDF) that describes the probability profile of\neach observation. Thereafter, the residual of an observation is calculated as\nthe value of the CDF that corresponds to the actual observed value:\n\n- a value of 0 indicates that the observed value was less than all simulated values\n- a value of 1 indicates that the observed value was greater than all simulated values\n- a value of 0.5 indicates that have the observed value were greater than all\nsimulated values from a correctly specified model, these quantile residuals\nshould be uniformly distributed\n\nThis approach ensures that all residuals have the same interpretation\nirrespective of the model and distribution selected.\n\nExploring DHARMa residuals begins with running the `simulateResiduals()`\nfunction. If this is done with `plot=TRUE`, a pair of diagnostic plots with a\nrange of diagnostic tests will be provided as side effects.\n\n- the left hand plot is a Q-Q plot (ideally all points should be close\n  to the red line).\n  - the KS (Kolmogorov-Smirnov) test tests whether the (in this case\n    simulated) are likely to have been drawn from the nominated\n    distribution (in this case Gaussian).\n  - the Dispersion test tests whether the standard deviation of the\n    data is equal to that of the simulated data\n  - the Outlier test tests for the prevalence of outliers (when\n    observed values are outside the simulated range)\n- the right hand plot is a residual plot. Ideally, there should be no patterns\n  in the residuals. To help identify any patterns, quantile trends are\n  overlayed. Ideally, there should be a flat black line at each of the quantiles\n  of 0.25, 0.5 and 0.75.\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\ndat.resid <- dat1b.lm |> \n  simulateResiduals(plot = TRUE)\n```\n\n::: {.cell-output-display}\n![](30_glm_files/figure-html/validateModelb1b-1.png){width=768}\n:::\n:::\n\n\n\nAlternatively, once the simulated residuals have been generated,\nindividual tests can be explored.\n\n- residuals.  This includes:\n\n  - a Q-Q plot (same as above)\n  - a plot of simulated dispersion values (histogram) as well as the\n    standardised observed dispersion (red line). Dispersion is the\n    ratio of variance to mean and on a non-standardized scale should\n    ideally be 1. Higher values indicate overdispersion. More about\n    this issue will be discussed later on in the tutorial. For the\n    plot, the red line should fall well within the range of the\n    underlying histogram. If the red line is off to the right, it\n    suggests that the model might be over-dispersed. If the red line\n    is to the left, it suggests under-dispersion.\n  - histogram of outliers. The red line (if present) indicates the\n    presence of outliers.\n \n  The figures are accompanied by formal statistical tests. These tests\n  should be reviewed, however, be aware that they are typically more\n  sensitive than the assumptions they seek to explore. So while it is\n  important to review them in order to identify potential issues,\n  significant tests need not be considered indicators of complete\n  model failure.\n  \n\n\n::: {.cell}\n\n```{.r .cell-code}\n## To run tests of KS (uniformity),  dispersion and outliers\ndat.resid |> testResiduals()\n```\n\n::: {.cell-output-display}\n![](30_glm_files/figure-html/validateModelb2b-1.png){width=768}\n:::\n\n::: {.cell-output .cell-output-stdout}\n\n```\n$uniformity\n\n\tExact one-sample Kolmogorov-Smirnov test\n\ndata:  simulationOutput$scaledResiduals\nD = 0.152, p-value = 0.949\nalternative hypothesis: two-sided\n\n\n$dispersion\n\n\tDHARMa nonparametric dispersion test via sd of residuals fitted vs.\n\tsimulated\n\ndata:  simulationOutput\ndispersion = 0.90609, p-value = 0.952\nalternative hypothesis: two.sided\n\n\n$outliers\n\n\tDHARMa outlier test based on exact binomial test with approximate\n\texpectations\n\ndata:  simulationOutput\noutliers at both margin(s) = 0, observations = 10, p-value = 1\nalternative hypothesis: true probability of success is not equal to 0.007968127\n95 percent confidence interval:\n 0.0000000 0.3084971\nsample estimates:\nfrequency of outliers (expected: 0.00796812749003984 ) \n                                                     0 \n```\n\n\n:::\n\n::: {.cell-output .cell-output-stdout}\n\n```\n$uniformity\n\n\tExact one-sample Kolmogorov-Smirnov test\n\ndata:  simulationOutput$scaledResiduals\nD = 0.152, p-value = 0.949\nalternative hypothesis: two-sided\n\n\n$dispersion\n\n\tDHARMa nonparametric dispersion test via sd of residuals fitted vs.\n\tsimulated\n\ndata:  simulationOutput\ndispersion = 0.90609, p-value = 0.952\nalternative hypothesis: two.sided\n\n\n$outliers\n\n\tDHARMa outlier test based on exact binomial test with approximate\n\texpectations\n\ndata:  simulationOutput\noutliers at both margin(s) = 0, observations = 10, p-value = 1\nalternative hypothesis: true probability of success is not equal to 0.007968127\n95 percent confidence interval:\n 0.0000000 0.3084971\nsample estimates:\nfrequency of outliers (expected: 0.00796812749003984 ) \n                                                     0 \n```\n\n\n:::\n:::\n\n\n\n- uniformity\n\n\n::: {.cell}\n\n```{.r .cell-code}\ndat.resid |> testUniformity()\n```\n\n::: {.cell-output-display}\n![](30_glm_files/figure-html/validateModelb3b-1.png){width=384}\n:::\n\n::: {.cell-output .cell-output-stdout}\n\n```\n\n\tExact one-sample Kolmogorov-Smirnov test\n\ndata:  simulationOutput$scaledResiduals\nD = 0.152, p-value = 0.949\nalternative hypothesis: two-sided\n```\n\n\n:::\n:::\n\n\n- dispersion\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\ndat.resid |> testDispersion()\n```\n\n::: {.cell-output-display}\n![](30_glm_files/figure-html/validateModelb4b-1.png){width=384}\n:::\n\n::: {.cell-output .cell-output-stdout}\n\n```\n\n\tDHARMa nonparametric dispersion test via sd of residuals fitted vs.\n\tsimulated\n\ndata:  simulationOutput\ndispersion = 0.90609, p-value = 0.952\nalternative hypothesis: two.sided\n```\n\n\n:::\n:::\n\n\n- outliers\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\ndat.resid |> testOutliers()\n```\n\n::: {.cell-output-display}\n![](30_glm_files/figure-html/validateModelb5b-1.png){width=384}\n:::\n\n::: {.cell-output .cell-output-stdout}\n\n```\n\n\tDHARMa outlier test based on exact binomial test with approximate\n\texpectations\n\ndata:  dat.resid\noutliers at both margin(s) = 0, observations = 10, p-value = 1\nalternative hypothesis: true probability of success is not equal to 0.007968127\n95 percent confidence interval:\n 0.0000000 0.3084971\nsample estimates:\nfrequency of outliers (expected: 0.00796812749003984 ) \n                                                     0 \n```\n\n\n:::\n:::\n\n\n- quantiles\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\ndat.resid |> testQuantiles()\n```\n\n::: {.cell-output-display}\n![](30_glm_files/figure-html/validateModelb6b-1.png){width=384}\n:::\n\n::: {.cell-output .cell-output-stdout}\n\n```\n\n\tTest for location of quantiles via qgam\n\ndata:  simulationOutput\np-value = 0.8891\nalternative hypothesis: both\n```\n\n\n:::\n\n```{.r .cell-code}\n## The above fits quantile gams at 0.25,  0.5 and 0.75\n## testSpatialAutocorrelation(fert.resid,  x=,  y=) # needs x and y coordinates\n## testTemporalAutocorrelation(fert.resid,  time=) # needs time\n```\n:::\n\n\n\n:::::\n\n### Summarise model\n\nSince the diagnostics do not reveal any issues, we are free to explore\nthe model summaries\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\ndat1b.lm |> summary()\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n\nCall:\nlm(formula = y ~ scale(x, scale = FALSE), data = dat)\n\nResiduals:\n   Min     1Q Median     3Q    Max \n-9.387 -4.218  1.821  2.991  7.316 \n\nCoefficients:\n                        Estimate Std. Error t value Pr(>|t|)    \n(Intercept)              27.8110     1.9581   14.20 5.88e-07 ***\nscale(x, scale = FALSE)   4.5746     0.6817    6.71 0.000151 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 6.192 on 8 degrees of freedom\nMultiple R-squared:  0.8491,\tAdjusted R-squared:  0.8303 \nF-statistic: 45.03 on 1 and 8 DF,  p-value: 0.0001511\n```\n\n\n:::\n\n```{.r .cell-code}\ndat1b.lm |> confint()\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n                            2.5 %    97.5 %\n(Intercept)             23.295697 32.326303\nscale(x, scale = FALSE)  3.002579  6.146633\n```\n\n\n:::\n:::\n\n\n\n**Interpretation**:\n\n- when $x=0$ (e.g. the average $x$ value since centered), $y$ is\n  expected to be 27.811 (the y-intercept).\n- for every one unit change in $x$, the expected value of $y$\n  increases by 4.575 (the slope)\n- the slope could be as low as 3.003 or as high as \n  6.147 (95% confidence interval of the slope)\n- as the above interval does not include the value of 0, the linear\n  relationship (slope) can be considered significant\n- we would reject the null hypothesis of no relationship (p-value for\n  slope is less than 0.05)\n- 84.914% of the variance in $y$ is\n  explained by its linear relationship with $x$ (R squared value)\n\n::::\n\n## Standardised predictor\n\n:::: {.panel-tabset}\n\n\n### Fit model via `lm()`\n\n$$\ny_i = \\beta_0+\\beta_1\\times (x_i - \\bar{x})/\\sigma_{x} +\\varepsilon_i \\hspace{1cm}\\varepsilon_i\\sim{}\\mathcal{N}(0, \\sigma^2)\n$$\n\n\nThis whole process, can be more conveniently wrapped into a simple function within R called `lm()`. \n\n\n\n::: {.cell}\n\n```{.r .cell-code}\ndat1c.lm <- lm(y ~ scale(x), data = dat)\ndat1c.lm\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n\nCall:\nlm(formula = y ~ scale(x), data = dat)\n\nCoefficients:\n(Intercept)     scale(x)  \n      27.81        13.85  \n```\n\n\n:::\n:::\n\n\n\n### Model diagnostics\n\nHaving fit the model, it is vital that we review a range of regression\ndiagnostics so as to assess the goodness of fit of the model. This\nstep definitively confirms the model assumptions.\n\n\n::::: {.panel-tabset}\n\n### Autoplot\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\ndat1c.lm |> \n  autoplot(which = 1:6, ncol = 2, label.size = 3)\n```\n\n::: {.cell-output-display}\n![](30_glm_files/figure-html/lm_diagnostics1c-1.png){width=672}\n:::\n:::\n\n\n\nWhen supplied with a fitted linear model, the `autoplot()` function generates a\nset of standard diagnostic regression plots:\n\n- the top left plot is a residual plot: Ideally, there should not be\n  any patterns in the residual plot. Of particular concern would be if\n  there was a wedge (funnel) shape (indicative of unequal variances)\n  or some curved shape (indicative of having fit a linear trend\n  through non-linear data).\n- the top right plot is a Q-Q normal plot: This figure plots the\n  quantiles of the residuals against the quantiles that would be\n  expected if the data were drawn from a normal distribution. Ideally,\n  the points should be close to the dashed line. Deviations from this\n  line at the tails signify potential non-normality.\n- the middle left plot is a standardised residual plot. This has a\n  similar interpretation to the residual plot.\n- the middle right plot displays the cooks distance values associated\n  with each observation. Cook's distance is a measure of the influence\n  of each point on the estimated parameter values. This is a\n  combination of residuals (measure of outlierness along the y-axis)\n  and leverage (measure of outlierness along the x-axis). Essentially,\n  it estimates variations in regression coefficients after removing\n  each observation (one by one). Ideally, all the values should be\n  under 0.8. Numbers above the bars indicate the observation number -\n  this can be useful to identify which observations are influential.\n- the bottom left plot displays the trend between residuals and\n  leverage. In the event of large Cook's distance, this can help\n  identify whether the issues are due to residuals or leverage.\n- the bottom right plot displays the trend between Cook's distance and\n  leverage.\n  \n### Influence measures\n\nStatistical models assume that all observations have the same\ninfluence (weight) on the estimates. Outliers (unusually small or\nlarge observations) are problematic as they tend to have higher\ninfluence on estimates. They tend to \"pull\" the estimates (that is\nbias the estimates) towards themselves.\n\nThere are numerous measures of observation influence.\n\n- **residuals** - the deviations (along the y-axis) between observed\n  and expected values. Observations that have relatively large\n  residuals (an order of magnitude greater than the others) can be\n  viewed as potentially overly influential.\n- **leverage** - the deviations along the x-axis. That is, how unusual\n  is each predictor observation. For experimental designs, this is\n  usually not an issue since the observed values of predictors are\n  under the control of the experiment (we set what values of the\n  predictor we wish to explore a response to). However, for natural\n  experiments (e.g. surveys), the experimenter has less control over\n  the range of predictor values observed.\n- **Cook's distance** - this is a metric of influence that combines\n  together residuals and leverage. The values can range from 0\n  (typical influence) to 1 (highly influential). Values greater than\n  **0.8** should be viewed as overly influential and scrutinised further.\n\nCook's distance (`cook.d`) and leverage (`hat`) are displayed in\ntabular form.\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\ndat1c.lm |> influence.measures()\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nInfluence measures of\n\t lm(formula = y ~ scale(x), data = dat) :\n\n    dfb.1_ dfb.sc..  dffit cov.r  cook.d   hat inf\n1   0.1789  -0.2802  0.332 1.881 0.06131 0.345   *\n2  -0.5994   0.7304 -0.945 0.905 0.36812 0.248    \n3  -0.3310   0.2881 -0.439 1.243 0.09745 0.176    \n4   0.4188  -0.2187  0.473 1.008 0.10468 0.127    \n5   0.4342  -0.0756  0.441 0.945 0.08939 0.103    \n6   0.1326   0.0231  0.135 1.393 0.01012 0.103    \n7   0.1767   0.0923  0.199 1.387 0.02186 0.127    \n8  -0.6741  -0.5868 -0.894 0.672 0.29732 0.176    \n9   0.0783   0.0954  0.123 1.715 0.00865 0.248    \n10 -0.0546  -0.0855 -0.101 1.984 0.00586 0.345   *\n```\n\n\n:::\n\n```{.r .cell-code}\ndat1c.lm |> fortify()\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n       y   scale(x)      .hat   .sigma     .cooksd   .fitted     .resid\n1   9.64 -1.4863011 0.3454545 6.522628 0.061314588  7.225273  2.4147273\n2   3.79 -1.1560120 0.2484848 5.623285 0.368122762 11.799879 -8.0098788\n3  11.00 -0.8257228 0.1757576 6.229844 0.097452765 16.374485 -5.3744848\n4  27.88 -0.4954337 0.1272727 5.996167 0.104682723 20.949091  6.9309091\n5  32.84 -0.1651446 0.1030303 5.940710 0.089394162 25.523697  7.3163030\n6  32.56  0.1651446 0.1030303 6.546155 0.010120337 30.098303  2.4616970\n7  37.84  0.4954337 0.1272727 6.494260 0.021858264 34.672909  3.1670909\n8  29.86  0.8257228 0.1757576 5.342608 0.297318395 39.247515 -9.3875152\n9  45.05  1.1560120 0.2484848 6.597780 0.008650710 43.822121  1.2278788\n10 47.65  1.4863011 0.3454545 6.610265 0.005863429 48.396727 -0.7467273\n    .stdresid\n1   0.4820270\n2  -1.4922110\n3  -0.9560542\n4   1.1981856\n5   1.2476017\n6   0.4197772\n7   0.5475130\n8  -1.6699226\n9   0.2287493\n10 -0.1490614\n```\n\n\n:::\n:::\n\n\n\nIn this case, no observations would be considered overly influential.\n\n### Performance model checking\n\n\nThe `performance` package provides a similar set of visual diagnostics:\n\n- the top left plot is a \"Posterior predictive plot\"\". This plot\n  features the density of the observed response (thick green line)\n  along with a collection of random realisations predicted from the\n  model. The point of this diagnostic is to see whether the\n  predictions are broadly consistent with the input data. If the\n  densities of realisations and observed data are not well aligned, it\n  might imply that the model is not a good fit.\n- the top right and middle left two plots are residual and standard\n  residual plots. Ideally, these should show no patterns in the\n  residuals\n- the middle right plot is an influence plot that plots residuals\n  against leverage with contours to help identify large Cook's D\n  values. Points should not fall outside the 0.8 contours (if\n  present).\n- the bottom left plot is a form of Q-Q plot that plots the distribution\n  (density) of the residuals from observed data (y-axis) against those\n  based on an exact normal (or other nominated) distribution. Ideally,\n  the points should all lay along the green horizontal line.\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\ndat1c.lm |> performance::check_model()\n```\n\n::: {.cell-output-display}\n![](30_glm_files/figure-html/validateModela1c-1.png){width=768}\n:::\n\n```{.r .cell-code}\ndat1c.lm |> performance::check_outliers()\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nOK: No outliers detected.\n- Based on the following method and threshold: cook (0.8).\n- For variable: (Whole model)\n```\n\n\n:::\n:::\n\n\n\n**Conclusions**:\n\n- there are no alarming signs from any of the diagnostics\n\n### DHARMa (simulated) residuals\n\nAlthough an exploration of model residuals can provide important insights into\nthe goodness of fit and conformity of a model to the underlying assumptions,\ndiagnosing issues is a bit of a fine art.  This difficulty is exacerbated when\nthe residuals are being calculated from some models (e.g logistic regression\nmodels) where it is difficult to separate out nefarious patterns from the\nspecific patterns expected of the specific model.\n\nThe `DHARMa` package generates standardised residuals via simulation and uses\nthese as the basis of a range of tools to diagnose common modelling issues\nincluding outliers, heterogeneity, over-dispersion, autocorrelation.\n\nNew observations simulated from the fitted model are used to calculate a\ncumulative density function (CDF) that describes the probability profile of\neach observation. Thereafter, the residual of an observation is calculated as\nthe value of the CDF that corresponds to the actual observed value:\n\n- a value of 0 indicates that the observed value was less than all simulated values\n- a value of 1 indicates that the observed value was greater than all simulated values\n- a value of 0.5 indicates that have the observed value were greater than all\nsimulated values from a correctly specified model, these quantile residuals\nshould be uniformly distributed\n\nThis approach ensures that all residuals have the same interpretation\nirrespective of the model and distribution selected.\n\nExploring DHARMa residuals begins with running the `simulateResiduals()`\nfunction. If this is done with `plot=TRUE`, a pair of diagnostic plots with a\nrange of diagnostic tests will be provided as side effects.\n\n- the left hand plot is a Q-Q plot (ideally all points should be close\n  to the red line).\n  - the KS (Kolmogorov-Smirnov) test tests whether the (in this case\n    simulated) are likely to have been drawn from the nominated\n    distribution (in this case Gaussian).\n  - the Dispersion test tests whether the standard deviation of the\n    data is equal to that of the simulated data\n  - the Outlier test tests for the prevalence of outliers (when\n    observed values are outside the simulated range)\n- the right hand plot is a residual plot. Ideally, there should be no patterns\n  in the residuals. To help identify any patterns, quantile trends are\n  overlayed. Ideally, there should be a flat black line at each of the quantiles\n  of 0.25, 0.5 and 0.75.\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\ndat.resid <- dat1c.lm |> \n  simulateResiduals(plot = TRUE)\n```\n\n::: {.cell-output-display}\n![](30_glm_files/figure-html/validateModelb1c-1.png){width=768}\n:::\n:::\n\n\n\nAlternatively, once the simulated residuals have been generated,\nindividual tests can be explored.\n\n- residuals.  This includes:\n\n  - a Q-Q plot (same as above)\n  - a plot of simulated dispersion values (histogram) as well as the\n    standardised observed dispersion (red line). Dispersion is the\n    ratio of variance to mean and on a non-standardized scale should\n    ideally be 1. Higher values indicate overdispersion. More about\n    this issue will be discussed later on in the tutorial. For the\n    plot, the red line should fall well within the range of the\n    underlying histogram. If the red line is off to the right, it\n    suggests that the model might be over-dispersed. If the red line\n    is to the left, it suggests under-dispersion.\n  - histogram of outliers. The red line (if present) indicates the\n    presence of outliers.\n \n  The figures are accompanied by formal statistical tests. These tests\n  should be reviewed, however, be aware that they are typically more\n  sensitive than the assumptions they seek to explore. So while it is\n  important to review them in order to identify potential issues,\n  significant tests need not be considered indicators of complete\n  model failure.\n  \n\n\n::: {.cell}\n\n```{.r .cell-code}\n## To run tests of KS (uniformity),  dispersion and outliers\ndat.resid |> testResiduals()\n```\n\n::: {.cell-output-display}\n![](30_glm_files/figure-html/validateModelb2c-1.png){width=768}\n:::\n\n::: {.cell-output .cell-output-stdout}\n\n```\n$uniformity\n\n\tExact one-sample Kolmogorov-Smirnov test\n\ndata:  simulationOutput$scaledResiduals\nD = 0.152, p-value = 0.949\nalternative hypothesis: two-sided\n\n\n$dispersion\n\n\tDHARMa nonparametric dispersion test via sd of residuals fitted vs.\n\tsimulated\n\ndata:  simulationOutput\ndispersion = 0.90609, p-value = 0.952\nalternative hypothesis: two.sided\n\n\n$outliers\n\n\tDHARMa outlier test based on exact binomial test with approximate\n\texpectations\n\ndata:  simulationOutput\noutliers at both margin(s) = 0, observations = 10, p-value = 1\nalternative hypothesis: true probability of success is not equal to 0.007968127\n95 percent confidence interval:\n 0.0000000 0.3084971\nsample estimates:\nfrequency of outliers (expected: 0.00796812749003984 ) \n                                                     0 \n```\n\n\n:::\n\n::: {.cell-output .cell-output-stdout}\n\n```\n$uniformity\n\n\tExact one-sample Kolmogorov-Smirnov test\n\ndata:  simulationOutput$scaledResiduals\nD = 0.152, p-value = 0.949\nalternative hypothesis: two-sided\n\n\n$dispersion\n\n\tDHARMa nonparametric dispersion test via sd of residuals fitted vs.\n\tsimulated\n\ndata:  simulationOutput\ndispersion = 0.90609, p-value = 0.952\nalternative hypothesis: two.sided\n\n\n$outliers\n\n\tDHARMa outlier test based on exact binomial test with approximate\n\texpectations\n\ndata:  simulationOutput\noutliers at both margin(s) = 0, observations = 10, p-value = 1\nalternative hypothesis: true probability of success is not equal to 0.007968127\n95 percent confidence interval:\n 0.0000000 0.3084971\nsample estimates:\nfrequency of outliers (expected: 0.00796812749003984 ) \n                                                     0 \n```\n\n\n:::\n:::\n\n\n\n- uniformity\n\n\n::: {.cell}\n\n```{.r .cell-code}\ndat.resid |> testUniformity()\n```\n\n::: {.cell-output-display}\n![](30_glm_files/figure-html/validateModelb3c-1.png){width=384}\n:::\n\n::: {.cell-output .cell-output-stdout}\n\n```\n\n\tExact one-sample Kolmogorov-Smirnov test\n\ndata:  simulationOutput$scaledResiduals\nD = 0.152, p-value = 0.949\nalternative hypothesis: two-sided\n```\n\n\n:::\n:::\n\n\n- dispersion\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\ndat.resid |> testDispersion()\n```\n\n::: {.cell-output-display}\n![](30_glm_files/figure-html/validateModelb4c-1.png){width=384}\n:::\n\n::: {.cell-output .cell-output-stdout}\n\n```\n\n\tDHARMa nonparametric dispersion test via sd of residuals fitted vs.\n\tsimulated\n\ndata:  simulationOutput\ndispersion = 0.90609, p-value = 0.952\nalternative hypothesis: two.sided\n```\n\n\n:::\n:::\n\n\n- outliers\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\ndat.resid |> testOutliers()\n```\n\n::: {.cell-output-display}\n![](30_glm_files/figure-html/validateModelb5c-1.png){width=384}\n:::\n\n::: {.cell-output .cell-output-stdout}\n\n```\n\n\tDHARMa outlier test based on exact binomial test with approximate\n\texpectations\n\ndata:  dat.resid\noutliers at both margin(s) = 0, observations = 10, p-value = 1\nalternative hypothesis: true probability of success is not equal to 0.007968127\n95 percent confidence interval:\n 0.0000000 0.3084971\nsample estimates:\nfrequency of outliers (expected: 0.00796812749003984 ) \n                                                     0 \n```\n\n\n:::\n:::\n\n\n- quantiles\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\ndat.resid |> testQuantiles()\n```\n\n::: {.cell-output-display}\n![](30_glm_files/figure-html/validateModelb6c-1.png){width=384}\n:::\n\n::: {.cell-output .cell-output-stdout}\n\n```\n\n\tTest for location of quantiles via qgam\n\ndata:  simulationOutput\np-value = 0.8891\nalternative hypothesis: both\n```\n\n\n:::\n\n```{.r .cell-code}\n## The above fits quantile gams at 0.25,  0.5 and 0.75\n## testSpatialAutocorrelation(fert.resid,  x=,  y=) # needs x and y coordinates\n## testTemporalAutocorrelation(fert.resid,  time=) # needs time\n```\n:::\n\n\n\n:::::\n\n### Summarise model\n\nSince the diagnostics do not reveal any issues, we are free to explore\nthe model summaries\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\ndat1c.lm |> summary()\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n\nCall:\nlm(formula = y ~ scale(x), data = dat)\n\nResiduals:\n   Min     1Q Median     3Q    Max \n-9.387 -4.218  1.821  2.991  7.316 \n\nCoefficients:\n            Estimate Std. Error t value Pr(>|t|)    \n(Intercept)   27.811      1.958   14.20 5.88e-07 ***\nscale(x)      13.850      2.064    6.71 0.000151 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 6.192 on 8 degrees of freedom\nMultiple R-squared:  0.8491,\tAdjusted R-squared:  0.8303 \nF-statistic: 45.03 on 1 and 8 DF,  p-value: 0.0001511\n```\n\n\n:::\n\n```{.r .cell-code}\ndat1c.lm |> confint()\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n               2.5 %   97.5 %\n(Intercept) 23.29570 32.32630\nscale(x)     9.09076 18.60986\n```\n\n\n:::\n:::\n\n\n\n**Interpretation**:\n\n- when $x=0$ (e.g. the average $x$ value since standardised), $y$ is expected to be 27.811 (the y-intercept).\n- for every one unit change in $x$ (which represents a span of\n  approximately 34% of the range of $x$ since standardised), the\n  expected value of $y$ increases by 13.85\n  (the slope)\n- the slope could be as low as 9.091 or as high as \n  18.61 (95% confidence interval of the slope)\n- as the above interval does not include the value of 0, the linear\n  relationship (slope) can be considered significant\n- we would reject the null hypothesis of no relationship (p-value for\n  slope is less than 0.05)\n- 84.914% of the variance in $y$ is\n  explained by its linear relationship with $x$ (R squared value)\n\n::::\n\n::::::\n\nWe can also compare the performance of each of these alternative\nmodels.\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nperformance::compare_performance(dat.lm, dat1b.lm, dat1c.lm, rank = TRUE)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n# Comparison of Model Performance Indices\n\nName     | Model |    R2 | R2 (adj.) |  RMSE | Sigma | AIC weights | AICc weights | BIC weights | Performance-Score\n-------------------------------------------------------------------------------------------------------------------\ndat1c.lm |    lm | 0.849 |     0.830 | 5.538 | 6.192 |       0.333 |        0.333 |       0.333 |           100.00%\ndat.lm   |    lm | 0.849 |     0.830 | 5.538 | 6.192 |       0.333 |        0.333 |       0.333 |            14.29%\ndat1b.lm |    lm | 0.849 |     0.830 | 5.538 | 6.192 |       0.333 |        0.333 |       0.333 |             0.00%\n```\n\n\n:::\n\n```{.r .cell-code}\nperformance::compare_performance(dat.lm, dat1b.lm, dat1c.lm, rank = TRUE) |> plot()\n```\n\n::: {.cell-output-display}\n![](30_glm_files/figure-html/compare_lm1-1.png){width=672}\n:::\n:::\n\n\n\n## Example 2 (categorical data)\n\nFor this demonstration, we will fit a range of models that vary only\nin the contrast paramterisations so that we can appreciate the ways\nthat they are similar and different. We will start with Treatment\ncontrasts as these are the default contrasts applied to an unordered\ncategorical predictor.\n\n:::: {.panel-tabset}\n\n### Treatment contrasts\n\nTreatment contrasts are contrasts in which each of the treatment\ngroups means are compared to the mean of a `control' or reference\ngroup. This approach to over-parameterization is computationally\nidentical to fitting $p-1$ dummy variables via multiple linear\nregression. However, due to the interpretation of the parameters\n(groups compared to a control) and the fact that treatment effects are\nnot orthogonal to the intercept, the interpretation of treatment\ncontrasts (and thus dummy regression) is really only meaningful for\nsituations where there is clearly a single group (control) to which\nthe other groups can be compared. For treatment contrasts, the\nintercept is replaced by $\\beta_{0}$ and thus the remaining\n$\\beta_{p}$ parameters are numbered starting at 1.\n\n| Parameter | Estimates                                                             | Null hypothesis               |\n|-----------|-----------------------------------------------------------------------|-------------------------------|\n| $\\beta_0$ | mean of first (control) group ($\\mu_1$)                               | H$_0$: $\\mu=\\mu_1=0$          |\n| $\\beta_1$ | mean of group 2 minus mean of first (control) group ($\\mu_2 - \\mu_1$) | H$_0$: $\\mu=\\mu_2 -  \\mu_1=0$ |\n| $\\beta_2$ | mean of group 3 minus mean of first (control) group ($\\mu_3 - \\mu_1$) | H$_0$: $\\mu=\\mu_3 -  \\mu_1=0$ |\n| ...       |                                                                       |                               |\n\n: {.sm .paperTable tbl-colwidths=\"[10,70, 20]\"}\n\nThe dummy codes can be viewed using the `model.matrix()` function. I\nam also specifically defining `\"contr.treatment\"` to indicate the\ncontrasts to use, however, as treatment contrasts are the default,\nthis is not necessary.\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nmodel.matrix(~x,\n    data = dat2,\n    contrasts.arg = list(x = \"contr.treatment\")\n)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n   (Intercept) xmedium xhigh\n1            1       0     0\n2            1       0     0\n3            1       0     0\n4            1       0     0\n5            1       1     0\n6            1       1     0\n7            1       1     0\n8            1       1     0\n9            1       0     1\n10           1       0     1\n11           1       0     1\n12           1       0     1\nattr(,\"assign\")\n[1] 0 1 1\nattr(,\"contrasts\")\nattr(,\"contrasts\")$x\n[1] \"contr.treatment\"\n```\n\n\n:::\n:::\n\n\n\nTo fit a model with treatment contrasts\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\ndat2a.lm <- lm(y ~ x, data = dat2)\ndat2a.lm\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n\nCall:\nlm(formula = y ~ x, data = dat2)\n\nCoefficients:\n(Intercept)      xmedium        xhigh  \n     20.839       -4.798      -10.387  \n```\n\n\n:::\n:::\n\n\n\n**Interpretation**\n\n- the mean of the first group is 20.8385636\n- the difference between the means of the first and second group (i.e.\n  the effect of the second group over the first) is -4.7983559\n- the difference between the means of the first and third group (i.e.\n  the effect of the third group over the first) is -10.3871828\n\n\n### Means parameterisation\n\nMeans parameterization literally estimates the group means. Whilst\nthis would initially seem the most obvious approach, as it estimates\nthe mean and standard error of each treatment group, since it does not\ninclude any effects (differences), it has traditionally not been seen\nas all that useful. In particular, the resulting hypothesis tests are\nnot particularly useful.\n\n| Parameter | Estimates                      | Null hypothesis      |\n|-----------|--------------------------------|----------------------|\n| $\\beta_0$ | mean of first group ($\\mu_1$)  | H$_0$: $\\mu=\\mu_1=0$ |\n| $\\beta_1$ | mean of second group ($\\mu_2$) | H$_0$: $\\mu_2=0$     |\n| $\\beta_2$ | mean of third group ($\\mu_3$)  | H$_0$: $\\mu_3=0$     |\n| ...       |                                |                      |\n\n: {.sm .paperTable tbl-colwidths=\"[10,70, 20]\"}\n\nNote that for means parameterisation, it is simply a matter of\ndropping the intercept (`-1`).\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nmodel.matrix(~-1 + x,\n    data = dat2\n)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n   xcontrol xmedium xhigh\n1         1       0     0\n2         1       0     0\n3         1       0     0\n4         1       0     0\n5         0       1     0\n6         0       1     0\n7         0       1     0\n8         0       1     0\n9         0       0     1\n10        0       0     1\n11        0       0     1\n12        0       0     1\nattr(,\"assign\")\n[1] 1 1 1\nattr(,\"contrasts\")\nattr(,\"contrasts\")$x\n[1] \"contr.treatment\"\n```\n\n\n:::\n:::\n\n\n\nTo fit a model with treatment contrasts\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\ndat2b.lm <- lm(y ~ -1 + x, data = dat2)\ndat2b.lm\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n\nCall:\nlm(formula = y ~ -1 + x, data = dat2)\n\nCoefficients:\nxcontrol   xmedium     xhigh  \n   20.84     16.04     10.45  \n```\n\n\n:::\n:::\n\n\n\n**Interpretation**\n\n- the mean of the first group is 20.8385636\n- the mean of the second group is 16.0402077\n- the mean of the third group is 10.4513808\n\n### Sum to zero contrasts\n\nThis technique constrains the sum of the unconstrained treatment\neffects ($\\beta$) to zero. In this model parameterization, the\nintercept estimates the average treatment effect and the remaining\n($\\beta_p$) estimate the differences between each of the treatment\nmeans and the average treatment mean. Unlike treatment contrasts,\nthese contrasts are genuinely orthogonal.\n\n| Parameter | Estimates                                                         | Null hypothesis                        |\n|-----------|-------------------------------------------------------------------|----------------------------------------|\n| $\\beta_0$ | mean of all groups ($\\mu_{1:p}/p$)                                | H$_0$: $\\mu=\\mu_{p}/p=0$               |\n| $\\beta_1$ | mean of group 1 minus mean of group means ($\\mu_1-(\\mu_{1:p}/p)$) | H$_0$: $\\beta_1=\\mu_1-(\\mu_{1:p}/p)=0$ |\n| $\\beta_2$ | mean of group 2 minus mean of group means ($\\mu_2-(\\mu_{1:p}/p)$) | H$_0$: $\\beta_2=\\mu_1-(\\mu_{1:p}/p)=0$ |\n| ...       |                                                                   |                                        |\n\nYou might notice that the last group is completely omitted.\n\n: {.sm .paperTable tbl-colwidths=\"[10,70, 20]\"}\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nmodel.matrix(~ x,\n  data = dat2,\n  contrasts.arg = list(x = \"contr.sum\")\n)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n   (Intercept) x1 x2\n1            1  1  0\n2            1  1  0\n3            1  1  0\n4            1  1  0\n5            1  0  1\n6            1  0  1\n7            1  0  1\n8            1  0  1\n9            1 -1 -1\n10           1 -1 -1\n11           1 -1 -1\n12           1 -1 -1\nattr(,\"assign\")\n[1] 0 1 1\nattr(,\"contrasts\")\nattr(,\"contrasts\")$x\n[1] \"contr.sum\"\n```\n\n\n:::\n:::\n\n\n\nTo fit a model with sum to zero contrasts\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\ndat2c.lm <- lm(y ~ x,\n    data = dat2,\n    contrasts = list(x = \"contr.sum\")\n)\ndat2c.lm\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n\nCall:\nlm(formula = y ~ x, data = dat2, contrasts = list(x = \"contr.sum\"))\n\nCoefficients:\n(Intercept)           x1           x2  \n    15.7767       5.0618       0.2635  \n```\n\n\n:::\n:::\n\n\n\n**Interpretation**\n\n- the mean of the groups is 15.7767174\n- the difference between the grand mean (mean of all groups) and mean\n  of the first group (i.e. the effect of the first group over the\n  average) is 5.0618462\n- the difference between the grand mean (mean of all groups) and mean\n  of the second group (i.e. the effect of the second group over the\n  average) is 0.2634903\n\n\n### Helmert contrasts\n\n\nIn Helmert contrasts, the intercept estimates the average treatment\neffect and the remaining ($\\beta_{p-1}$) estimate the differences\nbetween the overal mean and the mean of the subsequent groups. Helmert\ncontrasts are really only useful if the group levels are ordered.\n\n\n| Parameter | Estimates                                                            | Null hypothesis                        |\n|-----------|----------------------------------------------------------------------|----------------------------------------|\n| $\\beta_0$ | mean of all groups ($\\mu_{1:p}/p$)                                   | H$_0$: $\\mu=\\mu_{1:p}/p=0$             |\n| $\\beta_1$ | mean of groups 1 and 2 minus mean of group 1 ($\\mu_{1,2}-(\\mu_{1})$) | H$_0$: $\\beta_1=\\mu_{1,2}-(\\mu_{1})=0$ |\n| $\\beta_1$ | mean of groups 1 and 2 minus mean of group 1 ($\\mu_{1,2}-(\\mu_{1})$) | H$_0$: $\\beta_1=\\mu_{1,2}-(\\mu_{1})=0$ |\n| ...       |                                                                      |                                        |\n\nYou might notice that the last group is completely omitted.\n\n: {.sm .paperTable tbl-colwidths=\"[10,70, 20]\"}\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nmodel.matrix(~x,\n    data = dat2,\n    contrasts.arg = list(x = \"contr.helmert\")\n)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n   (Intercept) x1 x2\n1            1 -1 -1\n2            1 -1 -1\n3            1 -1 -1\n4            1 -1 -1\n5            1  1 -1\n6            1  1 -1\n7            1  1 -1\n8            1  1 -1\n9            1  0  2\n10           1  0  2\n11           1  0  2\n12           1  0  2\nattr(,\"assign\")\n[1] 0 1 1\nattr(,\"contrasts\")\nattr(,\"contrasts\")$x\n[1] \"contr.helmert\"\n```\n\n\n:::\n:::\n\n\n\nTo fit a model with Helmert contrasts\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\ndat2d.lm <- lm(y ~ x,\n    data = dat2,\n    contrasts = list(x = \"contr.helmert\")\n)\ndat2d.lm\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n\nCall:\nlm(formula = y ~ x, data = dat2, contrasts = list(x = \"contr.helmert\"))\n\nCoefficients:\n(Intercept)           x1           x2  \n     15.777       -2.399       -2.663  \n```\n\n\n:::\n:::\n\n\n\n**Interpretation**\n\n- the mean of the groups is 15.7767174\n- the difference between the mean of the first group and the mean\n  of the first and second groups is -2.3991779\n- the difference between the mean of the second group and the mean\n  of the second and third groups is -2.3991779\n  \n### Polynomial contrasts\n\nPolynomial contrasts generate orthogonal polynomial trends (such as\nlinear, quadratic and cubic). This is equivalent to fitting a multiple\nlinear regression (or polynomial regression) with orthogonal\nparameters. $p-1$ order polynomials are defined. Polynomial contrasts\nare obviously only sensible for factors whose levels can be\nconceptualized as representing an ordered, continuum. Unless otherwise\nspecified, the intervals between levels are assumed to be equally\nspaced. The first, second and third order polynomials respectively\nrepresent straight line (linear), curves with a single major change in\ndirection (quadratic) and curves with two major changes in direction\n(cubic).\n\n| Parameter | Estimates                                          | Null hypothesis    |\n|-----------|----------------------------------------------------|--------------------|\n| $\\beta_0$ | mean of all groups ($\\mu_{1:p}/p$)                 | H$_0$: $\\beta_0=0$ |\n| $\\beta_1$ | the first order polynomial (linear) coefficient    | H$_0$: $\\beta_1=0$ |\n| $\\beta_1$ | the second order polynomial (quadratic) coefficent | H$_0$: $\\beta_2=0$ |\n| ...       |                                                    |                    |\n\nYou might notice that the last group is completely omitted.\n\n: {.sm .paperTable tbl-colwidths=\"[10,70, 20]\"}\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nmodel.matrix(~x,\n    data = dat2,\n    contrasts.arg = list(x = \"contr.poly\")\n)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n   (Intercept)           x.L        x.Q\n1            1 -7.071068e-01  0.4082483\n2            1 -7.071068e-01  0.4082483\n3            1 -7.071068e-01  0.4082483\n4            1 -7.071068e-01  0.4082483\n5            1 -7.850462e-17 -0.8164966\n6            1 -7.850462e-17 -0.8164966\n7            1 -7.850462e-17 -0.8164966\n8            1 -7.850462e-17 -0.8164966\n9            1  7.071068e-01  0.4082483\n10           1  7.071068e-01  0.4082483\n11           1  7.071068e-01  0.4082483\n12           1  7.071068e-01  0.4082483\nattr(,\"assign\")\n[1] 0 1 1\nattr(,\"contrasts\")\nattr(,\"contrasts\")$x\n[1] \"contr.poly\"\n```\n\n\n:::\n:::\n\n\n\nTo fit a model with polynomial contrasts\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\ndat2e.lm <- lm(y ~ x,\n    data = dat2,\n    contrasts = list(x = \"contr.poly\")\n)\ndat2e.lm\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n\nCall:\nlm(formula = y ~ x, data = dat2, contrasts = list(x = \"contr.poly\"))\n\nCoefficients:\n(Intercept)          x.L          x.Q  \n    15.7767      -7.3448      -0.3227  \n```\n\n\n:::\n:::\n\n\n\n**Interpretation**\n\n- the mean of the groups is 15.7767174\n- $y$ declines at a rate of -7.3448474 per level of the\n  group ($x$). There is a negative relationship.\n- the rate of quadratic curvature is -0.3227084. Since this\n  value is negative, it suggests that the gradient of the trend (slope),\n  declines with $x$.\n\n\n### User defined contrasts\n\nIn addition to the `prefabricated' sets of comparisons illustrated\nabove, it is possible to define other contrast combinations that are\nspecifically suited to a particular experimental design and set of\nresearch questions. Contrasts are defined by constructing a contrast\nmatrix according to the following rules:\n\n- groups to be included and excluded in a specific contrasts\n  (comparison) are represented by non-zero and zero coefficients\n  respectively\n- groups to be apposed (contrasted) to one another should have\n  apposing signs\n- the number of contrasts must not exceed $p-1$, where $p$ is the\n\t\t\t\tnumber of groups. Actually, it must equal $p-1$\n\t\t\t\texactly. However, it is usually sufficient to define\n\t\t\t\tless than $p-1$ contrasts and let R generate the\n\t\t\t\tremaining contrasts.\n- within a given contrast, the sum of positive coefficients (and\n  negative coefficients) should sum to 1 to ensure that the resulting\n  estimates can be sensibly interpreted.\n- all the contrasts must be orthogonal (independent of one another)\n\nLets say we were interested in comparing the means of group 1 with the\naverage of groups 2 and 3. We can specifically define this one\ncontrasts and let R define the other two orthogonal contrasts (which\nmight hvae no interpretation at all).\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# define potential contrast matrix for comparing group G1 with the average of groups G2 and G3\nlibrary(gmodels)\ncontrasts(dat2$x) <- make.contrasts(rbind(c(1, -0.5, -0.5)))\ncontrasts(dat2$x)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n                C1            C2\ncontrol  0.6666667  5.551115e-17\nmedium  -0.3333333 -7.071068e-01\nhigh    -0.3333333  7.071068e-01\n```\n\n\n:::\n\n```{.r .cell-code}\nmodel.matrix(~x, data =  dat2)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n   (Intercept)        xC1           xC2\n1            1  0.6666667  5.551115e-17\n2            1  0.6666667  5.551115e-17\n3            1  0.6666667  5.551115e-17\n4            1  0.6666667  5.551115e-17\n5            1 -0.3333333 -7.071068e-01\n6            1 -0.3333333 -7.071068e-01\n7            1 -0.3333333 -7.071068e-01\n8            1 -0.3333333 -7.071068e-01\n9            1 -0.3333333  7.071068e-01\n10           1 -0.3333333  7.071068e-01\n11           1 -0.3333333  7.071068e-01\n12           1 -0.3333333  7.071068e-01\nattr(,\"assign\")\n[1] 0 1 1\nattr(,\"contrasts\")\nattr(,\"contrasts\")$x\n                C1            C2\ncontrol  0.6666667  5.551115e-17\nmedium  -0.3333333 -7.071068e-01\nhigh    -0.3333333  7.071068e-01\n```\n\n\n:::\n:::\n\n\n\nTo fit a model with user defined contrasts\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\ndat2f.lm <- lm(y ~ x,\n    data = dat2,\n    contrasts = list(x = make.contrasts(rbind(c(1, -0.5, -0.5))))\n)\ndat2f.lm\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n\nCall:\nlm(formula = y ~ x, data = dat2, contrasts = list(x = make.contrasts(rbind(c(1, \n    -0.5, -0.5)))))\n\nCoefficients:\n(Intercept)          xC1          xC2  \n     15.777        7.593       -3.952  \n```\n\n\n:::\n:::\n\n\n\n**Interpretation**\n\n- the mean of the groups is 15.7767174\n- the difference between the first group and the average of the second\n  and third groups is 7.5927693\n- since we did not define a second contrast, R has just added one in\n  that satisfies orthogonality - this one obviously has no\n  interpretation.\n\n\n::::\n\nWhilst the type of contrasts impact on the interpretation of model\nestimates, they rarely have an impact on the goodness of fit of the\nmodel (unless the sample sizes within groups vary substantially).\n\n\n**DHARMa (simulated) residuals**\n\n:::: {.panel-tabset}\n#### Treatment contrasts\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\ndat.resid <- dat2a.lm |> \n  simulateResiduals(plot = TRUE)\n```\n\n::: {.cell-output-display}\n![](30_glm_files/figure-html/validateModel2a-1.png){width=768}\n:::\n:::\n\n\n\n#### Means parameterisation\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\ndat.resid <- dat2b.lm |> \n  simulateResiduals(plot = TRUE)\n```\n\n::: {.cell-output-display}\n![](30_glm_files/figure-html/validateModel2b-1.png){width=768}\n:::\n:::\n\n\n\n#### Sum to zero contrasts\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\ndat.resid <- dat2c.lm |> \n  simulateResiduals(plot = TRUE)\n```\n\n::: {.cell-output-display}\n![](30_glm_files/figure-html/validateModel2c-1.png){width=768}\n:::\n:::\n\n\n\n#### Helmert contrasts\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\ndat.resid <- dat2d.lm |> \n  simulateResiduals(plot = TRUE)\n```\n\n::: {.cell-output-display}\n![](30_glm_files/figure-html/validateModel2d-1.png){width=768}\n:::\n:::\n\n\n\n#### Polynomial contrasts\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\ndat.resid <- dat2e.lm |> \n  simulateResiduals(plot = TRUE)\n```\n\n::: {.cell-output-display}\n![](30_glm_files/figure-html/validateModel2e-1.png){width=768}\n:::\n:::\n\n\n\n#### User defined contrasts\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\ndat.resid <- dat2f.lm |> \n  simulateResiduals(plot = TRUE)\n```\n\n::: {.cell-output-display}\n![](30_glm_files/figure-html/validateModel2f-1.png){width=768}\n:::\n:::\n\n\n::::\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nperformance::compare_performance(dat2a.lm, dat2b.lm, dat2c.lm, rank = TRUE)\n```\n\n::: {.cell-output .cell-output-stderr}\n\n```\nFollowing indices with missing values are not used for ranking: AIC_wt,\n  AICc_wt, BIC_wt\n```\n\n\n:::\n\n::: {.cell-output .cell-output-stdout}\n\n```\n# Comparison of Model Performance Indices\n\nName     | Model |    R2 | R2 (adj.) |  RMSE | Sigma | AIC weights | AICc weights | BIC weights | Performance-Score\n-------------------------------------------------------------------------------------------------------------------\ndat2b.lm |    lm | 0.955 |     0.940 | 3.535 | 4.082 |       0.333 |        0.333 |       0.333 |           100.00%\ndat2c.lm |    lm | 0.590 |     0.499 | 3.535 | 4.082 |       0.333 |        0.333 |       0.333 |            37.50%\ndat2a.lm |    lm | 0.590 |     0.499 | 3.535 | 4.082 |       0.333 |        0.333 |       0.333 |             0.00%\n```\n\n\n:::\n\n```{.r .cell-code}\nperformance::compare_performance(dat2a.lm, dat2b.lm, dat2c.lm, rank = TRUE) |> plot()\n```\n\n::: {.cell-output .cell-output-stderr}\n\n```\nFollowing indices with missing values are not used for ranking: AIC_wt,\n  AICc_wt, BIC_wt\n```\n\n\n:::\n\n::: {.cell-output-display}\n![](30_glm_files/figure-html/compare_lm2-1.png){width=672}\n:::\n:::\n\n\n\n## Example 3 (Poisson data)\n\nExploratory data analysis suggested that a simple linear model of the form\n\n$$\ny_i = \\beta_0+\\beta_1\\times x_i+\\varepsilon_i \\hspace{1cm}\\varepsilon_i\\sim{}\\mathcal{N}(0, \\sigma^2)\n$$\n\nmight not be appropriate for the motivating example 3 data. To see how\nthis manifests in the fitted model and diagnostics, lets fit the model\nvia OLS anyway.\n\n:::: {.panel-tabset}\n### Fit model via `lm()`\n\n$$\ny_i = \\beta_0+\\beta_1\\times x_i+\\varepsilon_i \\hspace{1cm}\\varepsilon_i\\sim{}\\mathcal{N}(0, \\sigma^2)\n$$\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\ndat3.lm <- lm(y~x, data = dat3)\ndat3.lm\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n\nCall:\nlm(formula = y ~ x, data = dat3)\n\nCoefficients:\n(Intercept)            x  \n     -6.400        3.127  \n```\n\n\n:::\n:::\n\n\n\n### Model diagnostics\n\nAnd now to explore the regression diagnostics.\n\n::::: {.panel-tabset}\n\n### Autoplot\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\ndat3.lm |> \n  autoplot(which = 1:6, ncol = 2, label.size = 3)\n```\n\n::: {.cell-output-display}\n![](30_glm_files/figure-html/lm_diagnostics3a-1.png){width=672}\n:::\n:::\n\n\n\n**Conclusions**:\n\n- there is a clear non-linear pattern remaining in the residual plot\n  indicative of a persistent non-linear trend\n- there is some evidence that the tails of the Q-Q plot are starting\n  to diverge from the line. This usually implies that the nominated\n  distribution (in this case gaussian) is not capturing the underlying\n  distribution appropriately.\n- the 10th observation has a large (>0.8) Cook's D value suggesting\n  that it was overly influential\n\n### Influence measures\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\ndat3.lm |> influence.measures()\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nInfluence measures of\n\t lm(formula = y ~ x, data = dat3) :\n\n     dfb.1_    dfb.x    dffit cov.r   cook.d   hat inf\n1   0.69973 -0.59205  0.70238 1.553 2.49e-01 0.345    \n2   0.36136 -0.28537  0.36916 1.550 7.35e-02 0.248    \n3  -0.08015  0.05651 -0.08608 1.569 4.21e-03 0.176    \n4  -0.00629  0.00355 -0.00767 1.496 3.36e-05 0.127    \n5  -0.00884  0.00249 -0.01455 1.455 1.21e-04 0.103    \n6  -0.22861 -0.12895 -0.75191 0.502 1.90e-01 0.103    \n7   0.00000 -0.19332 -0.41761 1.092 8.51e-02 0.127    \n8   0.07626 -0.21509 -0.32761 1.379 5.72e-02 0.176    \n9  -0.31623  0.62431  0.80763 1.058 2.91e-01 0.248    \n10 -0.54136  0.91610  1.08681 1.146 5.11e-01 0.345    \n```\n\n\n:::\n\n```{.r .cell-code}\ndat3.lm |> fortify()\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n    y  x      .hat   .sigma      .cooksd    .fitted     .resid   .stdresid\n1   1  1 0.3454545 5.462498 2.486948e-01 -3.2727273  4.2727273  0.97078434\n2   3  2 0.2484848 5.651781 7.354214e-02 -0.1454545  3.1454545  0.66696345\n3   2  3 0.1757576 5.801405 4.213192e-03  2.9818182 -0.9818182 -0.19878842\n4   6  4 0.1272727 5.815619 3.359699e-05  6.1090909 -0.1090909 -0.02146529\n5   9  5 0.1030303 5.815022 1.208692e-04  9.2363636 -0.2363636 -0.04587534\n6   3  6 0.1030303 4.456374 1.896896e-01 12.3636364 -9.3636364 -1.81736913\n7  10  7 0.1272727 5.374765 8.511611e-02 15.4909091 -5.4909091 -1.08041965\n8  15  8 0.1757576 5.617331 5.721763e-02 18.6181818 -3.6181818 -0.73257214\n9  28  9 0.2484848 5.136837 2.907776e-01 21.7454545  6.2545455  1.32621634\n10 31 10 0.3454545 5.062545 5.114353e-01 24.8727273  6.1272727  1.39214605\n```\n\n\n:::\n:::\n\n\n\n**Conclusions**:\n\n- the 10th observation has a large (>0.8) Cook's D value suggesting\n  that it was overly influential\n\n### Performance model checking\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\ndat3.lm |> performance::check_model()\n```\n\n::: {.cell-output-display}\n![](30_glm_files/figure-html/validateModel3a1-1.png){width=768}\n:::\n\n```{.r .cell-code}\ndat3.lm |> performance::check_outliers()\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nOK: No outliers detected.\n- Based on the following method and threshold: cook (0.8).\n- For variable: (Whole model)\n```\n\n\n:::\n:::\n\n\n\n**Conclusions**:\n\n- the observed density and simulated densities in the Posterior\n  Predictive Check plot are inconsistent \n  - the peaks are not aligned\n- there is clear evidence of a non-linear trend in the residuals plot\n- the 10th observation has high Cook's D value\n- dots do not fall along the Q-Q plot line (particularly the one in\n  the tails)\n\n### DHARMa (simulated) residuals\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\ndat3.resid <- dat3.lm |> \n  simulateResiduals(plot = TRUE)\n```\n\n::: {.cell-output-display}\n![](30_glm_files/figure-html/validateModel3b1-1.png){width=768}\n:::\n:::\n\n\n\n**Conclusions**:\n\n- the Q-Q plot is okay\n- there is clear evidence of a non-linear trend persisting in the\n  residuals\n:::::\n\n### Summarise model\n\nSince the model diagnostics indicated violations of the assumptions,\nwe will not explore the model summaries\n\n### Model performance\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nperformance::model_performance(dat3.lm)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n# Indices of model performance\n\nAIC    |   AICc |    BIC |    R2 | R2 (adj.) |  RMSE | Sigma\n------------------------------------------------------------\n66.024 | 70.024 | 66.931 | 0.773 |     0.745 | 4.866 | 5.440\n```\n\n\n:::\n:::\n\n\n::::\n\n## Example 4 (NB data)\n\nExploratory data analysis suggested that a simple linear model of the form\n\n$$\ny_i = \\beta_0+\\beta_1\\times x_i+\\varepsilon_i \\hspace{1cm}\\varepsilon_i\\sim{}\\mathcal{N}(0, \\sigma^2)\n$$\n\nmight not be appropriate for the motivating example 4 data. To see how\nthis manifests in the fitted model and diagnostics, lets fit the model\nvia OLS anyway.\n\n:::: {.panel-tabset}\n### Fit model via `lm()`\n\n$$\ny_i = \\beta_0+\\beta_1\\times x_i+\\varepsilon_i \\hspace{1cm}\\varepsilon_i\\sim{}\\mathcal{N}(0, \\sigma^2)\n$$\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\ndat4.lm <- lm(y~x, data = dat4)\ndat4.lm\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n\nCall:\nlm(formula = y ~ x, data = dat4)\n\nCoefficients:\n(Intercept)            x  \n     -3.400        2.309  \n```\n\n\n:::\n:::\n\n\n\n### Model diagnostics\n\nAnd now to explore the regression diagnostics.\n\n::::: {.panel-tabset}\n\n### Autoplot\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\ndat4.lm |> \n  autoplot(which = 1:6, ncol = 2, label.size = 3)\n```\n\n::: {.cell-output-display}\n![](30_glm_files/figure-html/lm_diagnostics4a-1.png){width=672}\n:::\n:::\n\n\n\n**Conclusions**:\n\n- there is a clear non-linear pattern remaining in the residual plot\n  indicative of a persistent non-linear trend\n- there is evidence that the tails of the Q-Q plot have diverge from\n  the line. This usually implies that the nominated distribution (in\n  this case gaussian) is not capturing the underlying distribution\n  appropriately.\n- the 10th observation has a large (>0.8) Cook's D value suggesting\n  that it was overly influential\n\n### Influence measures\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\ndat4.lm |> influence.measures()\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nInfluence measures of\n\t lm(formula = y ~ x, data = dat4) :\n\n    dfb.1_   dfb.x   dffit cov.r   cook.d   hat inf\n1   0.2577 -0.2180  0.2587 1.925 0.037551 0.345   *\n2   0.3092 -0.2442  0.3159 1.597 0.054662 0.248    \n3   0.4650 -0.3278  0.4993 1.163 0.122089 0.176    \n4  -0.2610  0.1472 -0.3181 1.239 0.052606 0.127    \n5  -0.1896  0.0535 -0.3119 1.159 0.049580 0.103    \n6  -0.0419 -0.0236 -0.1378 1.390 0.010602 0.103    \n7   0.0000  0.0117  0.0253 1.495 0.000365 0.127    \n8   0.1886 -0.5319 -0.8102 0.764 0.260507 0.176    \n9   0.0260 -0.0513 -0.0663 1.731 0.002510 0.248    \n10 -1.1603  1.9635  2.3294 0.327 1.255963 0.345   *\n```\n\n\n:::\n\n```{.r .cell-code}\ndat4.lm |> fortify()\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n    y  x      .hat   .sigma      .cooksd   .fitted     .resid   .stdresid\n1   0  1 0.3454545 3.787196 0.0375508913 -1.090909  1.0909091  0.37722422\n2   3  2 0.2484848 3.741534 0.0546616885  1.218182  1.7818182  0.57501005\n3   7  3 0.1757576 3.537286 0.1220892204  3.527273  3.4727273  1.07009938\n4   3  4 0.1272727 3.644957 0.0526058342  5.836364 -2.8363636 -0.84938298\n5   5  5 0.1030303 3.609271 0.0495801803  8.145455 -3.1454545 -0.92912778\n6   9  6 0.1030303 3.776988 0.0106021970 10.454545 -1.4545455 -0.42965447\n7  13  7 0.1272727 3.820138 0.0003653183 12.763636  0.2363636  0.07078191\n8  10  8 0.1757576 3.184752 0.2605067570 15.072727 -5.0727273 -1.56312946\n9  17  9 0.2484848 3.817707 0.0025099755 17.381818 -0.3818182 -0.12321644\n10 26 10 0.3454545 2.432094 1.2559625765 19.690909  6.3090909  2.18161342\n```\n\n\n:::\n:::\n\n\n\n**Conclusions**:\n\n- the 10th observation has a large (>0.8) Cook's D value suggesting\n  that it was overly influential\n\n### Performance model checking\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\ndat4.lm |> performance::check_model()\n```\n\n::: {.cell-output-display}\n![](30_glm_files/figure-html/validateModel4a1-1.png){width=768}\n:::\n\n```{.r .cell-code}\ndat4.lm |> performance::check_outliers()\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n1 outlier detected: case 10.\n- Based on the following method and threshold: cook (0.8).\n- For variable: (Whole model).\n```\n\n\n:::\n:::\n\n\n\n**Conclusions**:\n\n- the observed density and simulated densities in the Posterior\n  Predictive Check plot are inconsistent \n  - the peaks are not aligned\n- there is clear evidence of a non-linear trend in the residuals plot\n- the 10th observation has high Cook's D value\n- dots do not fall along the Q-Q plot line (particularly those in\n  the tails)\n\n### DHARMa (simulated) residuals\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\ndat4.resid <- dat4.lm |> \n  simulateResiduals(plot = TRUE)\n```\n\n::: {.cell-output-display}\n![](30_glm_files/figure-html/validateModel4b1-1.png){width=768}\n:::\n:::\n\n\n\n**Conclusions**:\n\n- the Q-Q plot is starting to deviate from the linear line\n- there is clear evidence of a non-linear trend persisting in the\n  residuals\n\n:::::\n\n\n### Summarise model\n\nSince the model diagnostics indicated violations of the assumptions,\nwe will not explore the model summaries\n\n### Model performance\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nperformance::model_performance(dat4.lm)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n# Indices of model performance\n\nAIC    |   AICc |    BIC |    R2 | R2 (adj.) |  RMSE | Sigma\n------------------------------------------------------------\n57.624 | 61.624 | 58.532 | 0.811 |     0.788 | 3.197 | 3.575\n```\n\n\n:::\n:::\n\n\n\n::::\n\n## Example 5 (Binary data)\n\nExploratory data analysis suggested that a simple linear model of the form\n\n$$\ny_i = \\beta_0+\\beta_1\\times x_i+\\varepsilon_i \\hspace{1cm}\\varepsilon_i\\sim{}\\mathcal{N}(0, \\sigma^2)\n$$\n\nmight not be appropriate for the motivating example 4 data. To see how\nthis manifests in the fitted model and diagnostics, lets fit the model\nvia OLS anyway.\n\n:::: {.panel-tabset}\n### Fit model via `lm()`\n\n$$\ny_i = \\beta_0+\\beta_1\\times x_i+\\varepsilon_i \\hspace{1cm}\\varepsilon_i\\sim{}\\mathcal{N}(0, \\sigma^2)\n$$\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\ndat5.lm <- lm(y~x, data = dat5)\ndat5.lm\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n\nCall:\nlm(formula = y ~ x, data = dat5)\n\nCoefficients:\n(Intercept)            x  \n    -0.1333       0.1333  \n```\n\n\n:::\n:::\n\n\n\n### Model diagnostics\n\nAnd now to explore the regression diagnostics.\n\n::::: {.panel-tabset}\n\n### Autoplot\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\ndat5.lm |> \n  autoplot(which = 1:6, ncol = 2, label.size = 3)\n```\n\n::: {.cell-output-display}\n![](30_glm_files/figure-html/lm_diagnostics5a-1.png){width=672}\n:::\n:::\n\n\n\n**Conclusions**:\n\n- the regular residual plot is not interpretable for binary data. It\n  will just show two, angled clouds of points (one associated with the\n  0 values, the other associated with the 1's). there is a clear\n  non-linear pattern remaining in the residual plot indicative of a\n  persistent non-linear trend\n- there is evidence that the tails of the Q-Q plot have diverge from\n  the line. This usually implies that the nominated distribution (in\n  this case gaussian) is not capturing the underlying distribution\n  appropriately.\n\n### Influence measures\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\ndat5.lm |> influence.measures()\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nInfluence measures of\n\t lm(formula = y ~ x, data = dat5) :\n\n    dfb.1_   dfb.x     dffit cov.r   cook.d   hat inf\n1   0.0000  0.0000  1.37e-16 1.995 1.06e-32 0.345   *\n2  -0.2401  0.1896 -2.45e-01 1.651 3.35e-02 0.248    \n3  -0.3631  0.2560 -3.90e-01 1.305 7.88e-02 0.176    \n4   0.7379 -0.4162  8.99e-01 0.466 2.58e-01 0.127    \n5  -0.3911  0.1103 -6.43e-01 0.635 1.56e-01 0.103    \n6   0.1066  0.0602  3.51e-01 1.095 6.10e-02 0.103    \n7   0.0000  0.1063  2.30e-01 1.353 2.86e-02 0.127    \n8  -0.0217  0.0611  9.31e-02 1.566 4.93e-03 0.176    \n9   0.0476 -0.0939 -1.21e-01 1.716 8.38e-03 0.248    \n10  0.2534 -0.4289 -5.09e-01 1.743 1.38e-01 0.345    \n```\n\n\n:::\n\n```{.r .cell-code}\ndat5.lm |> fortify()\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n   y  x      .hat    .sigma      .cooksd      .fitted        .resid  .stdresid\n1  0  1 0.3454545 0.3651484 1.064866e-32 8.326673e-17  5.551115e-17  0.0000000\n2  0  2 0.2484848 0.3604912 3.352163e-02 1.333333e-01 -1.333333e-01 -0.4502943\n3  0  3 0.1757576 0.3478626 7.884330e-02 2.666667e-01 -2.666667e-01 -0.8599394\n4  1  4 0.1272727 0.2727724 2.578125e-01 4.000000e-01  6.000000e-01  1.8803495\n5  0  5 0.1030303 0.2967000 1.561098e-01 5.333333e-01 -5.333333e-01 -1.6486803\n6  1  6 0.1030303 0.3400545 6.098038e-02 6.666667e-01  3.333333e-01  1.0304252\n7  1  7 0.1272727 0.3560698 2.864583e-02 8.000000e-01  2.000000e-01  0.6267832\n8  1  8 0.1757576 0.3640921 4.927706e-03 9.333333e-01  6.666667e-02  0.2149849\n9  1  9 0.2484848 0.3639897 8.380407e-03 1.066667e+00 -6.666667e-02 -0.2251472\n10 1 10 0.3454545 0.3529917 1.382275e-01 1.200000e+00 -2.000000e-01 -0.7237469\n```\n\n\n:::\n:::\n\n\n\n**Conclusions**:\n\n- there are no obvious issues with the influence values\n\n### Performance model checking\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\ndat5.lm |> performance::check_model()\n```\n\n::: {.cell-output-display}\n![](30_glm_files/figure-html/validateModel5a1-1.png){width=768}\n:::\n\n```{.r .cell-code}\ndat5.lm |> performance::check_outliers()\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nOK: No outliers detected.\n- Based on the following method and threshold: cook (0.8).\n- For variable: (Whole model)\n```\n\n\n:::\n:::\n\n\n\n**Conclusions**:\n\n- the observed density and simulated densities in the Posterior\n  Predictive Check plot are inconsistent \n  - the observed data show two peaks (associated with 0's and 1's)\n  - the posterior predictions show a single peak between 0 and 1\n- there is clear evidence of a non-linear trend in the standardised\n  residuals plot\n- dots do not fall along the Q-Q plot line (particularly those in\n  the tails)\n\n### DHARMa (simulated) residuals\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\ndat5.resid <- dat5.lm |> \n  simulateResiduals(plot = TRUE)\n```\n\n::: {.cell-output-display}\n![](30_glm_files/figure-html/validateModel5b1-1.png){width=768}\n:::\n:::\n\n\n\n**Conclusions**:\n\n- interesting the simulated residuals look acceptable, although the\n  Q-Q plot is clearly not following the reference line\n\n:::::\n\n### Summarise model\n\nSince the model diagnostics indicated violations of the assumptions,\nwe will not explore the model summaries\n\n### Model performance\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nperformance::model_performance(dat5.lm)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n# Indices of model performance\n\nAIC    |   AICc |    BIC |    R2 | R2 (adj.) |  RMSE | Sigma\n------------------------------------------------------------\n10.663 | 14.663 | 11.571 | 0.611 |     0.562 | 0.306 | 0.342\n```\n\n\n:::\n:::\n\n\n::::\n\n\n## Example 6 (Binomial data)\n\nExploratory data analysis suggested that a simple linear model of the form\n\n$$\ny_i = \\beta_0+\\beta_1\\times x_i+\\varepsilon_i \\hspace{1cm}\\varepsilon_i\\sim{}\\mathcal{N}(0, \\sigma^2)\n$$\n\nmight not be appropriate for the motivating example 4 data. To see how\nthis manifests in the fitted model and diagnostics, lets fit the model\nvia OLS anyway.\n\n:::: {.panel-tabset}\n### Fit model via `lm()`\n\n$$\ny_i = \\beta_0+\\beta_1\\times x_i+\\varepsilon_i \\hspace{1cm}\\varepsilon_i\\sim{}\\mathcal{N}(0, \\sigma^2)\n$$\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\ndat6.lm <- lm(y~x, data = dat6)\ndat6.lm\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n\nCall:\nlm(formula = y ~ x, data = dat6)\n\nCoefficients:\n(Intercept)            x  \n    0.01333      0.11394  \n```\n\n\n:::\n:::\n\n\n\n### Model diagnostics\n\nAnd now to explore the regression diagnostics.\n\n::::: {.panel-tabset}\n\n### Autoplot\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\ndat6.lm |> \n  autoplot(which = 1:6, ncol = 2, label.size = 3)\n```\n\n::: {.cell-output-display}\n![](30_glm_files/figure-html/lm_diagnostics6a-1.png){width=672}\n:::\n:::\n\n\n\n**Conclusions**:\n\n- the regular residual plot is not interpretable for binary data. It\n  will just show two, angled clouds of points (one associated with the\n  0 values, the other associated with the 1's). there is a clear\n  non-linear pattern remaining in the residual plot indicative of a\n  persistent non-linear trend\n- there is evidence that the tails of the Q-Q plot have diverge from\n  the line. This usually implies that the nominated distribution (in\n  this case gaussian) is not capturing the underlying distribution\n  appropriately.\n\n### Influence measures\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\ndat6.lm |> influence.measures()\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nInfluence measures of\n\t lm(formula = y ~ x, data = dat6) :\n\n    dfb.1_   dfb.x  dffit cov.r  cook.d   hat inf\n1  -0.5258  0.4449 -0.528 1.725 0.14801 0.345    \n2  -0.1195  0.0944 -0.122 1.716 0.00847 0.248    \n3  -0.3417  0.2409 -0.367 1.333 0.07057 0.176    \n4   0.6158 -0.3473  0.750 0.622 0.20736 0.127    \n5  -0.1876  0.0529 -0.308 1.164 0.04862 0.103    \n6   0.1743  0.0983  0.573 0.734 0.13326 0.103    \n7   0.0000  0.1695  0.366 1.169 0.06771 0.127    \n8   0.0677 -0.1908 -0.291 1.419 0.04570 0.176    \n9   0.0450 -0.0888 -0.115 1.718 0.00750 0.248    \n10  0.3208 -0.5429 -0.644 1.613 0.21314 0.345    \n```\n\n\n:::\n\n```{.r .cell-code}\ndat6.lm |> fortify()\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n     y  x      .hat    .sigma     .cooksd   .fitted      .resid  .stdresid\n1  0.0  1 0.3454545 0.2165384 0.148014601 0.1272727 -0.12727273 -0.7489309\n2  0.2  2 0.2484848 0.2238334 0.008468314 0.2412121 -0.04121212 -0.2263249\n3  0.2  3 0.1757576 0.2150630 0.070573026 0.3551515 -0.15515152 -0.8135885\n4  0.8  4 0.1272727 0.1802776 0.207356771 0.4690909  0.33090909  1.6863422\n5  0.4  5 0.1030303 0.2123412 0.048615863 0.5830303 -0.18303030 -0.9200478\n6  1.0  6 0.1030303 0.1892068 0.133261324 0.6969697  0.30303030  1.5232580\n7  1.0  7 0.1272727 0.2111195 0.067708333 0.8109091  0.18909091  0.9636241\n8  0.8  8 0.1757576 0.2184552 0.045697585 0.9248485 -0.12484848 -0.6546845\n9  1.0  9 0.2484848 0.2239157 0.007501344 1.0387879 -0.03878788 -0.2130117\n10 1.0 10 0.3454545 0.2129163 0.213141026 1.1527273 -0.15272727 -0.8987170\n```\n\n\n:::\n:::\n\n\n\n**Conclusions**:\n\n- there are no obvious issues with the influence values\n\n### Performance model checking\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\ndat6.lm |> performance::check_model()\n```\n\n::: {.cell-output-display}\n![](30_glm_files/figure-html/validateModel6a1-1.png){width=768}\n:::\n\n```{.r .cell-code}\ndat6.lm |> performance::check_outliers()\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nOK: No outliers detected.\n- Based on the following method and threshold: cook (0.8).\n- For variable: (Whole model)\n```\n\n\n:::\n:::\n\n\n\n**Conclusions**:\n\n- the observed density and simulated densities in the Posterior\n  Predictive Check plot are inconsistent \n  - the observed data show two peaks (associated with 0's and 1's)\n  - the posterior predictions show a single peak between 0 and 1\n- there is clear evidence of a non-linear trend in the standardised\n  residuals plot\n- dots do not fall along the Q-Q plot line (particularly those in\n  the tails)\n\n### DHARMa (simulated) residuals\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\ndat6.resid <- dat6.lm |> \n  simulateResiduals(plot = TRUE)\n```\n\n::: {.cell-output-display}\n![](30_glm_files/figure-html/validateModel6b1-1.png){width=768}\n:::\n:::\n\n\n\n**Conclusions**:\n\n- interesting the simulated residuals look acceptable\n\n:::::\n\n### Summarise model\n\nSince the model diagnostics indicated violations of the assumptions,\nwe will not explore the model summaries\n\n### Model performance\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nperformance::model_performance(dat6.lm)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n# Indices of model performance\n\nAIC   |  AICc |   BIC |    R2 | R2 (adj.) |  RMSE | Sigma\n---------------------------------------------------------\n0.939 | 4.939 | 1.847 | 0.752 |     0.721 | 0.188 | 0.210\n```\n\n\n:::\n:::\n\n\n::::\n\n \n:::\n# Generalised linear models\n\n## Summary\n\nThe callout below contains a lot of detail that some might find\nexcessive and unnecessary if you only need to know how to fit a\nGeneralised Linear Model (GLM). Whilst it is useful to have a more\nin-depth understanding of the concepts and mathematics behind\nstatistical routines in preparation to fitting models, the follwing\nsummary might suffice for those seeking a quicker overview.\n\nThe essential points are:\n\n- GLM's take on the form of:\n\n    $$\n    \\begin{align}\n    Y \\sim{}& D(\\boldsymbol{\\eta}, ...)\\\\\n    g(\\boldsymbol{\\eta}) =& \\boldsymbol{X}\\boldsymbol{\\beta}\\\\\n    \\end{align}\n    $$\n    \n    where $D$ represents the nominated distribution to model the data\n    against and $g()$ represents a _link_ function that is used to map\n    the scale of the expected values [$-\\infty, \\infty$] to the scale\n    of data under the nominated distribution.\n\n- there is no closed form solution to find the values of the\n  parameters that best fit the data.\n- rather than find a solution based on minimising the residuals, GLM's\n  operate on likelihood. Likelihood is a calculation of the\n  probability of obtaining the observed data for a specific\n  combination of parameter values. maximising the (log) likelihood of\n  the given set of parameters given the observed data.\n- Maximum Likelihood Estimation (MLE) is the process of finding the\n  specific combination of parameter values that maximise the (log)\n  likelihood of observing the data.\n- there are numerous optimisation algorithms designed to efficiently\n  explore the entire possible parameter space tp find the MLE\n- the role of many R GLM model fitting routines is to define the\n  appropriate likelihood function for the specified model and data and\n  to pass this on to a optimisation routine.\n\nIf all you desire is a overview, you can now skip down to the section\non Fitting GLM's.\n\n\n::::::: {.callout-note collapse=\"true\"}\n## Details about Maximum Likelihood and Optimasation\n\nRecall from the previous section that the simple linear model can be written as:\n$$\n\\begin{align}\ny_i =& \\beta_0 + \\beta_1 x_i + \\varepsilon_i\\\\\nY =& \\boldsymbol{X}\\boldsymbol{\\beta} + \\boldsymbol{\\varepsilon}\n\\end{align}\n$$\n\nThis could be re-written as:\n\n$$\n\\begin{align}\ny_i \\sim{}& N(\\mu_i, \\sigma^2I)\\\\\n\\mu_i =& \\beta_0 + \\beta_1 x_i\\\\\n\\end{align}\n$$\n\nindicating that the response ($y$) is distributed as a Gaussian (normal) the\nmean of which is determined by the linear relationship with $x$ and there is a\nconstant variance ($\\sigma^2$) - all observations are independently and\nidentically distributed (_iid_) - independently drawn from a distribution with\nthe same variance.\n\nThe $I$ signifies an identity matrix (a square matrix whose diagonals are all one).\n\nMore generally, the above can be written in vector/matrix form as:\n$$\n\\begin{align}\nY \\sim{}& N(\\boldsymbol{\\mu}, \\sigma^2I)\\\\\n\\boldsymbol{\\mu} =& \\boldsymbol{X}\\boldsymbol{\\beta}\\\\\n\\end{align}\n$$\n\nIf we suspect that the residuals are not independent and identically distributed\n(if for example they were Poisson distributed), then we could alter (generalise)\nthe above to:\n\n$$\n\\begin{align}\nY \\sim{}& N(\\boldsymbol{\\mu}, \\sigma^2\\boldsymbol{W}^{-1})\\\\\n\\boldsymbol{\\mu} =& \\boldsymbol{X}\\boldsymbol{\\beta}\\\\\n\\end{align}\n$$\n\nwhere $\\boldsymbol{W}$ is a matrix of positive diagonals .\n\nThis allows us to generalise to other (exponential) families (such as Binomial,\nPoisson, Negative Binomial, Gamma etc).  For example, if our response ($Y$) were\ncount data, we might consider a Poisson.\n\n$$\n\\begin{align}\nY \\sim{}& Pois(\\boldsymbol{\\lambda})\\\\\n\\boldsymbol{\\lambda} =& e^{\\boldsymbol{X}\\boldsymbol{\\beta}}\\\\\n&\\text{OR equivalently}\\\\\nlog(\\boldsymbol{\\lambda}) =& \\boldsymbol{X}\\boldsymbol{\\beta}\\\\\n\\end{align}\n$$\n\nThe Poisson distribution ($P(x|\\lambda) = e^{-\\lambda}\\lambda^x/x!$) is\nparameterised by a single parameter ($\\lambda$) that represents both the mean\nand variance (as well as degrees of freedom).  Poisson data are bound at the\nlower end by zero (negative values are not defined) - it is not possible to\ncount fewer than 0 things.  The Poisson family includes an exponential term,\ntherefore to map the expected values back onto the natural scale (scale of the\nobserved data), we use a **link** function (in the case of the Poission, this\nlink is a log link).  Hence the above can be generalized even further to:\n\n$$\n\\begin{align}\nY \\sim{}& D(\\boldsymbol{\\eta}, ...)\\\\\ng(\\boldsymbol{\\eta}) =& \\boldsymbol{X}\\boldsymbol{\\beta}\\\\\n\\end{align}\n$$\n\nwhere $D$ is the nominated family, $g$ is the link function and $...$ represents\nany additional parameters required by the nominated distribution (such as\n$\\sigma^2\\boldsymbol{W}^{-1}$ in the case of the Gaussian distribution).\n\n\n## Maximum likelihood\n\nOrdinary Least Squares provides an elegant solution for when the data\nsatisfy certain assumptions (normality, homogeneity, independence,\netc), yet for many other situations, it is not appropriate.\n\nFor the following demonstrations, we will use the data from Motivating\nexample 1.\n\nAs with OLS, lets start with motivating example 1 data\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\ndat$y\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n [1]  9.64  3.79 11.00 27.88 32.84 32.56 37.84 29.86 45.05 47.65\n```\n\n\n:::\n:::\n\n\n\nA more general alternative to OLS is Maximum Likelihood (ML).\n\nLikelihood is a measure of how probable (likely) a set of observations\nare at following (or being drawn from) a specific distribution. For\nexample, we could evaluate the likelihood that the observations could\nhave come from a normal (Gaussian) distribution with a specific mean\nand standard deviation.\n\nBefore we can understand likelihood, we must first remind ourselves of\na couple of things about probability.\n\n1. for any continuous distribution, the probability of obtaining a\n   specific values (that is, that a specific value ($X$) is equal to a\n   particular reference values ($x$)) is infinitely small\n   ($Pr(X=x)=0$). We can only directly estimate probabilities of\n   obtaining values less than (or greater than) nominated reference\n   points (quantiles).\n2. it is possible to calculate the probability that a specific value\n   ($X$) is between two reference points ($Q1$ and $Q2$). This is just\n   the probability of $X$ being less than Q1 minus the probability of\n   $X$ being less than Q2 ($Pr(Q1 < X > Q2)$).\n\nSo although we cant estimate the probability that $Pr(X=x)$ directly\nfrom the distributions' function ($f(x)$), we can approximate this by\ncalculating the probability that $X$ is in the interval $[x,\nx+\\Delta]$:\n\n$$\n\\frac{Pr(x < X \\le x + \\Delta)}{\\Delta}\n$$\n\n\nThe smaller $\\Delta$ (so long as it is larger than 0), the more accurate the\nestimate.  This becomes a simple calculus problem.  The derivative ($f'(x)$) of\nthe distributions' function is a **probability density function** (PDF).  The\nPDF allows us to approximate the probability of obtaining a single value from a\ndistribution.\n\nProvided the data are all iid (individually and identically distributed), and\nthus from the same distribution, the probability (likelihood) that a set of\nvalues ($X$) comes from a specific distribution (described by its parameters,\n$\\theta$) can be calculated as the product of their individual probabilities.\n\n$$\nL(X|\\theta) = \\prod^n_{i=1} f'(x_i|\\theta)\n$$\n\nThe products of probability densities can soon become very small and this can\nlead to computation and rounding issues.  Hence it is more usual to work with\nthe logarithms of likelihood.  The log laws indicate that the log of a product\nis the same as the sum of the individual logs ($log(A\\times B) = log(A) +\nlog(B)$).\n\n$$\nLL(X|\\theta) = \\sum^n_{i=1} log(f'(x_i|\\theta))\n$$\n\n\nThe PDF of a Gaussian distribution is:\n\n$$\nP(x|\\mu, \\sigma) = \\frac{1}{\\sqrt{\\sigma^2 2\\pi}} exp^{-\\frac{1}{2}((x-\\mu)/\\sigma)^2}\n$$\n\nSo in order to estimate the optimum values for the parameters ($\\mu$ and $\\sigma$), given our data ($x$), we would maximize the following:\n\nReturning to our example, \n\n$$\n\\begin{align}\nLL(x_1, x_2, x_3, ..., x_n|\\mu, \\sigma^2) =& \\sum^n_{i=1}ln(\\frac{1}{\\sqrt{\\sigma^2 2\\pi}} exp^{-\\frac{1}{2}((x_i-\\mu)/\\sigma)^2})\\\\\n=& -\\frac{n}{2}ln(2\\pi\\sigma^2)-\\frac{1}{2\\sigma^2}\\sum^n_{i=1}(x_i-\\mu)^2\n\\end{align}\n$$\n\n\n\n**Note** optimization routines usually attempt to minimize rather than maximize.\nNevertheless, finding the maximum of a log-likelihood (what we are after) is the\nsame as finding the minimum of the negative log-likelihood.\n\nFor the examples and routines that follow, we will write our own code from first\nprinciples as well as use existing built in R functions.  Although the code that\nwe write could be written to find maximums, the inbuilt functions typically\noptimise on minimums.  As a result, to enable us to compare routines, we will\nwork with **minimizing negative log-likelihood**.\n\nDo, lets now write a function for calculating the negative log-likelihood for\nour data given a Gaussian distribution based on the formula above.\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nLL.gaus = function(theta, x) {\n    m=theta[1]\n    s=theta[2]\n    ll = -(length(x)/2)*(log(2*pi*s^2)) + (-1/(2*s^2)) * sum((x-m)^2)\n    ##OR\n    ## ll = sum(dnorm(x, mean=m, sd=s, log=TRUE))\n    return(-ll)\n}\n```\n:::\n\n\n\n\nIn a similar manner to the brute force approach we used to approximate OLS\nearlier, lets use a brute force approach to explore the partial negative\nlog-likelihood profile for the mean and then approximate the mean (we will fix\nthe standard deviation at 1).  We refer to it as a partial profile, because it\nis holding the other parameter constant.\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nmu = seq(15,40,len=1000)\ntheta=cbind(mu=mu,sigma=1)\nB=apply(theta, 1, LL.gaus, dat$y)\ntheta[which(B==min(B)),]\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n      mu    sigma \n27.81281  1.00000 \n```\n\n\n:::\n\n```{.r .cell-code}\nggplot(data=NULL) + geom_line(aes(y=B, x=theta[,'mu']))\n```\n\n::: {.cell-output-display}\n![](30_glm_files/figure-html/mle-1.png){width=672}\n:::\n:::\n\n\n\nAgain, this estimation is very close to the 'true' value.\n\n\n## Optimization \n\nOptimization algorithms are essentially search algorithms. They are\nattempting to find a single point in multidimensional space. There are\nnumerous types of algorithms, each of which offers different\nadvantages and disadvantages under different circumstances. For\nexample, some assume that the underlying likelihood is very smooth\n(changes very gradually) and gain efficiencies out of being able to\nlocated minimums via differentiation. Others are less efficient, yet\nmore accurate when the likelihood is not smooth or there are multiple\nlocal minima.\n\nLets use an analogy to gain a better appreciation of the problem and\nsolutions. Imagine we had a big block of land and we wanted to install\na well from which to draw water from an underground aquifer. Although\nthere are no physical restrictions on where the well can be\npositioned, we are keen on it being as shallow as possible (perhaps\nbecause it is cheaper to drill a shallow well).\n\nThe depth from the land surface down to the aquifer is not constant\nover space and we want to be able to put our well in the shallowest\npoint. Although we do not know the true underground topography, we can\ndrill narrow pilot holes and accurately measure the depth down to the\naquifer at any point in space.\n\nTo put this another way, although we do not know what the underground\nprofile looks like throughout the entire spatial domain (all possible\nlatitide/longitude values), we can estimate its value (depth) at any\npoint (single latitude/longitude).\n\n<!-- The same is true of a (log)likelihood function - although we do not know what it -->\n<!-- looks like, we can evaluate it for any combination of parameters. -->\n\nTo find the optimum location for our well, we need a search algorithm.\nOne that is able to find the latitude/longitude associated with the\nminimum depth. We will showcase a few different options and try to\ndescribe the advantages and disadvantages of each. For example, in our\nwell analogy, if the depth profile was very smooth (undulated very\nslowly), we might be able to use approximations to the curvature of\nthe undulations to find where any minimums are. On the other hand, if\nthe profile is not smooth (perhaps there are underground caves or\nother abrupt underground geological features), such approximations may\nbe very inaccurate and more exhaustive searching (such as a grid of\npilot holes) may be required.\n\nJust like with the underground aquifer, although a (negative)\nlog-likelihood function has an unknown profile in multidimensional\nspace (one dimension for each parameter to estimate), we can evaluate\nit for any combination of parameters.\n\n::: {.panel-tabset}\n\n### Brute force\n\nOne conceptually simple way of searching for the minimum of a function is to\nevaluate the function for a large number of parameter combinations (perhaps in a\ngrid).  For example, to drill a pilot hole every 100m in a grid.  If the grid is\nfine enough, it will located the minimum (maximum) no matter what the functions\nprofile is. However, the finer the grid, the more effort is required - lower\nefficiency.\n\nThe following code chunk evaluates and plots the negative log-likelihood for a\nfull ($100\\times 100$) grid of parameter combinations.  Negative log-likelihood\nis represented as a colour along the green to white spectrum.  The blue lines\nrepresent major contours in the profile. The optimum parameters (those\nassociated with the minimum negative log-likelihood and thus maximum\nlog-likelihood) are indicated by the black solid point.\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nmu = seq(15,40,len=100)\nsigma=seq(10,20,len=100)\ntheta = expand.grid(mu=mu, sigma=sigma)\ntheta$LL=apply(theta, 1, LL.gaus, x=dat$y)\nggplot(data=theta,aes(y=mu, x=sigma, fill=LL)) +\n    geom_tile(show.legend=FALSE) + geom_contour(aes(z=LL)) +\n    geom_point(data=theta[which(theta$LL==min(theta$LL)),], aes(y=mu, x=sigma), fill='black') +\n    scale_fill_gradientn(colors=terrain.colors(12)) +\n    scale_x_continuous(expand=c(0,0)) +\n    scale_y_continuous(expand=c(0,0))\n```\n\n::: {.cell-output .cell-output-stderr}\n\n```\nWarning: The following aesthetics were dropped during statistical transformation: fill.\nℹ This can happen when ggplot fails to infer the correct grouping structure in\n  the data.\nℹ Did you forget to specify a `group` aesthetic or to convert a numerical\n  variable into a factor?\n```\n\n\n:::\n\n::: {.cell-output-display}\n![](30_glm_files/figure-html/bruteForce-1.png){width=384}\n:::\n\n```{.r .cell-code}\ntheta[which(theta$LL==min(theta$LL)),]\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n           mu    sigma       LL\n4252 27.87879 14.24242 40.76342\n```\n\n\n:::\n:::\n\n\nThe optimum solution yielded an estimated mean of \n27.8787879 and sigma of \n14.2424242.  These values are very similar\nto the empirical calculations.\n\nThe brute force approach is a useful illustration, but it is practically limited\nto just a one or two parameters and since the entire search space within the\ndomain needs to be evaluated.  This is essentially an exhaustive search\nalgorithm.  Furthermore, the accuracy is dependent on the resolution of the\ngrid.  The finer the grid, the more accurate, however it does require $n^p$\nfunction evaluations (where $n$ is the number of grid increments per $p$\nparameters.\n\nOf course, we can always use a relatively course search grid and having\nidentified the 'optimum' parameter configuration within this grid, we could\napply a finer resolution grid over a narrower search domain.  This is analogous\nto starting with a 100x100m drilling grid and then centring a 1x1m drilling grid\naround the 'best' location.\n\n\n### Simplex methods\n\nA _simplex_ is a multidimensional space that has one more vertex than there are\nparameter dimensions ($p+1$).  In this case, we are estimating two parameters,\ntherefore the simplex is a triangle (three vertices).  The most common form of\nsimplex optimisation is the **Nelder-Mead** algorithm.  As with most optimisation\nalgorithms, the Nelder-Mead algorithm is a search algorithm that aims to find a\npoint in multidimensional space as efficiently as possible.\n\nOptimisation routines work on a wide variety of function (not just likelihood\nfunctions).  To keep the terminology about what is being optimised general, the\nfunction to be optimised is often referred to as a **loss** or **objective**\nfunction. A loss function is any function that evaluates the performance (or\nfit) of a set of events (i.e. data).  The further the loss is from zero, the\nworse the fit (hence the desire to find the minimum).\n\nThe Nelder-Mead algorithm can be described as (keep in mind that it is a\nminimisation rather than maximisation):\n\n1. Start with some initial estimate values - e.g. a set of $p+1$ vertices for\n   each parameter.\n2. Identify the vertex with the highest (ie worst) loss (negative log-likelihood).\n3. Reflect the simplex around the centroid of the other vertices \n    3a. If the reflected point is better (lower negative log-likelihood) than the second\n\t\tworst point, but not better than the best point, replace the worst point\n\t\twith the reflected point.\n    3b. If instead, the reflected point is the best vertex, then expand this\n\t    point by doubling the reflection distance\n\t\t\n        3b.1.  If this expanded point is better than the reflected point,\n\t\t       replace the worst point with the expanded point\n        3b.2   Otherwise replace the worst point with the reflected point.\n\t\t\n    3c. If instead neither 3a or 3b (the reflected point is not better than the\n\t\tsecond worst point, then contract the point by halving the reflection\n\t\tdistance.\n\t\t\n        3c.1.  If this contracted point is better than the worst point, replace the worst point with the contracted point\n        3c.2.  Otherwise, shrink the entire simplex (contract all vertices towards the centroid)\n\t\t\n4. Repeat Steps 2-3 until either the maximum number of iterations have occurred\n   or the change in loss between two successive iterations is below a\n   certain threshold.\n\nClearly, the more iterations are performed, the more accurate the estimates, and\nyet the longer the search will take.\n\nIn the well analogy, the simplex represents three points of the search triangle.\nReflecting the triangle allows us to move away from the direction we know to be\ndeeper.  We expand the triangle in order to explore a new direction and contract\nthe triangle to narrow our search area.\n\nCode for illustrating the process is listed as details below.  This code is a modification of the\ncode presented in\n<https://github.com/nicolaivicol/nelder-mead-R/blob/master/optimNM.R>\n\n\n:::: {.callout-note collapse=\"true\"}\n### See the function\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nget.optim.NM <- function(X.vert, params.init, objective.fn, iter.max=250, abs.tol=0.0001, x, control=list(fnscale=1,refl=1,expan=2,contr=-0.5,shrink=0.5))\n{\n  # input dimension\n  X.len <- length(params.init)\n  # initialize controls before iterations of searching\n  iter <- 0; not.converged <- 1; not.max.iter <- 1\n  X.optim <- params.init; f_X.optim <- control$fnscale*objective.fn(X.optim, x=x)\n  # while loop, iterations\n  while (not.converged & not.max.iter)\n  {\n    # get values at vertices\n    f_X.vert <- control$fnscale*apply(X = X.vert, MARGIN = 1, FUN = objective.fn, x) \n    # order ascending X.vert and f(X.vert), by f(X.vert)\n    X.order <- sort(f_X.vert, index.return = TRUE)$ix\n    X.vert <- X.vert[X.order, ]\n    f_X.vert <- f_X.vert[X.order]\n    # get centroid (mean on each dimension) of all points except the worst\n    X.centr <- apply(X = X.vert[1:X.len, ], MARGIN = 2, FUN = mean)\n    # get reflected point\n    X.refl <- X.centr + control$refl*(X.centr - X.vert[X.len+1, ])\n    f_X.refl <- control$fnscale*objective.fn(X.refl,x)\n    if ((f_X.vert[1] <= f_X.refl) & (f_X.refl < f_X.vert[X.len]))\n    { \n      # if the reflected point is better than the second worst, but not better than the best...\n      # ... then obtain a new simplex by replacing the worst point with the reflected point\n      X.vert[X.len+1, ] <- X.refl \n    } else if (f_X.refl < f_X.vert[1]) {\n      # if the reflected point is the best point so far\n      # ... then compute the expanded point\n      X.expan <- X.centr + control$expan*(X.centr - X.vert[X.len+1, ])\n      f_X.expan <- control$fnscale*objective.fn(X.expan,x)\n      # ... if the expanded point is better than the reflected point\n      if (f_X.expan < f_X.refl)\n      {\n        # ... then obtain a new simplex by replacing the worst point with the expanded point\n        X.vert[X.len+1, ] <- X.expan   \n      } else {\n        # ... else obtain a new simplex by replacing the worst point with the reflected point\n        X.vert[X.len+1, ] <- X.refl\n      }\n    } else {\n      # ... reflected point is not better than second worst\n      # ... then compute the contracted point\n      X.contr <- X.centr + control$contr*(X.centr - X.vert[X.len+1, ])\n      f_X.contr <- control$fnscale*objective.fn(X.contr,x)\n      # ... if the contracted point is better than the worst point\n      if (f_X.contr < f_X.vert[X.len+1])\n      {\n        # ... then obtain a new simplex by replacing the worst point with the contracted point\n        X.vert[X.len+1, ] <- X.contr\n      } else {\n        # ... shrink the simplex: X = X1 + coef.shrink(X-X1)\n        X.vert <- sweep(control$shrink*sweep(X.vert, 2, X.vert[1, ], FUN = \"-\"), 2, X.vert[1, ], FUN=\"+\")\n      }    \n    }\n    # get values at vertices\n    f_X.vert <- control$fnscale*apply(X = X.vert, MARGIN = 1, FUN = objective.fn, x) \n    # order asc X.vert and f(X.vert)\n    X.order <- sort(f_X.vert, index.return = TRUE)$ix\n    X.vert <- X.vert[X.order, ]\n    f_X.vert <- f_X.vert[X.order]   \n    # update controls\n    iter <- iter + 1 \n    not.max.iter <- (iter < iter.max)*1\n    not.converged <- (abs(control$fnscale*objective.fn(X.vert[X.len, ],x)- control$fnscale*objective.fn(X.vert[1, ],x)) > abs.tol)*1\n    \n    X.optim <- X.vert[1, ]; f_X.optim <- control$fnscale*objective.fn(X.optim,x)\n  }\n  return(list(X.optim=X.optim, f_X.optim=f_X.optim, X.vert=X.vert, iter=iter))   \n}\n```\n:::\n\n\n    \n::::\n\nWe can illustrate the iterative process by plotting the outcome of a limited\nnumber of iterations - in this case 10 iterations.  In this illustration, the\nfilled in triangle represents the current optimum simplex.  Previous simplexes\nremain as open triangle.\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\n## Starting values at the center of the vectices\nparams.init <- c(mu = 20, sigma = 12)\nd.mu <- 0.5\nd.sigma <- 0.3\nsimplex <- rbind(Vertex1 = params.init + c(d.mu,d.sigma),\n  Vertex2 = params.init + c(-d.mu, d.sigma),\n  Vertex3 = params.init + c(-d.mu, -d.sigma)) |>\n  data.frame()\nbase.plot <- ggplot(data = theta, aes(y = mu, x = sigma)) +\n  geom_tile(aes(fill = LL), show.legend = FALSE) + \n  geom_contour(aes(z = LL)) +\n  scale_fill_gradientn(colors = terrain.colors(12)) +\n  scale_x_continuous(expand = c(0,0)) +\n  scale_y_continuous(expand = c(0,0))\n\nnewdata <- vector('list', 15)\na <- get.optim.NM(X.vert = as.matrix(simplex), params.init, objective.fn = LL.gaus, x = dat$y, iter.max = 1, control = list(fnscale = 1, refl = 1, expan = 2, contr = -0.5, shrink = 0.5))\nnewdata[[1]] <- data.frame(a$X.vert)\nfor (i in 2:15) {\n  a <- get.optim.NM(X.vert = a$X.vert, params.init = a$X.optim, objective.fn = LL.gaus, x = dat$y, iter.max = 1, control = list(fnscale = 1, refl = 1, expan = 2, contr = -0.5, shrink = 0.5))\n  newdata[[i]] <- data.frame(a$X.vert)\n}\nnewdata <- bind_rows(newdata, .id = 'Iter') |> \n  mutate(Iter=factor(Iter, levels = unique(Iter)))\ng <- base.plot + \n  geom_polygon(data = newdata, aes(y = mu, x = sigma, group = Iter), \n    color = 'black', fill = 'grey40') +\n  transition_manual(Iter) + \n  shadow_trail(distance = 0.1, alpha = 0.4, color = 'grey40', fill = NA) + \n  labs(title = 'Iter: {current_frame}')\nga <- animate(g, fps = 20, duration = 15)\n#ga=animate(g, renderer=av_renderer())\nanim_save('simplexAnim.gif', animation = ga, path = '../resources/',  renderer =av_renderer()) \n```\n:::\n\n\n\n\n![](../resources/simplexAnim.gif)\n\n\nHaving seen this illustration, we could allow the Nelder-Mead simplex\noptimization to iterate more thoroughly. We will now instruct the\nroutine to iterate a maximum of 250 times. Along with setting a\nmaximum number of iterations, most optimizations also have a stopping\ntrigger based around the extent of improvement between iterations.\nThis convergence tolerance defines a threshold difference below which\ntwo successive iteration outcomes are considered the same. The lower\nthe value, the more accuracy is demanded.\n\nIt is also a good idea to repeat the iterations again from multiple\nstarting configurations to ensure that any single optimization has not\njust settled n a local minimum (maximum).\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nget.optim.NM(X.vert = as.matrix(simplex), params.init, objective.fn = LL.gaus, \n  x = dat$y, iter.max = 250, abs.tol = 1e-08, \n  control = list(fnscale = 1, refl = 1, expan = 2, contr = -0.5, shrink = 0.5))\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n$X.optim\n      mu    sigma \n27.81238 14.25925 \n\n$f_X.optim\n   sigma \n40.76329 \n\n$X.vert\n              mu    sigma\nVertex3 27.81238 14.25925\nVertex2 27.80955 14.25881\nVertex1 27.81327 14.25858\n\n$iter\n[1] 32\n```\n\n\n:::\n\n```{.r .cell-code}\nget.optim.NM(X.vert = as.matrix(simplex - c(-0.5, 0.2)), params.init, objective.fn = LL.gaus, \n  x = dat$y, iter.max = 250, abs.tol = 1e-08, \n  control = list(fnscale = 1, refl = 1, expan = 2, contr = -0.5, shrink = 0.5))\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n$X.optim\n      mu    sigma \n27.81122 14.25812 \n\n$f_X.optim\n   sigma \n40.76329 \n\n$X.vert\n              mu    sigma\nVertex1 27.81122 14.25812\nVertex2 27.80970 14.25939\nVertex3 27.81149 14.26005\n\n$iter\n[1] 38\n```\n\n\n:::\n:::\n\n\n\nThe two sets of estimated parameters (listed as `X.optim`) are very\nsimilar (converged) and are very similar to those calculated\nempirically.\n\nR has an inbuilt function (`optim()`) that is an interface to numerous\noptimization algorithms, and the default algorithm is `Nelder-Mead`.\nAs with other optimizations, `optim()` defaults to minimizing. To\nforce it to maximize (if our likelihood function returned\nlog-likelihood rather than negative log-likelihood), we can indicate\nthat the `fnscale` is -1. Other important optimization _control\nparameters_ include:\n\n- `maxit` - the maximum number of iterations to perform (100 for\n  Nelder-Mead).\n- `abstol` - the absolute convergence tolerance. The lower the\n   tolerance, the smaller the change in optimized value\n   (log-likelihood) required before convergence is reached.\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\noptim(par = c(20, 12), LL.gaus, x = dat$y, control = list(fnscale = 1))\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n$par\n[1] 27.81143 14.25771\n\n$value\n[1] 40.76329\n\n$counts\nfunction gradient \n      53       NA \n\n$convergence\n[1] 0\n\n$message\nNULL\n```\n\n\n:::\n:::\n\n\n\nWe can see that the negative log-likelihood calculation was performed\n51 times before convergence. Whilst this is not the same as the number\nof iterations, it does provide an estimate of the total computation\nload.\n\nIf we compare this to the brute force approach (which required\n$100\\times 100=10,000$ evaluations), the Nelder-Mead simplex approach\nis a substantial improvement.\n\n\n### Derivative methods\n\nIf the profile of a function is smooth enough, and the function itself\nis doubly differentiable (can be differentiated into first and second\norder derivatives), then we can make use of a group of algorithms\nbased on a root-finding algorithm devised by Isaac Newton. In\nmathematical contexts, a root is the value of the parameters ($x$)\nwhen the function equals zero ($f(x)=0$).\n\nA simplified version of Newton's method, the **Newton-Raphson method**\nshows that root ($x_{n+1}$) of a function ($f(x_n)$) can be\napproximated by iteratively solving:\n\n$$\nx_{n+1} = x_n - \\frac{f(x_n)}{f'(x_n)}\n$$\n\nwhere $x_n$ is the initial parameter estimate, $x_{n+1}$ is the\nimproved parameter estimate, $f(x_n)$ is the value of the function at\n$x_ n$ and $f'(x_n)$ is the first order derivative (the slope) of the\nfunction at $x_n)$.\n\nBefore we use this approach to estimate maximum likelihood estimates,\nlets see how it works with a polynomial function (e.g. $y=0.1x^4 +\nx^3 - x^2 + 30$).\n\nIn the following animation, we will use the Newton-Raphson method to\nestimate the value of $x$ when $y=0$. The animation will go through\nfive iterations. For each iteration, the red line represents the slope\nassociated with the initial estimate of $x$. The point where this line\nintersects with the dashed line ($y=0$) is the updated estimate for\n$x$. We can see that by the fifth iteration, the estimated $x$ is has\nbegan to stabalise (converge) on a value of approximately $1.98$.\n\n\n:::: {.callout-note collapse=\"true\"}\n### Code used to implement Newton-Raphson method for simple functions and generate animation\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nNR <- function(f, x, return.grid=FALSE) {\n    if (is.function(f)) f=body(f)[[2]]    \n    f_x = eval(f)\n    f._x = eval(D(f,'x'))\n    if (return.grid) {\n        list(x1=x - f_x/f._x, f_x=f_x, f._x=f._x)\n    }else {\n        list(x1=x - f_x/f._x)\n    }\n}\noptim.NR <- function(f, x0, abs.tol=1.0E-6, iter.max=250, return.grid=FALSE) {\n    iter <- 0; not.converged <- 1; not.max.iter <- 1\n    fgrid <- list()\n    while (not.converged & not.max.iter) {\n        nr <- NR(f, x = x0, return.grid)\n        x1 <- nr$x1\n        iter <- iter + 1 \n        not.max.iter <- (iter < iter.max)*1\n        not.converged <- (abs(x0-x1) > abs.tol)*1\n        if (return.grid) fgrid[[iter]] <- c(x0 = x0, x1 = x1, f_x = nr$f_x, f._x = nr$f._x)\n        x0 <- x1\n    }\n    list(X.optim = x0, iter = iter, grid = do.call('rbind', fgrid))\n}\n```\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\nf <- function(x) {0.1*x^4 + x^3 - x^2 + 10*x + 30} \na <- optim.NR(f, x0 = 3, abs.tol = 0.001, return.grid = TRUE)\n\nx <- seq(-4, 4, len = 100)\ndat1 <- data.frame(x = x, y = f(x))\ngdat <- a$grid %>% as.data.frame |>\n    mutate(Iter = 1:n(),\n           x = ifelse(x0>0, x0+1, x0-1),\n           y = f_x + (x-x0)*f._x)\n\ng <- ggplot() + geom_line(data = dat1, aes(y = y, x = x)) +\n    geom_hline(yintercept = 0, linetype = 'dashed') +\n    geom_segment(data = gdat, aes(x = x, y = y, xend = x1, yend = 0), color = 'red') +\n    geom_segment(data = gdat, aes(x = x0, xend = x0, y = 0, yend = f_x), linetype = 'dashed')+\n    geom_text(data = gdat |> filter(Iter<4), aes(x = x0, y = -5, label = \"x[0]\"), parse = TRUE) +\n    geom_text(data = gdat %>% filter(Iter<4), aes(x = x1, y = -5, label = \"x[1]\"), parse = TRUE) +\n    geom_point(data = gdat, aes(x = x0, y = f_x)) +\n    geom_text(data = gdat |> filter(Iter<4), aes(x = x0, y = f_x, label = \"f(x)\"), \n      parse = TRUE, nudge_x = 0.1, nudge_y = -5, hjust = 0, vjust = 0) +\n    geom_text(data = gdat |> filter(Iter<4), aes(x = x0+0.3+(x1-x0)/2, y = (f_x/2)-5, label = \"f*minute*(x)\"), \n      parse = TRUE, color = 'red') +\n    geom_text(data = gdat, aes(x = -4, y = 140, label = paste0(\"Iter == \", Iter)), parse = TRUE, hjust = 0) +\n    geom_text(data = gdat, aes(x = -4, y = 120, label = paste0(\"x[1] == \", round(x1, 3))), parse = TRUE, hjust = 0) +\n    transition_manual(Iter)\nga <- animate(g, fps = 20, duration = 5)\nanim_save('NMAnim1.gif', animation = ga, path = '../resources')\n```\n:::\n\n\n::::\n\n![](../resources/NMAnim1.gif)\n\n\nIf we allow our implementation of the Newton-Raphson method to run\nfrom an initial guess of 3 until it converges:\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\noptim.NR(f, x0=3)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n$X.optim\n[1] -1.982394\n\n$iter\n[1] 6\n\n$grid\nNULL\n```\n\n\n:::\n:::\n\n\n\nWe see that it takes just 6 to converge.\n\nIn the above, we estimated the root (value of $x$ when $f(x)=0$) of a\nfunction. If instead, we want to find the value of $x$ when the\nfunction is at its minimum (e.g. optimisation), then we want to find\nthe root of the first derivative ($f'(x)$) of the function - that is,\nwe want to find the value of $x$ where the slope of $f(x)$ is 0.\n\nAgain, in order to illustrate the principles of what we are trying to\nachieve, we must digress from our actual example. Rather than try to\nfind the root of a function, we will now try to find the root of the\nderivative of a function (so as to find the minimum of a function). So\nwe are now shifting our focus away from the profile of the function\nand onto the profile of the derivative of the function (since the\nderivative of a function is a slope profile).\n\nThe left hand side of the following figure represents the profile of\nthe function ($y = 0.001x^3 - 0.001x^2 - 0.3x + 5$). The right hand\nside represents the derivative ($0.001(3x^2) - 0.301(2x)$) of that\nfunction.\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nf <- function(x) {0.001*x^3 - 0.001*x^2 -0.3*x + 5}\nf1 <- D(body(f)[[2]], 'x')\nx <- seq(0, 20, len = 100)\ndat1 <- data.frame(x = x, y = f(x))\ng1 <- ggplot() + \n  geom_line(data = dat1, aes(y = y, x = x)) \n\ng2 <- ggplot() + \n  geom_line(data = data.frame(x = x, y = eval(f1, envi = list(x = x))), aes(y = y, x = x)) +\n  geom_hline(yintercept = 0, linetype = 'dashed')\ngrid.arrange(g1, g2, nrow = 1)\n```\n\n::: {.cell-output-display}\n![](30_glm_files/figure-html/NManim1-1.png){width=768}\n:::\n\n```{.r .cell-code}\n(a <- optim.NR(f1, x0 = 3, abs.tol = 0.001, return.grid = TRUE))\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n$X.optim\n[1] 10.33889\n\n$iter\n[1] 6\n\n$grid\n           x0       x1           f_x       f._x\n[1,]  3.00000 20.43750 -2.790000e-01 0.01600000\n[2,] 20.43750 12.87523  9.121992e-01 0.12062500\n[3,] 12.87523 10.59535  1.715639e-01 0.07525136\n[4,] 10.59535 10.34209  1.559353e-02 0.06157209\n[5,] 10.34209 10.33889  1.924166e-04 0.06005255\n[6,] 10.33889 10.33889  3.079948e-08 0.06003333\n```\n\n\n:::\n:::\n\n\n\nIf we animate the process:\n\n:::: {.callout-note collapse=\"true\"}\n### Animation code\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\ndat1 <- data.frame(x, y = eval(f1, env = list(x = x)))\ngdat <- a$grid |>\n  as.data.frame() |>\n  mutate(Iter = 1:n(),\n           x = ifelse(x0>0,x0+1, x0-1),\n           y = f_x + (x-x0)*f._x)\n\ng2 <- ggplot() + \n  geom_line(data = dat1, aes(y = y, x = x)) +\n  geom_hline(yintercept = 0, linetype = 'dashed') +\n  geom_segment(data = gdat, aes(x = x, y = y, xend = x1, yend = 0), color = 'red') +\n  geom_segment(data = gdat, aes(x = x0, xend = x0, y = 0, yend = f_x), linetype = 'dashed') +\n  geom_text(data = gdat |> filter(Iter<4), aes(x = x0, y = -0.05, label = \"x[0]\"), parse = TRUE) +\n  geom_text(data = gdat |> filter(Iter<4), aes(x = x1, y = -0.05, label = \"x[1]\"), parse = TRUE) +\n  geom_point(data = gdat, aes(x = x0, y = f_x)) +\n  geom_text(data = gdat |> filter(Iter<4), aes(x = x0, y = f_x, label = \"f(x)\"), \n    parse = TRUE, nudge_x = 0.1, nudge_y = -0.05, hjust = 0, vjust = 0) +\n  geom_text(data = gdat |> filter(Iter<4), aes(x = x0+0.3+(x1-x0)/2, y = (f_x/2)-0.05, label = \"f*minute*(x)\"), \n    parse = TRUE, color = 'red') +\n  geom_text(data = gdat, aes(x = 0, y = 0.8, label = paste0(\"Iter == \", Iter)), \n    parse = TRUE, hjust = 0) +\n  geom_text(data = gdat, aes(x = -0, y = 1, label = paste0(\"x[1] == \", round(x1, 3))), parse = TRUE, hjust = 0) +\n  transition_manual(Iter)\nga <- animate(g2, fps = 20, duration = 6)\nanim_save('NMAnim2.gif', animation = ga, path='../resources')\n```\n:::\n\n\n\n::::\n\n![](../resources/NMAnim2.gif)\n\nNote that we are now looking for were the slope of the profile is\nequal to zero. This makes no distinction between a peak (maximum) and\na valley (minimum) as both have a slope of zero. Provided the\n(negative)log-likelihood profile is monotonic (has either a single\npeak or valley), this should be OK. It can however be problematic if\nthe profile has local minima and maxima. To minimize issues, it is\nbest to select starting values (inital parameter values) that are\nlikely to be reasonably close to the optimum values.\n\nOk, great. Now how do we use this approach to optimize for multiple\nparameters.\n\nRecall that the Newton-Raphson method for optimisation estimates the\nroot by subtracting the ratio of the first order derivative of the\n(loss) function by the second order derivative of the function.\n\n$$ x_{n+1} = x_n - \\frac{f'(x_n)}{f''(x_n)} $$\n\nWhen there are multiple parameters to estimate, then there are\nmultiple **partial** gradients (slopes).\n\nNow that we are back to estimating the mean and variance of our\nexample data, we have two parameters to estimate. Therefore we need:\n\n- the partial derivative of the negative log-likelihood with respect\n  to the mean parameter\n- the partial derivative of the negative log-likelihood with respect\n  to the sigma parameter\n- the second order partial derivative with respect to mean of the\n  first order derivative with respect to the mean\n- the second order partial derivative with respect to sigma of the\n  first order derivative with respect to the mean\n- the second order partial derivative with respect to mean of the\n  first order derivative with respect to the sigma\n- the second order partial derivative with respect to sigma of the\n  first order derivative with respect to the sigma\n\nThe second order partial derivatives form a square matrix called a\n**Hessian** matrix.\n\nWhen there are multiple parameters to estimate, the above formula\nbecomes:\n\n$$\n\\boldsymbol{x_{n+1}} = \\boldsymbol{x_n} - \\frac{\\boldsymbol{g_n}}{\\boldsymbol{H_n}}\n$$\n\nwhere $\\boldsymbol{g_n}$ is a vector of partial gradients (first order\nderivatives), $\\boldsymbol{H_n}$ is a matrix of second order partial\nderivatives and $\\boldsymbol{x_n}$ and $\\boldsymbol{x_{n+1}}$ are the\nprevious and updated parameter estimates respectively.\n\nRecall that matrices cannot be divided. Rather we must multiply by the\nmatrix inverse. Hence the above equation becomes:\n\n$$\n\\boldsymbol{x_{n+1}} = \\boldsymbol{x_n} - (\\boldsymbol{H_n})^{-1}\\boldsymbol{g_n}\n$$\n\nRecall also to invert a matrix, it must be decomposed into an identity\nmatrix and the inverse. In R, this can be achieved via either\n`solve()` or `qr.solve`.\n\nOn top of this, there is the need to calculate the first and second\norder derivatives for a function for which there is no equation.\nHence, we need to approximate the derivatives using **finite\ndifferences**. That is,we can estimate a derivative (gradient at a\nspecific point on a profile), by calculating the rise over run for a\nvery small run ($\\Delta$)\n\n$$\n\\frac{df(x)}{dx} \\approx \\frac{(f(x) + \\Delta x/2) - (f(x - \\Delta x/2))}{\\Delta x} \n$$\n\nNow that all the pieces are in place, we can demonstrate this by\niterating through a number of Newton-Raphson cycles to estimate the\nmean and sigma of our example 1 data.\n\n:::: {.callout-note collapse=\"true\"}\n### Newton-Raphson and animation code\n\n\n\n::: {.cell}\n\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\nparams.init <- c(mu = 20, sigma = 12)\n\n## The following function calculates the difference-quotient approximation of gradient\napprox.grad <- function(theta, fn, eps = 1e-05) {\n    p <- length(theta)\n    nf <- length(fn(theta))\n    eps.mat <- diag(p) * (eps/2)\n    Gmat <- array(0, dim = c(nf, p))\n    for (i in 1:p) {\n        Gmat[,i] <- (fn(theta + eps.mat[,i]) - fn(theta - eps.mat[,i]))/eps\n    }\n    if (nf>1) Gmat else c(Gmat)\n}\n\n\noptim.NR <- function(params.init, fn, x, iter.max = 250, abs.tol = 1e-05, control = list(eps = 1e-06)) {\n    fnc <- function(bb) t(approx.grad(bb, fn))\n    eps <- control$eps\n    gradfn <- function(x) approx.grad(x, fnc, eps)\n    iter <- 0; not.converged <- 1; not.max.iter <- 1\n    newpar <- params.init\n    oldpar <- params.init - 1\n    while (not.converged & not.max.iter) {\n        oldpar <- newpar\n        newpar <- oldpar - solve(gradfn(oldpar), t(fnc(oldpar)))\n        iter <- iter + 1\n        not.max.iter <- (iter < iter.max)*1\n        not.converged <- (abs(fn(oldpar) - fn(newpar))>abs.tol)*1\n    }\n    list(iter=iter, final = as.vector(newpar), LL = fn(as.vector(newpar)), \n      gradient = fnc(newpar), hessian = gradfn(newpar))\n}\n\n\n#optim.NR(params.init, fn=function(t) LL.gaus(t, x=y), iter.max=1)\n\nmu <- seq(15, 040, len = 100)\nsigma <- seq(10, 20, len = 100)\ntheta <- expand.grid(mu = mu, sigma = sigma)\ntheta$LL <- apply(theta, 1, LL.gaus, x = dat$y)\n\nbase.plot <- ggplot(data = theta, aes(y = mu, x = sigma)) +\n    geom_tile(aes(fill = LL), show.legend = FALSE) + \n    geom_contour(aes(z = LL)) +\n    scale_fill_gradientn(colors = terrain.colors(12)) +\n    scale_x_continuous(expand = c(0,0)) +\n    scale_y_continuous(expand = c(0,0))\n\nnewdata <- vector('list', 10)\nnewdata[[1]] <- data.frame(t(setNames(params.init, c('mu', 'sigma'))))\np.i <- params.init\nfor (i in 2:10) {\n    a <- optim.NR(params.init = p.i, fn = function(t) LL.gaus(t, x = dat$y), iter.max = 1)\n    newdata[[i]] <- data.frame(t(setNames(a$final,c('mu','sigma'))))\n    p.i <- as.vector(a$final)\n}\nnewdata <- bind_rows(newdata, .id='Iter') |>\n  mutate(Iter = factor(Iter, levels = unique(Iter)), nIter = as.numeric(Iter))\ng <- base.plot + \n    geom_point(data = newdata, aes(y = mu, x = sigma, group = Iter), color = 'black') +\n    geom_path(data = newdata, aes(y = mu, x = sigma), color = 'black') +\n    transition_reveal(nIter) +\n    labs(title = \"Iteration: {frame_along}\")\nga=animate(g, nframes = 10, fps = 1)\n\nanim_save('NMAnim3.gif', animation = ga, path = '../resources')\n```\n:::\n\n\n::::\n\n![](../resources/NMAnim3.gif)\n    \nNow lets allow the routine (`optim.NR()` defined in the concealed code\nabove) to run to convergence.\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\noptim.NR(params.init, fn = function(t) LL.gaus(t, x = dat$y))\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n$iter\n[1] 5\n\n$final\n[1] 27.81098 14.25903\n\n$LL\n[1] 40.76329\n\n$gradient\n             [,1]          [,2]\n[1,] -1.04734e-06 -5.478284e-07\n\n$hessian\n             [,1]      [,2]\n[1,] 0.0490274488 0.0000000\n[2,] 0.0007105427 0.0980549\n```\n\n\n:::\n:::\n\n\n\nAgain, we see that these estimates (`final` in the output) are very\nsimilar to the empirical calculations. Furthermore, notice that\nconvergence took only 5 iterations.\n\nThe inverse of the hessian matrix is the **variance-covariance**\nmatrix. Therefore, we can also generate estimates of the standard\nerror of the estimates:\n\n$$\nSE = \\sqrt{diag(\\boldsymbol{H})}\n$$\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nH=optim.NR(params.init, fn=function(t) LL.gaus(t, x=dat$y))$hessian\nsqrt(diag(solve(H)))\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n[1] 4.516275 3.193488\n```\n\n\n:::\n:::\n\n\n\nR has an inbuilt routine (`nlm()`) that performs the Newton-like\nmethod for optimisation.\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nnlm(LL.gaus, params.init, x = dat$y, hessian = TRUE, gradtol = 1e-03)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n$minimum\n[1] 40.76329\n\n$estimate\n[1] 27.81205 14.25769\n\n$gradient\n[1]  5.249938e-05 -1.312170e-04\n\n$hessian\n              [,1]          [,2]\n[1,]  4.919280e-02 -1.686155e-05\n[2,] -1.686155e-05  9.836416e-02\n\n$code\n[1] 1\n\n$iterations\n[1] 9\n```\n\n\n:::\n\n```{.r .cell-code}\nH <- nlm(LL.gaus, params.init, x = dat$y, hessian = TRUE, gradtol = 1e-06*2)$hessian\nsqrt(diag(solve(H)))\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n[1] 4.509099 3.189208\n```\n\n\n:::\n:::\n\n\n\n### Stochastic global optimisation\n\nWhen the profile of a function is not smooth, derivative methods can\nstruggle to locate a minimum efficiently (if at all) and when the\nprofile has multiple local minima, both derivative and simplex methods\ncan fail to converge on the \"true\" parameter values. Stochastic global\nmethods add a random (_stochastic_) component to increase the\npotential of finding the _global_ minimum when there are multiple\nlocal minima.\n\nIf we return briefly to our well analogy, we might appreciate that\nthere could be multiple underground caves and depending on where our\ninitial pilot hole is drilled, the more efficient search algorithms\nmight quickly hone in on a point that is locally shallow yet not the\nshallowest location in the entire landscape. Of course repeating the\nsearch from multiple random locations could help alleviate this issue,\nyet it might still be difficult to discover the shallowest point if\nthis is associated with a very abrupt (rather than gradual)\nunderground geological feature.\n\nThe classic stochastic global method is called **simulated annealing**\nor the **Metropolis algorithm** and it works as follows:\n\n1. Start with some initial estimate values (one for each parameter)\n   and calculate the loss function (e.i. the negative log-likelihood)\n2. Pick a new set of parameter estimates _close_ to the previous -\n   e.g. jump a small distance in multidimensional space - and again\n   calculate the loss function.\n3. If the value of the loss function is better (lower), accept the new\n   parameters and return to Step 2.\n4. If the value of the loss function is not better,\n    - Calculate the difference ($\\Delta L = L_{new} - L_{old}$) in\n\t  loss between the new and old parameter estimates\n    - Pick a random number between 0 and 1\n    - Accept the new parameter estimates if the random number is less\n\t  than $e^{-\\Delta L/k}$ (where $k$ is a constant that regulates\n\t  the acceptance propensity), otherwise retain the previous\n\t  parameter estimates.\n    - Periodically (e.g. every 100 iterations), decrease $k$ so as to\n      reduce the acceptance propensity.\n    - Return to Step 2.\n\t\nRather than have a stopping rule based on convergence, simulated\nannealing continues until the maximum number of iterations have been\nperformed. Along with the capacity and encouragement to occasionally\nmove 'uphill' (towards higher loss values), a large number of\niterations increases the chances that the global minima will be\ndiscovered even in the presence of multiple minima. The iterations,\nkeep track of the parameters associated with the 'best' configuration.\n\nThere are variants of this algorithm that control the jump distance\nused to select the next point. By adaptively increasing and reducing\nthe jump length following acceptance and non-acceptance respectively,\nthese variances are able to further encourage wider exploration of the\nparameter space.\n\nThe following animation illustrates 4096 iterations (stepping up in\n$log_2$ increments). The red point indicates the current 'best'\nparameter estimates. Note that whilst the algorithm 'discovered' the\n'best' solution after approximately 100 iterations, it continued to\nexplore the profile thoroughly. If there had been other minima, it is\nlikely to have discovered them as well.\n\n:::: {.callout-note collapse=\"true\"}\n### Simulated Annealing code\n\n\n::: {.cell}\n\n```{.r .cell-code}\noptim.SANN <- function(params.init, fn, iter.max = 2500, jump = 0.05, k = 100) {\n    bestpar <- newpar <- oldpar <- params.init\n    iter <- 0; not.max.iter <- 1\n    inck <- k/10\n    while(not.max.iter) {\n        ## jump to new parameter set\n        newpar <- oldpar + replicate(length(params.init), runif(1, -jump, jump))\n        deltaL <- fn(newpar)-fn(oldpar)\n        if (deltaL<0) { #improvement\n            oldpar <- newpar\n        } else {\n            rnd <- runif(1)\n            if (rnd <= exp(-deltaL/k)) oldpar <- newpar\n        }\n        if (fn(newpar)<fn(bestpar)) bestpar <- newpar\n        iter <- iter+1\n        if ((iter %% inck)==0) k <- k/10\n        not.max.iter <- (iter < iter.max)*1\n    }\n    list(iter = iter, final = as.vector(bestpar), LL = fn(bestpar), last = as.vector(oldpar), LL = fn(bestpar))\n}\n#optim.SANN(params.init=c(-0.25,1), fn=function(p) LL.gaus(p, x=y), iter.max=2500)\n```\n:::\n\n\n::::\n\n:::: {.callout-note collapse=\"true\"}\n### Simulated Annealing animation code\n\n\n::: {.cell}\n\n```{.r .cell-code}\np.i <- params.init\niter.cnt <- 1\niters <- 2500\nnewdata <- vector('list', iters)\nbestpar <- p.i\nfor (i in 1:iters) {\n    a <- optim.SANN(params.init = p.i, fn = function(t) LL.gaus(t, x = dat$y), iter.max = 1, jump = 0.5, k = 0.1)\n    if (LL.gaus(a$last, x = dat$y)<LL.gaus(bestpar, x = dat$y)) bestpar = a$last\n    newdata[[i]] <- data.frame(t(setNames(a$last, c('mu', 'sigma'))), iter = floor(log2(i))+1, t(setNames(bestpar, c('bestmu', 'bestsigma'))))\n    p.i <- as.vector(a$last)\n}\nnewdata <- bind_rows(newdata, .id = 'Iter') |> \n  mutate(iter = factor(iter, levels = unique(iter)), nIter = as.numeric(as.character(iter)))\ng <- base.plot + \n    geom_point(data = newdata, aes(y = mu, x = sigma, group = iter), color = 'black') +\n    geom_path(data = newdata, aes(y = mu, x = sigma), color = 'black') +\n    geom_point(data = newdata, aes(y = bestmu, x = bestsigma), color = 'red') + \n    transition_reveal(nIter) +\n    labs(title = \"Iteration: {2^frame_along}\")\nga <- animate(g, nframes = 12, fps = 1)\n#ga\nanim_save('SANNAnim1.gif', animation = ga, path = '../resources')\n```\n:::\n\n\n\n::::\n\n\nAllowing the simulated annealing to iterate 2500 times (with updating\n$k$):\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\noptim.SANN(params.init = c(20, 12), fn = function(t) LL.gaus(t, x = dat$y), iter.max = 2500, jump = 0.5, k = 0.1)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n$iter\n[1] 2500\n\n$final\n[1] 27.76141 14.24703\n\n$LL\n[1] 40.76336\n\n$last\n[1] 27.91323 13.76679\n\n$LL\n[1] 40.76336\n```\n\n\n:::\n:::\n\n\n\nWhich is again very similar the empirical estimates.\n\n:::\n\n\n:::::::\n\n## Fitting GLM's\n\n:::: {.panel-tabset}\n\n\n### Example 1 (Gaussian data)\n\n::::::: {.panel-tabset}\n#### Raw predictor\n::::: {.panel-tabset}\n\n##### Fit the model\n$$\n\\begin{align}\ny_i \\sim{}& N(\\mu_i, \\sigma^2)\\\\\n\\mu_i =& \\beta_0 + \\beta_1 x_i\\\\\n\\end{align}\n$$\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\ndat.glm <- glmmTMB(y~x, data = dat)\ndat.glm\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nFormula:          y ~ x\nData: dat\n      AIC       BIC    logLik  df.resid \n 68.61231  69.52006 -31.30615         7 \n\nNumber of obs: 10\n\nDispersion estimate for gaussian family (sigma^2): 30.7 \n\nFixed Effects:\n\nConditional model:\n(Intercept)            x  \n      2.651        4.575  \n```\n\n\n:::\n:::\n\n\n\nAnd to explore the diagnostics\n\n\n\n##### Performance model checking\n\n\n::: {.cell}\n\n```{.r .cell-code}\ndat.glm |> performance::check_model()\n```\n\n::: {.cell-output-display}\n![](30_glm_files/figure-html/glm_validateModela1-1.png){width=768}\n:::\n\n```{.r .cell-code}\ndat.glm |> performance::check_outliers()\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nNULL\n```\n\n\n:::\n:::\n\n\n\n**Conclusions**:\n\n- these diagnostics are broadly acceptable given the small nature of the\n  data\n\n\n##### DHARMa (simulated) residuals\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\ndat.resid <- dat.glm |> \n  simulateResiduals(plot = TRUE)\n```\n\n::: {.cell-output-display}\n![](30_glm_files/figure-html/glm_validateModelb1-1.png){width=768}\n:::\n:::\n\n\n\n**Conclusions**\n\n- no obvious issues with these diagnostics\n\n##### Summarise model\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\ndat.glm |> summary()\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n Family: gaussian  ( identity )\nFormula:          y ~ x\nData: dat\n\n     AIC      BIC   logLik deviance df.resid \n    68.6     69.5    -31.3     62.6        7 \n\n\nDispersion estimate for gaussian family (sigma^2): 30.7 \n\nConditional model:\n            Estimate Std. Error z value Pr(>|z|)    \n(Intercept)   2.6507     3.7833   0.701    0.484    \nx             4.5746     0.6097   7.503 6.26e-14 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n```\n\n\n:::\n\n```{.r .cell-code}\ndat.glm |> confint()\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n                2.5 %    97.5 % Estimate\n(Intercept) -4.764542 10.065873 2.650666\nx            3.379537  5.769675 4.574606\n```\n\n\n:::\n\n```{.r .cell-code}\ndat.glm |> performance::r2()\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n# R2 for Linear Regression\n       R2: 0.849\n  adj. R2: 0.806\n```\n\n\n:::\n:::\n\n\n\n**Interpretation**:\n\n- when $x=0$ (e.g. the average $x$ value since centered), $y$ is\n  expected to be 2.651 (the\n  y-intercept).\n- for every one unit change in $x$, the expected value of $y$\n  increases by 4.575 (the slope)\n- the slope could be as low as 3.38 or as high as \n  5.77 (95% confidence interval of the slope)\n- as the above interval does not include the value of 0, the linear\n  relationship (slope) can be considered significant\n- we would reject the null hypothesis of no relationship (p-value for\n  slope is less than 0.05)\n- 80.604% of the variance in $y$ is\n  explained by its linear relationship with $x$ (R squared value)\n\n:::::\n\n#### Centered predictor\n::::: {.panel-tabset}\n\n##### Fit the model\n$$\n\\begin{align}\ny_i \\sim{}& N(\\mu_i, \\sigma^2)\\\\\n\\mu_i =& \\beta_0 + \\beta_1 (x_i - \\bar{x})\\\\\n\\end{align}\n$$\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\ndat1b.glm <- glmmTMB(y ~ scale(x, scale = FALSE), data = dat)\ndat1b.glm\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nFormula:          y ~ scale(x, scale = FALSE)\nData: dat\n      AIC       BIC    logLik  df.resid \n 68.61231  69.52006 -31.30615         7 \n\nNumber of obs: 10\n\nDispersion estimate for gaussian family (sigma^2): 30.7 \n\nFixed Effects:\n\nConditional model:\n            (Intercept)  scale(x, scale = FALSE)  \n                 27.811                    4.575  \n```\n\n\n:::\n:::\n\n\n\nAnd to explore the diagnostics\n\n\n\n##### Performance model checking\n\n\n::: {.cell}\n\n```{.r .cell-code}\ndat1b.glm |> performance::check_model()\n```\n\n::: {.cell-output-display}\n![](30_glm_files/figure-html/glm_validateModela1b-1.png){width=768}\n:::\n\n```{.r .cell-code}\ndat1b.glm |> performance::check_outliers()\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nNULL\n```\n\n\n:::\n:::\n\n\n\n**Conclusions**:\n\n- these diagnostics are broadly acceptable given the small nature of the\n  data\n\n\n##### DHARMa (simulated) residuals\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\ndat.resid <- dat1b.glm |> \n  simulateResiduals(plot = TRUE)\n```\n\n::: {.cell-output-display}\n![](30_glm_files/figure-html/glm_validateModelb1b-1.png){width=768}\n:::\n:::\n\n\n\n**Conclusions**\n\n- no obvious issues with these diagnostics\n\n##### Summarise model\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\ndat1b.glm |> summary()\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n Family: gaussian  ( identity )\nFormula:          y ~ scale(x, scale = FALSE)\nData: dat\n\n     AIC      BIC   logLik deviance df.resid \n    68.6     69.5    -31.3     62.6        7 \n\n\nDispersion estimate for gaussian family (sigma^2): 30.7 \n\nConditional model:\n                        Estimate Std. Error z value Pr(>|z|)    \n(Intercept)              27.8110     1.7513  15.880  < 2e-16 ***\nscale(x, scale = FALSE)   4.5746     0.6097   7.503 6.26e-14 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n```\n\n\n:::\n\n```{.r .cell-code}\ndat1b.glm |> confint()\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n                            2.5 %    97.5 %  Estimate\n(Intercept)             24.378410 31.243560 27.810985\nscale(x, scale = FALSE)  3.379534  5.769673  4.574603\n```\n\n\n:::\n\n```{.r .cell-code}\ndat1b.glm |> performance::r2()\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n# R2 for Linear Regression\n       R2: 0.849\n  adj. R2: 0.806\n```\n\n\n:::\n:::\n\n\n\n**Interpretation**:\n\n- when $x=0$ (e.g. the average $x$ value since centered), $y$ is\n  expected to be 27.811 (the\n  y-intercept).\n- for every one unit change in $x$ (which represents a span of approximately 34% of the range of $x$), the expected value of $y$\n  increases by 4.575 (the slope)\n- the slope could be as low as 3.38 or as high as \n  5.77 (95% confidence interval of the slope)\n- as the above interval does not include the value of 0, the linear\n  relationship (slope) can be considered significant\n- we would reject the null hypothesis of no relationship (p-value for\n  slope is less than 0.05)\n- 80.604% of the variance in $y$ is\n  explained by its linear relationship with $x$ (R squared value)\n\n:::::\n\n#### Standardised predictor\n\n::::: {.panel-tabset}\n\n##### Fit the model\n\n$$\n\\begin{align}\ny_i \\sim{}& N(\\mu_i, \\sigma^2)\\\\\n\\mu_i =& \\beta_0 + \\beta_1 (x_i - \\bar{x})/\\sigma_{x}\\\\\n\\end{align}\n$$\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\ndat1c.glm <- glmmTMB(y ~ scale(x), data = dat)\ndat1c.glm\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nFormula:          y ~ scale(x)\nData: dat\n      AIC       BIC    logLik  df.resid \n 68.61231  69.52006 -31.30615         7 \n\nNumber of obs: 10\n\nDispersion estimate for gaussian family (sigma^2): 30.7 \n\nFixed Effects:\n\nConditional model:\n(Intercept)     scale(x)  \n      27.81        13.85  \n```\n\n\n:::\n:::\n\n\n\nAnd to explore the diagnostics\n\n\n##### Performance model checking\n\n\n::: {.cell}\n\n```{.r .cell-code}\ndat1c.glm |> performance::check_model()\n```\n\n::: {.cell-output-display}\n![](30_glm_files/figure-html/glm_validateModela1c-1.png){width=768}\n:::\n\n```{.r .cell-code}\ndat1c.glm |> performance::check_outliers()\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nNULL\n```\n\n\n:::\n:::\n\n\n\n**Conclusions**:\n\n- these diagnostics are broadly acceptable given the small nature of the\n  data\n\n\n##### DHARMa (simulated) residuals\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\ndat.resid <- dat1c.glm |> \n  simulateResiduals(plot = TRUE)\n```\n\n::: {.cell-output-display}\n![](30_glm_files/figure-html/glm_validateModelb1c-1.png){width=768}\n:::\n:::\n\n\n\n**Conclusions**\n\n- no obvious issues with these diagnostics\n\n##### Summarise model\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\ndat1c.glm |> summary()\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n Family: gaussian  ( identity )\nFormula:          y ~ scale(x)\nData: dat\n\n     AIC      BIC   logLik deviance df.resid \n    68.6     69.5    -31.3     62.6        7 \n\n\nDispersion estimate for gaussian family (sigma^2): 30.7 \n\nConditional model:\n            Estimate Std. Error z value Pr(>|z|)    \n(Intercept)   27.811      1.751  15.880  < 2e-16 ***\nscale(x)      13.850      1.846   7.503 6.26e-14 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n```\n\n\n:::\n\n```{.r .cell-code}\ndat1c.glm |> confint()\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n               2.5 %   97.5 % Estimate\n(Intercept) 24.37842 31.24357 27.81100\nscale(x)    10.23206 17.46856 13.85031\n```\n\n\n:::\n\n```{.r .cell-code}\ndat1c.glm |> performance::r2()\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n# R2 for Linear Regression\n       R2: 0.849\n  adj. R2: 0.806\n```\n\n\n:::\n:::\n\n\n\n**Interpretation**:\n\n- when $x=0$ (e.g. the average $x$ value since centered), $y$ is\n  expected to be 27.811 (the\n  y-intercept).\n- for every one unit change in $x$ (which represents a span of\n  approximately 34% of the range of $x$ since standardised), the\n  expected value of $y$ increases by `r\n  round(fixef(dat1c.glm)[[1]][2], 3)` (the slope)\n- the slope could be as low as 10.232 or as high as \n  17.469 (95% confidence interval of the slope)\n- as the above interval does not include the value of 0, the linear\n  relationship (slope) can be considered significant\n- we would reject the null hypothesis of no relationship (p-value for\n  slope is less than 0.05)\n- 80.604% of the variance in $y$ is\n  explained by its linear relationship with $x$ (R squared value)\n\n:::::\n:::::::\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nperformance::compare_performance(dat.glm, dat1b.glm, dat1c.glm, rank = TRUE)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n# Comparison of Model Performance Indices\n\nName      |   Model |    R2 | R2 (adj.) |  RMSE | Sigma | AIC weights | AICc weights | BIC weights | Performance-Score\n----------------------------------------------------------------------------------------------------------------------\ndat.glm   | glmmTMB | 0.849 |     0.806 | 5.538 | 5.538 |       0.333 |        0.333 |       0.333 |           100.00%\ndat1c.glm | glmmTMB | 0.849 |     0.806 | 5.538 | 5.538 |       0.333 |        0.333 |       0.333 |            85.72%\ndat1b.glm | glmmTMB | 0.849 |     0.806 | 5.538 | 5.538 |       0.333 |        0.333 |       0.333 |             0.00%\n```\n\n\n:::\n\n```{.r .cell-code}\nperformance::compare_performance(dat.glm, dat1b.glm, dat1c.glm, rank = TRUE) |> plot()\n```\n\n::: {.cell-output-display}\n![](30_glm_files/figure-html/compare_glm1-1.png){width=672}\n:::\n:::\n\n\n### Example 3 (Poisson data)\n\n::::::: {.panel-tabset}\n#### Raw predictor\n::::: {.panel-tabset}\n##### Fit the model\nGiven that exploratory data analysis suggested that the assumptions\nwere not likely to be met for a simple gaussian model and that this\nwas subsequently confirmed when we explored the diagnostics resulting\nfrom the OLS model of these data, we will instead entertain a poisson\nregression model. The model will be of the form:\n\n$$\n\\begin{align}\ny_i \\sim{}& Pois(\\lambda_i)\\\\\nlog(\\lambda_i) =& \\beta_0 + \\beta_1 x_i\\\\\n\\end{align}\n$$\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\ndat3.glm <- glmmTMB(y~x, data = dat3, family = poisson(link = \"log\"))\ndat3.glm\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nFormula:          y ~ x\nData: dat3\n      AIC       BIC    logLik  df.resid \n 50.35456  50.95973 -23.17728         8 \n\nNumber of obs: 10\n\nFixed Effects:\n\nConditional model:\n(Intercept)            x  \n    0.05136      0.34263  \n```\n\n\n:::\n:::\n\n\n\nAnd to explore the diagnostics\n\n\n\n##### Performance model checking\n\n\n::: {.cell}\n\n```{.r .cell-code}\n## glmmTMB not folly supported yet, residual_type=\"simulated\" would be better - if supported\ndat3.glm |> performance::check_model()\n```\n\n::: {.cell-output-display}\n![](30_glm_files/figure-html/glm_validateMode3a1-1.png){width=768}\n:::\n\n```{.r .cell-code}\ndat3.glm |> performance::check_outliers()\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nNULL\n```\n\n\n:::\n:::\n\n\n\n**Conclusions**:\n\n- these diagnostics are broadly acceptable given the small nature of the\n  data\n\n\n##### DHARMa (simulated) residuals\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\ndat.resid <- dat3.glm |> \n  simulateResiduals(plot = TRUE)\n```\n\n::: {.cell-output-display}\n![](30_glm_files/figure-html/glm_validateModel3b1-1.png){width=768}\n:::\n:::\n\n\n\n**Conclusions**\n\n- no obvious issues with these diagnostics\n\n##### Summarise model\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\ndat3.glm |> summary()\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n Family: poisson  ( log )\nFormula:          y ~ x\nData: dat3\n\n     AIC      BIC   logLik deviance df.resid \n    50.4     51.0    -23.2     46.4        8 \n\n\nConditional model:\n            Estimate Std. Error z value Pr(>|z|)    \n(Intercept)  0.05136    0.35408   0.145    0.885    \nx            0.34263    0.04319   7.932 2.15e-15 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n```\n\n\n:::\n\n```{.r .cell-code}\ndat3.glm |> confint()\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n                 2.5 %    97.5 %  Estimate\n(Intercept) -0.6426377 0.7453489 0.0513556\nx            0.2579690 0.4272885 0.3426288\n```\n\n\n:::\n\n```{.r .cell-code}\ndat3.glm |> performance::r2()\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n# R2 for Generalized Linear Regression\n  Nagelkerke's R2: 1.000\n```\n\n\n:::\n:::\n\n\n:::::::: {.callout-tip}\n\nSince this model used a log link, in order to return the estimates to\nthe scale of the response, we need to backtransform by exponentiation.\n\nImportantly, if using confidence intervals for the purpose of\ninference testsing:\n\n- if using estimates on the link (log) scale, intervals that do not include 0\n  are \"significant\"\n- if using estimates on the response scale, intervals that do not\n  include 1 are \"significant\"\n  \n::::::::\n\n**Interpretation**:\n\n- when $x=0$, $y$ is expected to be exp(0.051) = \n  1.053 (the y-intercept).\n- for every one unit change in $x$, the expected value of $y$\n  increases by exp(0.343) =  \n  1.409 (the slope)\n- this is equivalent to a 40.865% \n  increase in the response per one unit change in $x$\n- the slope (on the link scale) could be as low as \n  0.258 or\n  as high as 0.427 (95% confidence\n  interval of the slope)\n- as the above interval does not include the value of 0, the linear\n  relationship (slope) can be considered significant\n- the slope (on the response scale) could be as low as \n  1.294 or\n  as high as 1.533 (95% confidence\n  interval of the slope)\n- as the above interval does not include the value of 1, the linear\n  relationship (slope) can be considered significant\n- we would reject the null hypothesis of no relationship (p-value for\n  slope is less than 0.05)\n- 99.982% of the variance in $y$ is\n  explained by its linear relationship with $x$ (R squared value)\n\n:::::\n\n#### Centered predictor\n\n::::: {.panel-tabset}\n\n##### Fit the model\n\nGiven that exploratory data analysis suggested that the assumptions\nwere not likely to be met for a simple gaussian model and that this\nwas subsequently confirmed when we explored the diagnostics resulting\nfrom the OLS model of these data, we will instead entertain a poisson\nregression model. The model will be of the form:\n\n$$\n\\begin{align}\ny_i \\sim{}& Pois(\\lambda_i)\\\\\nlog(\\lambda_i) =& \\beta_0 + \\beta_1 (x_i - \\bar{x})\\\\\n\\end{align}\n$$\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\ndat3b.glm <- glmmTMB(y ~ scale(x, scale = FALSE), data = dat3, family = poisson(link = \"log\"))\ndat3b.glm\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nFormula:          y ~ scale(x, scale = FALSE)\nData: dat3\n      AIC       BIC    logLik  df.resid \n 50.35456  50.95973 -23.17728         8 \n\nNumber of obs: 10\n\nFixed Effects:\n\nConditional model:\n            (Intercept)  scale(x, scale = FALSE)  \n                 1.9358                   0.3426  \n```\n\n\n:::\n:::\n\n\n\nAnd to explore the diagnostics\n\n\n\n##### Performance model checking\n\n\n::: {.cell}\n\n```{.r .cell-code}\ndat3b.glm |> performance::check_model()\n```\n\n::: {.cell-output-display}\n![](30_glm_files/figure-html/glm_validateMode3a1b-1.png){width=768}\n:::\n\n```{.r .cell-code}\ndat3b.glm |> performance::check_outliers()\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nNULL\n```\n\n\n:::\n:::\n\n\n\n**Conclusions**:\n\n- these diagnostics are broadly acceptable given the small nature of the\n  data\n\n\n##### DHARMa (simulated) residuals\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\ndat.resid <- dat3b.glm |> \n  simulateResiduals(plot = TRUE)\n```\n\n::: {.cell-output-display}\n![](30_glm_files/figure-html/glm_validateModel3b1b-1.png){width=768}\n:::\n:::\n\n\n\n**Conclusions**\n\n- no obvious issues with these diagnostics\n\n##### Summarise model\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\ndat3b.glm |> summary()\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n Family: poisson  ( log )\nFormula:          y ~ scale(x, scale = FALSE)\nData: dat3\n\n     AIC      BIC   logLik deviance df.resid \n    50.4     51.0    -23.2     46.4        8 \n\n\nConditional model:\n                        Estimate Std. Error z value Pr(>|z|)    \n(Intercept)               1.9358     0.1411  13.720  < 2e-16 ***\nscale(x, scale = FALSE)   0.3426     0.0432   7.932 2.15e-15 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n```\n\n\n:::\n\n```{.r .cell-code}\ndat3b.glm |> confint()\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n                            2.5 %    97.5 %  Estimate\n(Intercept)             1.6592778 2.2123498 1.9358138\nscale(x, scale = FALSE) 0.2579681 0.4272894 0.3426288\n```\n\n\n:::\n\n```{.r .cell-code}\ndat3b.glm |> performance::r2()\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n# R2 for Generalized Linear Regression\n  Nagelkerke's R2: 1.000\n```\n\n\n:::\n:::\n\n\n\n:::::::: {.callout-tip}\n\nSince this model used a log link, in order to return the estimates to\nthe scale of the response, we need to backtransform by exponentiation.\n\nImportantly, if using confidence intervals for the purpose of\ninference testsing:\n\n- if using estimates on the link (log) scale, intervals that do not include 0\n  are \"significant\"\n- if using estimates on the response scale, intervals that do not\n  include 1 are \"significant\"\n  \n::::::::\n\n**Interpretation**:\n\n- when $x=0$ (e.g. the average $x$ value since centered), $y$ is\n  expected to be exp(1.936) = \n  6.93 (the y-intercept).\n- for every one unit change in $x$, the expected value of $y$\n  increases by exp(0.343) =  \n  1.409 (the slope)\n- this is equivalent to a 40.865% \n  increase in the response per one unit change in $x$\n- the slope (on the link scale) could be as low as \n  0.258 or\n  as high as 0.427 (95% confidence\n  interval of the slope)\n- as the above interval does not include the value of 0, the linear\n  relationship (slope) can be considered significant\n- the slope (on the response scale) could be as low as \n  1.294 or\n  as high as 1.533 (95% confidence\n  interval of the slope)\n- as the above interval does not include the value of 1, the linear\n  relationship (slope) can be considered significant\n- we would reject the null hypothesis of no relationship (p-value for\n  slope is less than 0.05)\n- 99.982% of the variance in $y$ is\n  explained by its linear relationship with $x$ (R squared value)\n\n:::::\n\n#### Standardised predictor\n\n::::: {.panel-tabset}\n\n##### Fit the model\n\nGiven that exploratory data analysis suggested that the assumptions\nwere not likely to be met for a simple gaussian model and that this\nwas subsequently confirmed when we explored the diagnostics resulting\nfrom the OLS model of these data, we will instead entertain a poisson\nregression model. The model will be of the form:\n\n$$\n\\begin{align}\ny_i \\sim{}& Pois(\\lambda_i)\\\\\nlog(\\lambda_i) =& \\beta_0 + \\beta_1 (x_i - \\bar{x})/\\sigma_{x}\\\\\n\\end{align}\n$$\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\ndat3c.glm <- glmmTMB(y ~ scale(x), data = dat3, family = poisson(link = \"log\"))\ndat3c.glm\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nFormula:          y ~ scale(x)\nData: dat3\n      AIC       BIC    logLik  df.resid \n 50.35456  50.95973 -23.17728         8 \n\nNumber of obs: 10\n\nFixed Effects:\n\nConditional model:\n(Intercept)     scale(x)  \n      1.936        1.037  \n```\n\n\n:::\n:::\n\n\n\nAnd to explore the diagnostics\n\n##### Performance model checking\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\ndat3c.glm |> performance::check_model()\n```\n\n::: {.cell-output-display}\n![](30_glm_files/figure-html/glm_validateMode3a1c-1.png){width=768}\n:::\n\n```{.r .cell-code}\ndat3c.glm |> performance::check_outliers()\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nNULL\n```\n\n\n:::\n:::\n\n\n\n**Conclusions**:\n\n- these diagnostics are broadly acceptable given the small nature of the\n  data\n\n\n##### DHARMa (simulated) residuals\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\ndat.resid <- dat3c.glm |> \n  simulateResiduals(plot = TRUE)\n```\n\n::: {.cell-output-display}\n![](30_glm_files/figure-html/glm_validateModel3b1c-1.png){width=768}\n:::\n:::\n\n\n\n**Conclusions**\n\n- no obvious issues with these diagnostics\n\n##### Summarise model\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\ndat3c.glm |> summary()\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n Family: poisson  ( log )\nFormula:          y ~ scale(x)\nData: dat3\n\n     AIC      BIC   logLik deviance df.resid \n    50.4     51.0    -23.2     46.4        8 \n\n\nConditional model:\n            Estimate Std. Error z value Pr(>|z|)    \n(Intercept)   1.9358     0.1411  13.720  < 2e-16 ***\nscale(x)      1.0374     0.1308   7.932 2.15e-15 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n```\n\n\n:::\n\n```{.r .cell-code}\ndat3c.glm |> fixef()\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n\nConditional model:\n(Intercept)     scale(x)  \n      1.936        1.037  \n```\n\n\n:::\n\n```{.r .cell-code}\ndat3c.glm |> performance::r2()\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n# R2 for Generalized Linear Regression\n  Nagelkerke's R2: 1.000\n```\n\n\n:::\n:::\n\n\n\n:::::::: {.callout-tip}\n\nSince this model used a log link, in order to return the estimates to\nthe scale of the response, we need to backtransform by exponentiation.\n\nImportantly, if using confidence intervals for the purpose of\ninference testsing:\n\n- if using estimates on the link (log) scale, intervals that do not include 0\n  are \"significant\"\n- if using estimates on the response scale, intervals that do not\n  include 1 are \"significant\"\n  \n::::::::\n\n**Interpretation**:\n\n- when $x=0$ (e.g. the average $x$ value since centered), $y$ is\n  expected to be exp(1.936) = \n  6.93 (the y-intercept).\n- for every one unit change in $x$ (which represents a span of approximately 34% of the \n  range of $x$ since standardised), the expected value of $y$\n  increases by exp(1.037) =\n  2.822 (the slope)\n- this is equivalent to a 182.176% \n  increase in the response per one unit change in (standardised) $x$\n- the slope (on the link scale) could be as low as \n  0.781 or\n  as high as 1.294 (95% confidence\n  interval of the slope)\n- as the above interval does not include the value of 0, the linear\n  relationship (slope) can be considered significant\n- the slope (on the response scale) could be as low as \n  2.184 or\n  as high as 3.646 (95% confidence\n  interval of the slope)\n- as the above interval does not include the value of 1, the linear\n  relationship (slope) can be considered significant\n- we would reject the null hypothesis of no relationship (p-value for\n  slope is less than 0.05)\n- 99.982% of the variance in $y$ is\n  explained by its linear relationship with $x$ (R squared value)\n\n:::::\n\n:::::::\n\n### Example 4 (NB data)\n\n::::::: {.panel-tabset}\n\n#### Raw predictor\n\n::::: {.panel-tabset}\n\n##### Fit the model\n\nGiven that exploratory data analysis suggested that the assumptions\nwere not likely to be met for a simple gaussian model and that this\nwas subsequently confirmed when we explored the diagnostics resulting\nfrom the OLS model of these data, we will instead entertain a Negative\nBinomial regression model. The model will be of the form:\n\n$$\n\\begin{align}\ny_i \\sim{}& NB(\\lambda_i, \\phi)\\\\\nlog(\\lambda_i) =& \\beta_0 + \\beta_1 x_i\\\\\n\\end{align}\n$$\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\ndat4.glm <- glmmTMB(y~x, data = dat4, family = nbinom2(link = \"log\"))\n```\n\n::: {.cell-output .cell-output-stderr}\n\n```\nWarning in finalizeTMB(TMBStruc, obj, fit, h, data.tmb.old): Model convergence\nproblem; non-positive-definite Hessian matrix. See vignette('troubleshooting')\n```\n\n\n:::\n\n::: {.cell-output .cell-output-stderr}\n\n```\nWarning in finalizeTMB(TMBStruc, obj, fit, h, data.tmb.old): Model convergence\nproblem; false convergence (8). See vignette('troubleshooting'),\nhelp('diagnose')\n```\n\n\n:::\n\n```{.r .cell-code}\ndat4.glm\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nFormula:          y ~ x\nData: dat4\n     AIC      BIC   logLik df.resid \n      NA       NA       NA        7 \n\nNumber of obs: 10\n\nDispersion parameter for nbinom2 family (): 5.36e+07 \n\nFixed Effects:\n\nConditional model:\n(Intercept)            x  \n     0.3913       0.2792  \n```\n\n\n:::\n:::\n\n\n\nAnd to explore the diagnostics\n\n\n\n##### Performance model checking\n\n\n::: {.cell}\n\n```{.r .cell-code}\ndat4.glm |> performance::check_model()\n```\n\n::: {.cell-output-display}\n![](30_glm_files/figure-html/glm_validateMode4a1-1.png){width=768}\n:::\n\n```{.r .cell-code}\ndat4.glm |> performance::check_outliers()\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nNULL\n```\n\n\n:::\n:::\n\n\n\n**Conclusions**:\n\n- these diagnostics are broadly acceptable given the small nature of the\n  data\n\n\n##### DHARMa (simulated) residuals\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\ndat.resid <- dat4.glm |> \n  simulateResiduals(plot = TRUE)\n```\n\n::: {.cell-output-display}\n![](30_glm_files/figure-html/glm_validateModel4b1-1.png){width=768}\n:::\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\ndat.resid |> testDispersion()\n```\n\n::: {.cell-output-display}\n![](30_glm_files/figure-html/glm_validateModel4b2-1.png){width=384}\n:::\n\n::: {.cell-output .cell-output-stdout}\n\n```\n\n\tDHARMa nonparametric dispersion test via sd of residuals fitted vs.\n\tsimulated\n\ndata:  simulationOutput\ndispersion = 0.56515, p-value = 0.528\nalternative hypothesis: two.sided\n```\n\n\n:::\n:::\n\n\n**Conclusions**\n\n- no obvious issues with these diagnostics\n\n##### Summarise model\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\ndat4.glm |> summary()\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n Family: nbinom2  ( log )\nFormula:          y ~ x\nData: dat4\n\n     AIC      BIC   logLik deviance df.resid \n      NA       NA       NA       NA        7 \n\n\nDispersion parameter for nbinom2 family (): 5.36e+07 \n\nConditional model:\n            Estimate Std. Error z value Pr(>|z|)    \n(Intercept)   0.3913     0.3415   1.146    0.252    \nx             0.2792     0.0431   6.479 9.24e-11 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n```\n\n\n:::\n\n```{.r .cell-code}\ndat4.glm |> confint()\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n                 2.5 %   97.5 %  Estimate\n(Intercept) -0.2779453 1.060588 0.3913216\nx            0.1947710 0.363723 0.2792470\n```\n\n\n:::\n\n```{.r .cell-code}\n#dat4.glm |> performance::r2()\n```\n:::\n\n\n\n:::::::: {.callout-tip}\n\nSince this model used a log link, in order to return the estimates to\nthe scale of the response, we need to backtransform by exponentiation.\n\nImportantly, if using confidence intervals for the purpose of\ninference testsing:\n\n- if using estimates on the link (log) scale, intervals that do not include 0\n  are \"significant\"\n- if using estimates on the response scale, intervals that do not\n  include 1 are \"significant\"\n  \n::::::::\n\n**Interpretation**:\n\n- when $x=0$, $y$ is expected to be exp(0.391) = \n  1.479 (the y-intercept).\n- for every one unit change in $x$, the expected value of $y$\n  increases by exp(0.279) =  \n  1.322 (the slope)\n- this is equivalent to a 32.213% \n  increase in the response per one unit change in $x$\n- the slope (on the link scale) could be as low as \n  0.195 or\n  as high as 0.364 (95% confidence\n  interval of the slope)\n- as the above interval does not include the value of 0, the linear\n  relationship (slope) can be considered significant\n- the slope (on the response scale) could be as low as \n  1.215 or\n  as high as 1.439 (95% confidence\n  interval of the slope)\n- as the above interval does not include the value of 1, the linear\n  relationship (slope) can be considered significant\n- we would reject the null hypothesis of no relationship (p-value for\n  slope is less than 0.05)\n  <!--\n- % of the variance in $y$ is\n  explained by its linear relationship with $x$ (R squared value)\n-->\n:::::\n\n#### Centered predictor\n\n::::: {.panel-tabset}\n\n##### Fit the model\n\nGiven that exploratory data analysis suggested that the assumptions\nwere not likely to be met for a simple gaussian model and that this\nwas subsequently confirmed when we explored the diagnostics resulting\nfrom the OLS model of these data, we will instead entertain a poisson\nregression model. The model will be of the form:\n\n$$\n\\begin{align}\ny_i \\sim{}& NB(\\lambda_i, \\phi)\\\\\nlog(\\lambda_i) =& \\beta_0 + \\beta_1 (x_i - \\bar{x})\\\\\n\\end{align}\n$$\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\ndat4b.glm <- glmmTMB(y ~ scale(x, scale = FALSE), data = dat4, family = nbinom2(link = \"log\"))\n```\n\n::: {.cell-output .cell-output-stderr}\n\n```\nWarning in finalizeTMB(TMBStruc, obj, fit, h, data.tmb.old): Model convergence\nproblem; false convergence (8). See vignette('troubleshooting'),\nhelp('diagnose')\n```\n\n\n:::\n\n```{.r .cell-code}\ndat4b.glm\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nFormula:          y ~ scale(x, scale = FALSE)\nData: dat4\n      AIC       BIC    logLik  df.resid \n 51.39412  52.30187 -22.69706         7 \n\nNumber of obs: 10\n\nDispersion parameter for nbinom2 family (): 2.01e+08 \n\nFixed Effects:\n\nConditional model:\n            (Intercept)  scale(x, scale = FALSE)  \n                 1.9272                   0.2792  \n```\n\n\n:::\n:::\n\n\n\nAnd to explore the diagnostics\n\n\n\n##### Performance model checking\n\n\n::: {.cell}\n\n```{.r .cell-code}\ndat4b.glm |> performance::check_model()\n```\n\n::: {.cell-output-display}\n![](30_glm_files/figure-html/glm_validateMode4a1b-1.png){width=768}\n:::\n\n```{.r .cell-code}\ndat4b.glm |> performance::check_outliers()\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nNULL\n```\n\n\n:::\n:::\n\n\n\n**Conclusions**:\n\n- these diagnostics are broadly acceptable given the small nature of the\n  data\n\n\n##### DHARMa (simulated) residuals\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\ndat.resid <- dat4b.glm |> \n  simulateResiduals(plot = TRUE)\n```\n\n::: {.cell-output-display}\n![](30_glm_files/figure-html/glm_validateModel4b1b-1.png){width=768}\n:::\n:::\n\n\n\n**Conclusions**\n\n- no obvious issues with these diagnostics\n\n##### Summarise model\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\ndat4b.glm |> summary()\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n Family: nbinom2  ( log )\nFormula:          y ~ scale(x, scale = FALSE)\nData: dat4\n\n     AIC      BIC   logLik deviance df.resid \n    51.4     52.3    -22.7     45.4        7 \n\n\nDispersion parameter for nbinom2 family (): 2.01e+08 \n\nConditional model:\n                        Estimate Std. Error z value Pr(>|z|)    \n(Intercept)               1.9272     0.1362  14.151  < 2e-16 ***\nscale(x, scale = FALSE)   0.2792     0.0431   6.479 9.24e-11 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n```\n\n\n:::\n\n```{.r .cell-code}\ndat4b.glm |> confint()\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n                            2.5 %    97.5 % Estimate\n(Intercept)             1.6602543 2.1941059 1.927180\nscale(x, scale = FALSE) 0.1947701 0.3637238 0.279247\n```\n\n\n:::\n\n```{.r .cell-code}\n## dat4b.glm |> performance::r2()\n```\n:::\n\n\n\n:::::::: {.callout-tip}\n\nSince this model used a log link, in order to return the estimates to\nthe scale of the response, we need to backtransform by exponentiation.\n\nImportantly, if using confidence intervals for the purpose of\ninference testsing:\n\n- if using estimates on the link (log) scale, intervals that do not include 0\n  are \"significant\"\n- if using estimates on the response scale, intervals that do not\n  include 1 are \"significant\"\n  \n::::::::\n\n**Interpretation**:\n\n- when $x=0$ (e.g. the average $x$ value since centered), $y$ is\n  expected to be exp(1.927) = \n  6.87 (the y-intercept).\n- for every one unit change in $x$, the expected value of $y$\n  increases by exp(0.279) =  \n  1.322 (the slope)\n- this is equivalent to a 32.213% \n  increase in the response per one unit change in $x$\n- the slope (on the link scale) could be as low as \n  0.195 or\n  as high as 0.364 (95% confidence\n  interval of the slope)\n- as the above interval does not include the value of 0, the linear\n  relationship (slope) can be considered significant\n- the slope (on the response scale) could be as low as \n  1.215 or\n  as high as 1.439 (95% confidence\n  interval of the slope)\n- as the above interval does not include the value of 1, the linear\n  relationship (slope) can be considered significant\n- we would reject the null hypothesis of no relationship (p-value for\n  slope is less than 0.05)\n  <!--\n- % of the variance in $y$ is\n  explained by its linear relationship with $x$ (R squared value)\n-->\n:::::\n\n#### Standardised predictor\n\n::::: {.panel-tabset}\n\n##### Fit the model\n\nGiven that exploratory data analysis suggested that the assumptions\nwere not likely to be met for a simple gaussian model and that this\nwas subsequently confirmed when we explored the diagnostics resulting\nfrom the OLS model of these data, we will instead entertain a poisson\nregression model. The model will be of the form:\n\n$$\n\\begin{align}\ny_i \\sim{}& NB(\\lambda_i, \\phi)\\\\\nlog(\\lambda_i) =& \\beta_0 + \\beta_1 (x_i - \\bar{x})/\\sigma_{x}\\\\\n\\end{align}\n$$\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\ndat4c.glm <- glmmTMB(y ~ scale(x), data = dat4, family = nbinom2(link = \"log\"))\n```\n\n::: {.cell-output .cell-output-stderr}\n\n```\nWarning in finalizeTMB(TMBStruc, obj, fit, h, data.tmb.old): Model convergence\nproblem; non-positive-definite Hessian matrix. See vignette('troubleshooting')\n```\n\n\n:::\n\n::: {.cell-output .cell-output-stderr}\n\n```\nWarning in finalizeTMB(TMBStruc, obj, fit, h, data.tmb.old): Model convergence\nproblem; false convergence (8). See vignette('troubleshooting'),\nhelp('diagnose')\n```\n\n\n:::\n\n```{.r .cell-code}\ndat4c.glm\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nFormula:          y ~ scale(x)\nData: dat4\n     AIC      BIC   logLik df.resid \n      NA       NA       NA        7 \n\nNumber of obs: 10\n\nDispersion parameter for nbinom2 family (): 2.21e+08 \n\nFixed Effects:\n\nConditional model:\n(Intercept)     scale(x)  \n     1.9272       0.8455  \n```\n\n\n:::\n:::\n\n\n\nAnd to explore the diagnostics\n\n##### Performance model checking\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\ndat4c.glm |> performance::check_model()\n```\n\n::: {.cell-output-display}\n![](30_glm_files/figure-html/glm_validateMode4a1c-1.png){width=768}\n:::\n\n```{.r .cell-code}\ndat4c.glm |> performance::check_outliers()\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nNULL\n```\n\n\n:::\n:::\n\n\n\n**Conclusions**:\n\n- these diagnostics are broadly acceptable given the small nature of the\n  data\n\n\n##### DHARMa (simulated) residuals\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\ndat.resid <- dat4c.glm |> \n  simulateResiduals(plot = TRUE)\n```\n\n::: {.cell-output-display}\n![](30_glm_files/figure-html/glm_validateModel4b1c-1.png){width=768}\n:::\n:::\n\n\n\n**Conclusions**\n\n- no obvious issues with these diagnostics\n\n##### Summarise model\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\ndat4c.glm |> summary()\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n Family: nbinom2  ( log )\nFormula:          y ~ scale(x)\nData: dat4\n\n     AIC      BIC   logLik deviance df.resid \n      NA       NA       NA       NA        7 \n\n\nDispersion parameter for nbinom2 family (): 2.21e+08 \n\nConditional model:\n            Estimate Std. Error z value Pr(>|z|)    \n(Intercept)   1.9272     0.1362  14.151  < 2e-16 ***\nscale(x)      0.8455     0.1305   6.479 9.25e-11 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n```\n\n\n:::\n\n```{.r .cell-code}\ndat4c.glm |> confint()\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n                2.5 %   97.5 %  Estimate\n(Intercept) 1.6602472 2.194100 1.9271735\nscale(x)    0.5896881 1.101223 0.8454555\n```\n\n\n:::\n\n```{.r .cell-code}\n## dat4c.glm |> performance::r2()\n```\n:::\n\n\n\n:::::::: {.callout-tip}\n\nSince this model used a log link, in order to return the estimates to\nthe scale of the response, we need to backtransform by exponentiation.\n\nImportantly, if using confidence intervals for the purpose of\ninference testsing:\n\n- if using estimates on the link (log) scale, intervals that do not include 0\n  are \"significant\"\n- if using estimates on the response scale, intervals that do not\n  include 1 are \"significant\"\n  \n::::::::\n\n**Interpretation**:\n\n- when $x=0$ (e.g. the average $x$ value since centered), $y$ is\n  expected to be exp(1.927) = \n  6.87 (the y-intercept).\n- for every one unit change in $x$ (which represents a span of approximately 34% of the \n  range of $x$ since standardised), the expected value of $y$\n  increases by exp(0.845) =\n  2.329 (the slope)\n- this is equivalent to a 132.904% \n  increase in the response per one unit change in (standardised) $x$\n- the slope (on the link scale) could be as low as \n  0.59 or\n  as high as 1.101 (95% confidence\n  interval of the slope)\n- as the above interval does not include the value of 0, the linear\n  relationship (slope) can be considered significant\n- the slope (on the response scale) could be as low as \n  1.803 or\n  as high as 3.008 (95% confidence\n  interval of the slope)\n- as the above interval does not include the value of 1, the linear\n  relationship (slope) can be considered significant\n- we would reject the null hypothesis of no relationship (p-value for\n  slope is less than 0.05)\n  <!--\n- % of the variance in $y$ is\n  explained by its linear relationship with $x$ (R squared value)\n-->\n:::::\n\n:::::::\n\n### Example  5 (Binary data)\n\n::::::: {.panel-tabset}\n\n#### Raw predictor\n\n::::: {.panel-tabset}\n\n##### Fit model\n\nGiven that exploratory data analysis suggested that the assumptions\nwere not likely to be met for a simple gaussian model and that this\nwas subsequently confirmed when we explored the diagnostics resulting\nfrom the OLS model of these data, we will instead entertain a\nBernoulli (Binomial with number of trials = 1) regression model. The\nmodel will be of the form:\n\n$$\n\\begin{align}\ny_i \\sim{}& Bin(\\pi, 1)\\\\\nlogit(\\frac{\\pi}{1-\\pi}) =& \\beta_0 + \\beta_1 x_i\\\\\n\\end{align}\n$$\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\ndat5.glm <- glmmTMB(y ~ x, data = dat5, family = binomial(link = \"logit\"))\ndat5.glm\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nFormula:          y ~ x\nData: dat5\n     AIC      BIC   logLik df.resid \n 9.01379  9.61896 -2.50690        8 \n\nNumber of obs: 10\n\nFixed Effects:\n\nConditional model:\n(Intercept)            x  \n     -5.825        1.295  \n```\n\n\n:::\n:::\n\n\n\nAnd to explore the diagnostics\n\n\n\n##### Performance model checking\n\n\n::: {.cell}\n\n```{.r .cell-code}\ndat5.glm |> performance::check_model(residual_type = \"normal\")\n```\n\n::: {.cell-output-display}\n![](30_glm_files/figure-html/glm_validateMode5a1-1.png){width=768}\n:::\n\n```{.r .cell-code}\ndat5.glm |> performance::check_outliers(residual_type = \"normal\")\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nNULL\n```\n\n\n:::\n:::\n\n\n\n**Conclusions**:\n\n- these diagnostics are broadly acceptable given the small nature of the\n  data\n\n\n##### DHARMa (simulated) residuals\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\ndat.resid <- dat5.glm |> \n  simulateResiduals(plot = TRUE)\n```\n\n::: {.cell-output-display}\n![](30_glm_files/figure-html/glm_validateModel5b1-1.png){width=768}\n:::\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\ndat.resid |> testDispersion()\n```\n\n::: {.cell-output-display}\n![](30_glm_files/figure-html/glm_validateModel5b2-1.png){width=384}\n:::\n\n::: {.cell-output .cell-output-stdout}\n\n```\n\n\tDHARMa nonparametric dispersion test via sd of residuals fitted vs.\n\tsimulated\n\ndata:  simulationOutput\ndispersion = 1.3257, p-value = 0.76\nalternative hypothesis: two.sided\n```\n\n\n:::\n:::\n\n\n**Conclusions**\n\n- no obvious issues with these diagnostics\n\n##### Summarise model\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\ndat5.glm |> summary()\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n Family: binomial  ( logit )\nFormula:          y ~ x\nData: dat5\n\n     AIC      BIC   logLik deviance df.resid \n     9.0      9.6     -2.5      5.0        8 \n\n\nConditional model:\n            Estimate Std. Error z value Pr(>|z|)\n(Intercept)  -5.8246     3.9861  -1.461    0.144\nx             1.2954     0.8451   1.533    0.125\n```\n\n\n:::\n\n```{.r .cell-code}\ndat5.glm |> confint()\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n                  2.5 %   97.5 %  Estimate\n(Intercept) -13.6371807 1.987979 -5.824601\nx            -0.3609074 2.951782  1.295437\n```\n\n\n:::\n\n```{.r .cell-code}\ndat5.glm |> performance::r2()\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n# R2 for Logistic Regression\n  Tjur's R2: 0.653\n```\n\n\n:::\n:::\n\n\n\n:::::::: {.callout-tip}\n\nSince this model used a logit link ($log(\\frac{\\pi}{1-\\pi})$), in\norder to return the estimates to the scale of the response, we can\neither:\n\n- for the y-intercept:\n  - backtransform by exponentiation to odds ratio ($\\frac{\\pi}{1-\\pi}$).\n  - backtransform to probability by exponentiation of the odds ratio\n    ($\\pi$).\n- for the slopes:\n  - backtransform by exponentiation to odds ratio.\n\nImportantly, if using confidence intervals for the purpose of\ninference testsing:\n\n- if using estimates on the link (logit) scale, intervals that do not include 0\n  are \"significant\"\n- if using estimates on the response scale, intervals that do not\n  include 1 are \"significant\"\n  \n::::::::\n\n**Interpretation**:\n\n- when $x=0$:\n  - the odds of $y$ being 1 vs 0 is expected to be \n    exp(-5.825) = \n    0.003 (the y-intercept).\n  - the probability of $y$ being 1 is expected to be \n    plogis(-5.825) = \n    0.003 (the y-intercept).\n- for every one unit change in $x$, the odds of $y$\n  increases by exp(1.295) =  \n  3.653 (the slope)\n- this is equivalent to a 265.259% \n  increase in the odds of the response being 1 per one unit change in $x$\n- the slope (on the link scale) could be as low as \n  -0.361 or\n  as high as 2.952 (95% confidence\n  interval of the slope)\n- as the above interval does not include the value of 0, the linear\n  relationship (slope) can be considered significant\n- the slope (on the response scale) could be as low as \n  0.697 or\n  as high as 19.14 (95% confidence\n  interval of the slope)\n- as the above interval does not include the value of 1, the linear\n  relationship (slope) can be considered significant\n- we would reject the null hypothesis of no relationship (p-value for\n  slope is less than 0.05)\n- 65.333% of the variance in $y$ is\n  explained by its linear relationship with $x$ (R squared value)\n\n\n:::::\n\n#### Centered predictor\n\n::::: {.panel-tabset}\n\n##### Fit the model\n\nGiven that exploratory data analysis suggested that the assumptions\nwere not likely to be met for a simple gaussian model and that this\nwas subsequently confirmed when we explored the diagnostics resulting\nfrom the OLS model of these data, we will instead entertain a poisson\nregression model. The model will be of the form:\n\n$$\n\\begin{align}\ny_i \\sim{}& Bin(\\pi_i, 1)\\\\\nlog(\\frac{\\pi_i}{1-\\pi_i}) =& \\beta_0 + \\beta_1 (x_i - \\bar{x})\\\\\n\\end{align}\n$$\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\ndat5b.glm <- glmmTMB(y ~ scale(x, scale = FALSE), data = dat5, family = binomial(link = \"logit\"))\ndat5b.glm\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nFormula:          y ~ scale(x, scale = FALSE)\nData: dat5\n     AIC      BIC   logLik df.resid \n 9.01379  9.61896 -2.50690        8 \n\nNumber of obs: 10\n\nFixed Effects:\n\nConditional model:\n            (Intercept)  scale(x, scale = FALSE)  \n                  1.300                    1.295  \n```\n\n\n:::\n:::\n\n\n\nAnd to explore the diagnostics\n\n\n\n##### Performance model checking\n\n\n::: {.cell}\n\n```{.r .cell-code}\ndat5b.glm |> performance::check_model(residual_type = \"normal\")\n```\n\n::: {.cell-output-display}\n![](30_glm_files/figure-html/glm_validateMode5a1b-1.png){width=768}\n:::\n\n```{.r .cell-code}\ndat5b.glm |> performance::check_outliers(residual_type = \"normal\")\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nNULL\n```\n\n\n:::\n:::\n\n\n\n**Conclusions**:\n\n- these diagnostics are broadly acceptable given the small nature of the\n  data\n\n\n##### DHARMa (simulated) residuals\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\ndat.resid <- dat5b.glm |> \n  simulateResiduals(plot = TRUE)\n```\n\n::: {.cell-output-display}\n![](30_glm_files/figure-html/glm_validateModel5b1b-1.png){width=768}\n:::\n:::\n\n\n\n**Conclusions**\n\n- no obvious issues with these diagnostics\n\n##### Summarise model\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\ndat5b.glm |> summary()\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n Family: binomial  ( logit )\nFormula:          y ~ scale(x, scale = FALSE)\nData: dat5\n\n     AIC      BIC   logLik deviance df.resid \n     9.0      9.6     -2.5      5.0        8 \n\n\nConditional model:\n                        Estimate Std. Error z value Pr(>|z|)\n(Intercept)               1.3003     1.4106   0.922    0.357\nscale(x, scale = FALSE)   1.2954     0.8451   1.533    0.125\n```\n\n\n:::\n\n```{.r .cell-code}\ndat5b.glm |> confint()\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n                             2.5 %   97.5 % Estimate\n(Intercept)             -1.4643927 4.064993 1.300300\nscale(x, scale = FALSE) -0.3609129 2.951788 1.295437\n```\n\n\n:::\n\n```{.r .cell-code}\ndat5b.glm |> performance::r2()\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n# R2 for Logistic Regression\n  Tjur's R2: 0.653\n```\n\n\n:::\n:::\n\n\n\n:::::::: {.callout-tip}\n\nSince this model used a logit link ($log(\\frac{\\pi}{1-\\pi})$), in\norder to return the estimates to the scale of the response, we can\neither:\n\n- for the y-intercept:\n  - backtransform by exponentiation to odds ratio ($\\frac{\\pi}{1-\\pi}$).\n  - backtransform to probability by exponentiation of the odds ratio\n    ($\\pi$).\n- for the slopes:\n  - backtransform by exponentiation to odds ratio.\n\nImportantly, if using confidence intervals for the purpose of\ninference testsing:\n\n- if using estimates on the link (logit) scale, intervals that do not include 0\n  are \"significant\"\n- if using estimates on the response scale, intervals that do not\n  include 1 are \"significant\"\n  \n::::::::\n\n**Interpretation**:\n\n- when $x=0$ (e.g. the average $x$ value since centered):\n  - the odds of $y$ being 1 vs 0 is expected to be \n    exp(1.3) = \n    3.67 (the y-intercept).\n  - the probability of $y$ being 1 is expected to be \n    plogis(1.3) = \n    0.786 (the y-intercept).\n- for every one unit change in $x$, the odds of $y$\n  increases by exp(1.295) =  \n  3.653 (the slope)\n- this is equivalent to a 265.259% \n  increase in the odds of the response being 1 per one unit change in $x$\n- the slope (on the link scale) could be as low as \n  -0.361 or\n  as high as 2.952 (95% confidence\n  interval of the slope)\n- as the above interval does not include the value of 0, the linear\n  relationship (slope) can be considered significant\n- the slope (on the response scale) could be as low as \n  0.697 or\n  as high as 19.14 (95% confidence\n  interval of the slope)\n- as the above interval does not include the value of 1, the linear\n  relationship (slope) can be considered significant\n- we would reject the null hypothesis of no relationship (p-value for\n  slope is less than 0.05)\n- 65.333% of the variance in $y$ is\n  explained by its linear relationship with $x$ (R squared value)\n\n:::::\n\n#### Standardised predictor\n\n::::: {.panel-tabset}\n\n##### Fit the model\n\nGiven that exploratory data analysis suggested that the assumptions\nwere not likely to be met for a simple gaussian model and that this\nwas subsequently confirmed when we explored the diagnostics resulting\nfrom the OLS model of these data, we will instead entertain a poisson\nregression model. The model will be of the form:\n\n$$\n\\begin{align}\ny_i \\sim{}& Bin(\\pi_i, \\phi)\\\\\nlog(\\frac{\\pi_i}{1-\\pi}) =& \\beta_0 + \\beta_1 (x_i - \\bar{x})/\\sigma_{x}\\\\\n\\end{align}\n$$\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\ndat5c.glm <- glmmTMB(y ~ scale(x), data = dat5, family = binomial(link = \"logit\"))\ndat5c.glm\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nFormula:          y ~ scale(x)\nData: dat5\n     AIC      BIC   logLik df.resid \n 9.01379  9.61896 -2.50690        8 \n\nNumber of obs: 10\n\nFixed Effects:\n\nConditional model:\n(Intercept)     scale(x)  \n      1.300        3.922  \n```\n\n\n:::\n:::\n\n\n\nAnd to explore the diagnostics\n\n##### Performance model checking\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\ndat5c.glm |> performance::check_model(residual_type = \"normal\")\n```\n\n::: {.cell-output-display}\n![](30_glm_files/figure-html/glm_validateMode5a1c-1.png){width=768}\n:::\n\n```{.r .cell-code}\ndat5c.glm |> performance::check_outliers(residual_type = \"normal\")\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nNULL\n```\n\n\n:::\n:::\n\n\n\n**Conclusions**:\n\n- these diagnostics are broadly acceptable given the small nature of the\n  data\n\n\n##### DHARMa (simulated) residuals\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\ndat.resid <- dat5c.glm |> \n  simulateResiduals(plot = TRUE)\n```\n\n::: {.cell-output-display}\n![](30_glm_files/figure-html/glm_validateModel5b1c-1.png){width=768}\n:::\n:::\n\n\n\n**Conclusions**\n\n- no obvious issues with these diagnostics\n\n##### Summarise model\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\ndat5c.glm |> summary()\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n Family: binomial  ( logit )\nFormula:          y ~ scale(x)\nData: dat5\n\n     AIC      BIC   logLik deviance df.resid \n     9.0      9.6     -2.5      5.0        8 \n\n\nConditional model:\n            Estimate Std. Error z value Pr(>|z|)\n(Intercept)    1.300      1.411   0.922    0.357\nscale(x)       3.922      2.559   1.533    0.125\n```\n\n\n:::\n\n```{.r .cell-code}\ndat5c.glm |> confint()\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n                2.5 %   97.5 % Estimate\n(Intercept) -1.464392 4.064999 1.300304\nscale(x)    -1.092721 8.936984 3.922131\n```\n\n\n:::\n\n```{.r .cell-code}\ndat5c.glm |> performance::r2()\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n# R2 for Logistic Regression\n  Tjur's R2: 0.653\n```\n\n\n:::\n:::\n\n\n\n:::::::: {.callout-tip}\n\nSince this model used a logit link ($log(\\frac{\\pi}{1-\\pi})$), in\norder to return the estimates to the scale of the response, we can\neither:\n\n- for the y-intercept:\n  - backtransform by exponentiation to odds ratio ($\\frac{\\pi}{1-\\pi}$).\n  - backtransform to probability by exponentiation of the odds ratio\n    ($\\pi$).\n- for the slopes:\n  - backtransform by exponentiation to odds ratio.\n\nImportantly, if using confidence intervals for the purpose of\ninference testsing:\n\n- if using estimates on the link (logit) scale, intervals that do not include 0\n  are \"significant\"\n- if using estimates on the response scale, intervals that do not\n  include 1 are \"significant\"\n  \n::::::::\n\n**Interpretation**:\n\n- when $x=0$ (e.g. the average $x$ value since centered):\n  - the odds of $y$ being 1 vs 0 is expected to be \n    exp(1.3) = \n    3.67 (the y-intercept).\n  - the probability of $y$ being 1 is expected to be \n    plogis(1.3) = \n    0.786 (the y-intercept).\n- for every one unit change in $x$ (which represents a span of approximately 34% of the \n  range of $x$ since standardised), the odds of $y$\n  increases by exp(3.922) =  \n  50.508 (the slope)\n- this is equivalent to a 4950.799% \n  increase in the odds of the response being 1 per one unit change in (standardised) $x$\n- the slope (on the link scale) could be as low as \n  -1.093 or\n  as high as 8.937 (95% confidence\n  interval of the slope)\n- as the above interval does not include the value of 0, the linear\n  relationship (slope) can be considered significant\n- the slope (on the response scale) could be as low as \n  0.335 or\n  as high as 7608.213 (95% confidence\n  interval of the slope)\n- as the above interval does not include the value of 1, the linear\n  relationship (slope) can be considered significant\n- we would reject the null hypothesis of no relationship (p-value for\n  slope is less than 0.05)\n- 65.333% of the variance in $y$ is\n  explained by its linear relationship with $x$ (R squared value)\n\n:::::\n\n:::::::\n\n### Example  6 (Binomial data)\n\n::::::: {.panel-tabset}\n\n#### Raw predictor\n\n::::: {.panel-tabset}\n\n##### Fit model\n\nGiven that exploratory data analysis suggested that the assumptions\nwere not likely to be met for a simple gaussian model and that this\nwas subsequently confirmed when we explored the diagnostics resulting\nfrom the OLS model of these data, we will instead entertain a Binomial\nregression model. The model will be of the form:\n\n$$\n\\begin{align}\ny_i \\sim{}& Bin(\\pi, n)\\\\\nlogit(\\frac{\\pi}{1-\\pi}) =& \\beta_0 + \\beta_1 x_i\\\\\n\\end{align}\n$$\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\ndat6.glm <- glmmTMB(cbind(count, total - count) ~ x, data = dat6, family = binomial(link = \"logit\"))\ndat6.glm\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nFormula:          cbind(count, total - count) ~ x\nData: dat6\n     AIC      BIC   logLik df.resid \n22.93434 23.53951 -9.46717        8 \n\nNumber of obs: 10\n\nFixed Effects:\n\nConditional model:\n(Intercept)            x  \n    -3.3295       0.8234  \n```\n\n\n:::\n:::\n\n\n\nAnd to explore the diagnostics\n\n\n\n##### Performance model checking\n\n\n::: {.cell}\n\n```{.r .cell-code}\ndat6.glm |> performance::check_model(residual_type = \"normal\")\n```\n\n::: {.cell-output-display}\n![](30_glm_files/figure-html/glm_validateMode6a1-1.png){width=768}\n:::\n\n```{.r .cell-code}\ndat6.glm |> performance::check_outliers(residual_type = \"normal\")\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nNULL\n```\n\n\n:::\n:::\n\n\n\n**Conclusions**:\n\n- these diagnostics are broadly acceptable given the small nature of the\n  data\n\n\n##### DHARMa (simulated) residuals\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\ndat.resid <- dat6.glm |> \n  simulateResiduals(plot = TRUE)\n```\n\n::: {.cell-output-display}\n![](30_glm_files/figure-html/glm_validateModel6b1-1.png){width=768}\n:::\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\ndat.resid |> testDispersion()\n```\n\n::: {.cell-output-display}\n![](30_glm_files/figure-html/glm_validateModel6b2-1.png){width=384}\n:::\n\n::: {.cell-output .cell-output-stdout}\n\n```\n\n\tDHARMa nonparametric dispersion test via sd of residuals fitted vs.\n\tsimulated\n\ndata:  simulationOutput\ndispersion = 1.0614, p-value = 0.76\nalternative hypothesis: two.sided\n```\n\n\n:::\n:::\n\n\n**Conclusions**\n\n- no obvious issues with these diagnostics\n\n##### Summarise model\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\ndat6.glm |> summary()\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n Family: binomial  ( logit )\nFormula:          cbind(count, total - count) ~ x\nData: dat6\n\n     AIC      BIC   logLik deviance df.resid \n    22.9     23.5     -9.5     18.9        8 \n\n\nConditional model:\n            Estimate Std. Error z value Pr(>|z|)    \n(Intercept)  -3.3295     1.0441  -3.189 0.001429 ** \nx             0.8234     0.2246   3.667 0.000246 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n```\n\n\n:::\n\n```{.r .cell-code}\ndat6.glm |> confint()\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n                 2.5 %    97.5 %   Estimate\n(Intercept) -5.3758818 -1.283040 -3.3294608\nx            0.3832516  1.263571  0.8234113\n```\n\n\n:::\n\n```{.r .cell-code}\ndat6.glm |> performance::r2()\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nNULL\n```\n\n\n:::\n:::\n\n\n\n:::::::: {.callout-tip}\n\nSince this model used a logit link ($log(\\frac{\\pi}{1-\\pi})$), in\norder to return the estimates to the scale of the response, we can\neither:\n\n- for the y-intercept:\n  - backtransform by exponentiation to odds ratio ($\\frac{\\pi}{1-\\pi}$).\n  - backtransform to probability by exponentiation of the odds ratio\n    ($\\pi$).\n- for the slopes:\n  - backtransform by exponentiation to odds ratio.\n\nImportantly, if using confidence intervals for the purpose of\ninference testsing:\n\n- if using estimates on the link (logit) scale, intervals that do not include 0\n  are \"significant\"\n- if using estimates on the response scale, intervals that do not\n  include 1 are \"significant\"\n  \n::::::::\n\n**Interpretation**:\n\n- when $x=0$:\n  - the odds of $y$ being 1 vs 0 is expected to be \n    exp(-3.329) = \n    0.036 (the y-intercept).\n  - the probability of $y$ being 1 is expected to be \n    plogis(-3.329) = \n    0.035 (the y-intercept).\n- for every one unit change in $x$, the odds of $y$\n  increases by exp(0.823) =  \n  2.278 (the slope)\n- this is equivalent to a 127.826% \n  increase in the odds of the response being 1 per one unit change in $x$\n- the slope (on the link scale) could be as low as \n  0.383 or\n  as high as 1.264 (95% confidence\n  interval of the slope)\n- as the above interval does not include the value of 0, the linear\n  relationship (slope) can be considered significant\n- the slope (on the response scale) could be as low as \n  1.467 or\n  as high as 3.538 (95% confidence\n  interval of the slope)\n- as the above interval does not include the value of 1, the linear\n  relationship (slope) can be considered significant\n- we would reject the null hypothesis of no relationship (p-value for\n  slope is less than 0.05)\n- % of the variance in $y$ is\n  explained by its linear relationship with $x$ (R squared value)\n\n:::::\n\n#### Centered predictor\n\n::::: {.panel-tabset}\n\n##### Fit the model\n\nGiven that exploratory data analysis suggested that the assumptions\nwere not likely to be met for a simple gaussian model and that this\nwas subsequently confirmed when we explored the diagnostics resulting\nfrom the OLS model of these data, we will instead entertain a poisson\nregression model. The model will be of the form:\n\n$$\n\\begin{align}\ny_i \\sim{}& Bin(\\pi_i, n)\\\\\nlog(\\frac{\\pi_i}{1-\\pi_i}) =& \\beta_0 + \\beta_1 (x_i - \\bar{x})\\\\\n\\end{align}\n$$\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\ndat6b.glm <- glmmTMB(cbind(count, total - count) ~ scale(x, scale = FALSE), data = dat6, family = binomial(link = \"logit\"))\ndat6b.glm\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nFormula:          cbind(count, total - count) ~ scale(x, scale = FALSE)\nData: dat6\n     AIC      BIC   logLik df.resid \n22.93434 23.53951 -9.46717        8 \n\nNumber of obs: 10\n\nFixed Effects:\n\nConditional model:\n            (Intercept)  scale(x, scale = FALSE)  \n                 1.1993                   0.8234  \n```\n\n\n:::\n:::\n\n\n\nAnd to explore the diagnostics\n\n\n\n##### Performance model checking\n\n\n::: {.cell}\n\n```{.r .cell-code}\ndat6b.glm |> performance::check_model(residual_type = \"normal\")\n```\n\n::: {.cell-output-display}\n![](30_glm_files/figure-html/glm_validateMode6a1b-1.png){width=768}\n:::\n\n```{.r .cell-code}\ndat6b.glm |> performance::check_outliers(residual_type = \"normal\")\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nNULL\n```\n\n\n:::\n:::\n\n\n\n**Conclusions**:\n\n- these diagnostics are broadly acceptable given the small nature of the\n  data\n\n\n##### DHARMa (simulated) residuals\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\ndat.resid <- dat6b.glm |> \n  simulateResiduals(plot = TRUE)\n```\n\n::: {.cell-output-display}\n![](30_glm_files/figure-html/glm_validateModel6b1b-1.png){width=768}\n:::\n:::\n\n\n\n**Conclusions**\n\n- no obvious issues with these diagnostics\n\n##### Summarise model\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\ndat6b.glm |> summary()\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n Family: binomial  ( logit )\nFormula:          cbind(count, total - count) ~ scale(x, scale = FALSE)\nData: dat6\n\n     AIC      BIC   logLik deviance df.resid \n    22.9     23.5     -9.5     18.9        8 \n\n\nConditional model:\n                        Estimate Std. Error z value Pr(>|z|)    \n(Intercept)               1.1993     0.5016   2.391 0.016801 *  \nscale(x, scale = FALSE)   0.8234     0.2246   3.667 0.000246 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n```\n\n\n:::\n\n```{.r .cell-code}\ndat6b.glm |> confint()\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n                            2.5 %   97.5 %  Estimate\n(Intercept)             0.2162207 2.182382 1.1993015\nscale(x, scale = FALSE) 0.3832501 1.263573 0.8234114\n```\n\n\n:::\n\n```{.r .cell-code}\ndat6b.glm |> performance::r2()\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nNULL\n```\n\n\n:::\n:::\n\n\n\n:::::::: {.callout-tip}\n\nSince this model used a logit link ($log(\\frac{\\pi}{1-\\pi})$), in\norder to return the estimates to the scale of the response, we can\neither:\n\n- for the y-intercept:\n  - backtransform by exponentiation to odds ratio ($\\frac{\\pi}{1-\\pi}$).\n  - backtransform to probability by exponentiation of the odds ratio\n    ($\\pi$).\n- for the slopes:\n  - backtransform by exponentiation to odds ratio.\n\nImportantly, if using confidence intervals for the purpose of\ninference testsing:\n\n- if using estimates on the link (logit) scale, intervals that do not include 0\n  are \"significant\"\n- if using estimates on the response scale, intervals that do not\n  include 1 are \"significant\"\n  \n::::::::\n\n**Interpretation**:\n\n- when $x=0$ (e.g. the average $x$ value since centered):\n  - the odds of $y$ being 1 vs 0 is expected to be \n    exp(1.199) = \n    3.318 (the y-intercept).\n  - the probability of $y$ being 1 is expected to be \n    plogis(1.199) = \n    0.768 (the y-intercept).\n- for every one unit change in $x$, the odds of $y$\n  increases by exp(0.823) =  \n  2.278 (the slope)\n- this is equivalent to a 127.826% \n  increase in the odds of the response being 1 per one unit change in $x$\n- the slope (on the link scale) could be as low as \n  0.383 or\n  as high as 1.264 (95% confidence\n  interval of the slope)\n- as the above interval does not include the value of 0, the linear\n  relationship (slope) can be considered significant\n- the slope (on the response scale) could be as low as \n  1.467 or\n  as high as 3.538 (95% confidence\n  interval of the slope)\n- as the above interval does not include the value of 1, the linear\n  relationship (slope) can be considered significant\n- we would reject the null hypothesis of no relationship (p-value for\n  slope is less than 0.05)\n- % of the variance in $y$ is\n  explained by its linear relationship with $x$ (R squared value)\n\n:::::\n\n#### Standardised predictor\n\n::::: {.panel-tabset}\n\n##### Fit the model\n\nGiven that exploratory data analysis suggested that the assumptions\nwere not likely to be met for a simple gaussian model and that this\nwas subsequently confirmed when we explored the diagnostics resulting\nfrom the OLS model of these data, we will instead entertain a poisson\nregression model. The model will be of the form:\n\n$$\n\\begin{align}\ny_i \\sim{}& Bin(\\pi_i, n)\\\\\nlog(\\frac{\\pi_i}{1-\\pi}) =& \\beta_0 + \\beta_1 (x_i - \\bar{x})/\\sigma_{x}\\\\\n\\end{align}\n$$\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\ndat6c.glm <- glmmTMB(cbind(count, total - count) ~ scale(x), data = dat6, family = binomial(link = \"logit\"))\ndat6c.glm\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nFormula:          cbind(count, total - count) ~ scale(x)\nData: dat6\n     AIC      BIC   logLik df.resid \n22.93434 23.53951 -9.46717        8 \n\nNumber of obs: 10\n\nFixed Effects:\n\nConditional model:\n(Intercept)     scale(x)  \n      1.199        2.493  \n```\n\n\n:::\n:::\n\n\n\nAnd to explore the diagnostics\n\n##### Performance model checking\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\ndat6c.glm |> performance::check_model(residual_type = \"normal\")\n```\n\n::: {.cell-output-display}\n![](30_glm_files/figure-html/glm_validateMode6a1c-1.png){width=768}\n:::\n\n```{.r .cell-code}\ndat6c.glm |> performance::check_outliers(residual_type = \"normal\")\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nNULL\n```\n\n\n:::\n:::\n\n\n\n**Conclusions**:\n\n- these diagnostics are broadly acceptable given the small nature of the\n  data\n\n\n##### DHARMa (simulated) residuals\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\ndat.resid <- dat6c.glm |> \n  simulateResiduals(plot = TRUE)\n```\n\n::: {.cell-output-display}\n![](30_glm_files/figure-html/glm_validateModel6b1c-1.png){width=768}\n:::\n:::\n\n\n\n**Conclusions**\n\n- no obvious issues with these diagnostics\n\n##### Summarise model\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\ndat6c.glm |> summary()\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n Family: binomial  ( logit )\nFormula:          cbind(count, total - count) ~ scale(x)\nData: dat6\n\n     AIC      BIC   logLik deviance df.resid \n    22.9     23.5     -9.5     18.9        8 \n\n\nConditional model:\n            Estimate Std. Error z value Pr(>|z|)    \n(Intercept)   1.1993     0.5016   2.391 0.016801 *  \nscale(x)      2.4930     0.6799   3.667 0.000246 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n```\n\n\n:::\n\n```{.r .cell-code}\ndat6c.glm |> confint()\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n                2.5 %   97.5 % Estimate\n(Intercept) 0.2162206 2.182382 1.199301\nscale(x)    1.1603468 3.825657 2.493002\n```\n\n\n:::\n\n```{.r .cell-code}\ndat6c.glm |> performance::r2()\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nNULL\n```\n\n\n:::\n:::\n\n\n\n:::::::: {.callout-tip}\n\nSince this model used a logit link ($log(\\frac{\\pi}{1-\\pi})$), in\norder to return the estimates to the scale of the response, we can\neither:\n\n- for the y-intercept:\n  - backtransform by exponentiation to odds ratio ($\\frac{\\pi}{1-\\pi}$).\n  - backtransform to probability by exponentiation of the odds ratio\n    ($\\pi$).\n- for the slopes:\n  - backtransform by exponentiation to odds ratio.\n\nImportantly, if using confidence intervals for the purpose of\ninference testsing:\n\n- if using estimates on the link (logit) scale, intervals that do not include 0\n  are \"significant\"\n- if using estimates on the response scale, intervals that do not\n  include 1 are \"significant\"\n  \n::::::::\n\n**Interpretation**:\n\n- when $x=0$ (e.g. the average $x$ value since centered):\n  - the odds of $y$ being 1 vs 0 is expected to be \n    exp(1.199) = \n    3.318 (the y-intercept).\n  - the probability of $y$ being 1 is expected to be \n    plogis(1.199) = \n    0.768 (the y-intercept).\n- for every one unit change in $x$ (which represents a span of approximately 34% of the \n  range of $x$ since standardised), the odds of $y$\n  increases by exp(2.493) =  \n  12.098 (the slope)\n- this is equivalent to a 1109.753% \n  increase in the odds of the response being 1 per one unit change in (standardised) $x$\n- the slope (on the link scale) could be as low as \n  1.16 or\n  as high as 3.826 (95% confidence\n  interval of the slope)\n- as the above interval does not include the value of 0, the linear\n  relationship (slope) can be considered significant\n- the slope (on the response scale) could be as low as \n  3.191 or\n  as high as 45.863 (95% confidence\n  interval of the slope)\n- as the above interval does not include the value of 1, the linear\n  relationship (slope) can be considered significant\n- we would reject the null hypothesis of no relationship (p-value for\n  slope is less than 0.05)\n- % of the variance in $y$ is\n  explained by its linear relationship with $x$ (R squared value)\n\n:::::\n\n:::::::\n\n::::\n\n\n# Iterative re-weighted least squares\n\n\n::: {.callout-note collapse=\"true\"}\n### Technical details\n\nRecall from the previous section that the simple linear model can be\nwritten as:\n\n$$\n\\begin{align}\ny_i =& \\beta_0 + \\beta_1 x_i + \\varepsilon_i\\\\\nY =& \\boldsymbol{X}\\boldsymbol{\\beta} + \\boldsymbol{\\varepsilon}\n\\end{align}\n$$\n\nThis could be re-written as:\n\n$$\n\\begin{align}\ny_i \\sim{}& N(\\mu_i, \\sigma^2I)\\\\\n\\mu_i =& \\beta_0 + \\beta_1 x_i\\\\\n\\end{align}\n$$\n\nindicating that the response ($y$) is distributed as a Gaussian\n(normal) the mean of which is determined by the linear relationship\nwith $x$ and there is a constant variance ($\\sigma^2$) - all\nobservations are independently and identically distributed (_iid_) -\nindependently drawn from a distribution with the same variance.\n\nThe $I$ signifies an identity matrix (a square matrix whose diagonals\nare all one).\n\nMore generally, the above can be written in vector/matrix form as:\n\n$$\n\\begin{align}\nY \\sim{}& N(\\boldsymbol{\\mu}, \\sigma^2I)\\\\\n\\boldsymbol{\\mu} =& \\boldsymbol{X}\\boldsymbol{\\beta}\\\\\n\\end{align}\n$$\n\nIf we suspect that the residuals are not independent and identically\ndistributed (if for example they were Poisson distributed), then we\ncould alter (generalise) the above to:\n\n$$\n\\begin{align}\nY \\sim{}& N(\\boldsymbol{\\mu}, \\sigma^2\\boldsymbol{W}^{-1})\\\\\n\\boldsymbol{\\mu} =& \\boldsymbol{X}\\boldsymbol{\\beta}\\\\\n\\end{align}\n$$\n\nwhere $\\boldsymbol{W}$ is a matrix of positive diagonals .\n\nThis allows us to generalise to other (exponential) families (such as\nBinomial, Poisson, Negative Binomial, Gamma etc). For example, if our\nresponse ($Y$) were count data, we might consider a Poisson.\n\n$$\n\\begin{align}\nY \\sim{}& Pois(\\boldsymbol{\\lambda})\\\\\n\\boldsymbol{\\lambda} =& e^{\\boldsymbol{X}\\boldsymbol{\\beta}}\\\\\n&\\text{OR equivalently}\\\\\nlog(\\boldsymbol{\\lambda}) =& \\boldsymbol{X}\\boldsymbol{\\beta}\\\\\n\\end{align}\n$$\n\nThe Poisson distribution ($P(x|\\lambda) = e^{-\\lambda}\\lambda^x/x!$)\nis parameterised by a single parameter ($\\lambda$) that represents\nboth the mean and variance (as well as degrees of freedom). Poisson\ndata are bound at the lower end by zero (negative values are not\ndefined) - it is not possible to count fewer than 0 things. The\nPoisson family includes an exponential term, therefore to map the\nexpected values back onto the natural scale (scale of the observed\ndata), we use a **link** function (in the case of the Poission, this\nlink is a log link). Hence the above can be generalized even further\nto:\n\n$$\n\\begin{align}\nY \\sim{}& D(\\boldsymbol{\\eta}, ...)\\\\\ng(\\boldsymbol{\\eta}) =& \\boldsymbol{X}\\boldsymbol{\\beta}\\\\\n\\end{align}\n$$\n\nwhere $D$ is the nominated family, $g$ is the link function and $...$\nrepresents any additional parameters required by the nominated\ndistribution (such as $\\sigma^2\\boldsymbol{W}^{-1}$ in the case of the\nGaussian distribution).\n\nIn regular OLS regression we are trying to minimize the sum squares of\nresiduals ($||Y - \\boldsymbol{X}\\boldsymbol{\\beta}||^2$). This assumes\nthat all residuals are independent and identically distributed as each\nwill be given equal weight when summing. However, we may wish to\nweight some observations (residuals) more heavily than others. For\nexample, a reasonably common situation is for the variance to be\nrelated to the mean (typically as the mean increases, so does the\nvariance). We can partly compensate for this be weighting the\nresiduals inversely proportional to the mean ($w_i = 1/\\mu_i$).\n\nNow, rather than trying to minimise the sum squares of residuals\n($||Y - \\boldsymbol{X}\\boldsymbol{\\beta}||^2$), we now try to minimise\nthe sum weighted residuals ($||Y - \\boldsymbol{X}\\boldsymbol{\\beta}||^{\\boldsymbol{p}}$), where\n$\\boldsymbol{p}$ is a vector of powers.\n\nThis can also (and once we take into consideration the link function),\nbe written as the sum square of weighted residuals\n($(g(\\boldsymbol{X}\\boldsymbol{\\beta}) -\nY)^T\\boldsymbol{W}(g(\\boldsymbol{X}\\boldsymbol{\\beta}) - Y)$), where\n$\\boldsymbol{W}$ is the diagonal of a weights matrix.\n\nRather than calculate the residuals on the response scale (by\nbacktransforming the linear predictor\n$\\boldsymbol{X}\\boldsymbol{\\beta}$ to the same scale as the response\n$Y$), the residuals are typically calculated on the link scale after\nadjusting the response variable onto this scale.\n\nThe response is adjusted ($\\boldsymbol{z}$) by adding the difference\nbetween observed and expected (natural scale) re-mapped onto the link\nscale (by dividing by the derivative of the expected value on the\nnatural scale) to the expected value (on the link scale).\n\n$$\n\\boldsymbol{z} = \\boldsymbol{\\eta} + \\frac{Y-g(\\boldsymbol{\\eta})}{g'(\\boldsymbol{\\eta})}\n$$\n\nwhere $\\eta$ is the estimated linear predictor (predicted value of $y$\non the scale of the link function), $g(\\eta)$ is the inverse link of\n$\\eta$ and $g'(\\eta)$ is the derivative of $g(\\eta)$.\n\nThe weighted least squares formulation then becomes:\n\n$$\n\\boldsymbol{\\beta} = (\\boldsymbol{X}^T\\boldsymbol{W}\\boldsymbol{X}^{-1})\\boldsymbol{X}^T\\boldsymbol{W}\\boldsymbol{z}\n$$\n\nwhere $\\boldsymbol{W}$ is the diagonal of a weights matrix:\n\n$$\n\\boldsymbol{W} = diag\\left(\\frac{g'(\\boldsymbol{\\eta})^2}{var(g(\\boldsymbol{\\eta}))}\\right)\n$$\n\nUnfortunately, there is no closed form solution for the above and thus\nit is usually solved iteratively, and is thus called **iterative\nre-weighted least squares**. A very simplistic implementation of an\niterative re-weighted least squares could be:\n\n1. Start with some initial values for the parameters ($\\beta$} -\n   typically 0 for each parameter (on the link scale and thus, 1 on\n   the response scale)\n2. Calculate the predicted value of the response given the current\n   estimates of $\\boldsymbol{\\beta}$ as well as the adjusted response\n   ($\\boldsymbol{z}$) and weights ($\\boldsymbol{W}$).\n3. Update the estimated parameter values\n4. Repeat steps 2-3 until either the maximum number of iterations has\n   occurred or a measure of the difference between successive\n   iterations is below a set tolerance.\n\n:::\n\n\n::: {.callout-note collapse=\"true\"}\n### Code used to implement a simple iterative re-weighted least\nsquares algorithm\n\n\n::: {.cell}\n\n```{.r .cell-code}\noptim.IRLS <- function(X, y, family, iter.max=25, abs.tol=1e-06) {\n    oldpar <- newpar <- rep(0, ncol(X))\n    iter <- 0; not.converged <- 1; not.max.iter <- 1\n    while (not.converged & not.max.iter) {\n        eta <- X %*% newpar         # calculate (update) the linear predictor\n        g <- family()$linkinv(eta)  # calculate (update) the linear predictor on the natural scale (inverse link)\n        g. <- family()$mu.eta(eta)  # calculate (update) the derivative of linear predictor on natural scale\n        z <- eta + (y - g) / g.     # calculate (update) the  adjusted response\n        W <- as.vector(g.^2 / family()$variance(g))  # calculate (update) the weights\n        oldpar <- newpar\n        newpar <- solve(crossprod(X,W*X), crossprod(X, W*z), tol = 2*.Machine$double.eps)\n        iter <- iter + 1\n        not.max.iter <- (iter < iter.max)*1\n        not.converged <- (max(abs((1-newpar/oldpar)))>abs.tol)*1\n    }\n    list(B.optim = newpar, Iter = iter-1)\n}\n```\n:::\n\n\n\n:::\n\n\n::: {.callout-note collapse=\"true\"}\n### Manual calculations\n\nNote, when the family is Gaussian, the above is simplified to the OLS form:\n\n$$\n\\begin{align}\n\\boldsymbol{\\beta} =& 0\\\\\n\\boldsymbol{\\eta} =& \\boldsymbol{X}\\boldsymbol{\\beta} = 0\\\\\n\\boldsymbol{z} =& \\boldsymbol{\\eta} +\n\\frac{Y-g(\\boldsymbol{\\eta})}{g'(\\boldsymbol{\\eta})} = 0 + \\frac{Y-0}{1} = Y\\\\\n\\boldsymbol{W} =&\ndiag\\left(\\frac{g'(\\boldsymbol{\\eta})^2}{var(g(\\boldsymbol{\\eta}))}\\right) =\ndiag(1^2/1) = 1\\\\\n\\boldsymbol{\\beta} =&\n(\\boldsymbol{X}^T\\boldsymbol{W}\\boldsymbol{X}^{-1})\\boldsymbol{X}^T\\boldsymbol{W}\\boldsymbol{z}\n= (\\boldsymbol{X}^T\\boldsymbol{X}^{-1})\\boldsymbol{X}^TY\n\\end{align}\n$$\n\n\nLets try it out, starting with an intercept only model - which is just\nestimating the mean response value (according to a Poisson\ndistribution).\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\noptim.IRLS(cbind(rep(1, length(dat$y))), dat$y, family = gaussian)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n$B.optim\n       [,1]\n[1,] 27.811\n\n$Iter\n[1] 1\n```\n\n\n:::\n:::\n\n\n\nThis estimate is (not surprisingly) identical to the OLS estimate.\n\nSo what if we modified the response such that it was some positive\nintegers and we nominate a Poisson distribution..\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\noptim.IRLS(cbind(rep(1,length(dat3$y))), dat3$y, family=poisson)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n$B.optim\n         [,1]\n[1,] 2.379546\n\n$Iter\n[1] 12\n```\n\n\n:::\n\n```{.r .cell-code}\nexp(optim.IRLS(cbind(rep(1,length(dat3$y))), dat3$y, family=poisson)$B.optim)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n     [,1]\n[1,] 10.8\n```\n\n\n:::\n:::\n\n\n\nAfter 12 iterations, the algorithm converged on an\nestimate of 2.3795461, which on the natural scale would be `r\nexp(optim.IRLS(cbind(rep(1,length(dat3$y))), dat3$y,\nfamily=poisson)$B.optim)`.\n\nIn R, there is an inbuilt function called `glm()` that fits\ngeneralized linear models by default via iterative re-weighted least\nsquares.\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nglm(y ~ 1, data=dat3, family = poisson(link = \"log\"))\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n\nCall:  glm(formula = y ~ 1, family = poisson(link = \"log\"), data = dat3)\n\nCoefficients:\n(Intercept)  \n       2.38  \n\nDegrees of Freedom: 9 Total (i.e. Null);  9 Residual\nNull Deviance:\t    89.83 \nResidual Deviance: 89.83 \tAIC: 129.3\n```\n\n\n:::\n:::\n\n\n\nAnd now we will explore the full model:\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nX = model.matrix(~x, dat3)\nirls = optim.IRLS(X, dat3$y, family = poisson)\nirls\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n$B.optim\n                 [,1]\n(Intercept) 0.0513556\nx           0.3426288\n\n$Iter\n[1] 24\n```\n\n\n:::\n\n```{.r .cell-code}\nexp(irls$B.optim)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n                [,1]\n(Intercept) 1.052697\nx           1.408646\n```\n\n\n:::\n:::\n\n\n\nBoth estimates are very close to the parameters on which the simulated\ndata were generated, and identical to those returned from the inbuilt\n`glm()` __function__.\n\n:::\n\n\n:::: {.panel-tabset}\n\n### Example 1 (Gaussian data)\n\n::::::: {.panel-tabset}\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nglm(y ~ x, data=dat3, family = poisson(link = \"log\"))\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n\nCall:  glm(formula = y ~ x, family = poisson(link = \"log\"), data = dat3)\n\nCoefficients:\n(Intercept)            x  \n    0.05136      0.34263  \n\nDegrees of Freedom: 9 Total (i.e. Null);  8 Residual\nNull Deviance:\t    89.83 \nResidual Deviance: 8.879 \tAIC: 50.35\n```\n\n\n:::\n:::\n\n\n\n#### Raw predictor\n::::: {.panel-tabset}\n\n##### Fit the model\n$$\n\\begin{align}\ny_i \\sim{}& N(\\mu_i, \\sigma^2)\\\\\n\\mu_i =& \\beta_0 + \\beta_1 x_i\\\\\n\\end{align}\n$$\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\ndat.glmw <- glm(y~x, data = dat)\ndat.glmw\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n\nCall:  glm(formula = y ~ x, data = dat)\n\nCoefficients:\n(Intercept)            x  \n      2.651        4.575  \n\nDegrees of Freedom: 9 Total (i.e. Null);  8 Residual\nNull Deviance:\t    2033 \nResidual Deviance: 306.7 \tAIC: 68.61\n```\n\n\n:::\n:::\n\n\n\nAnd to explore the diagnostics\n\n\n\n##### Performance model checking\n\n\n::: {.cell}\n\n```{.r .cell-code}\ndat.glmw |> performance::check_model()\n```\n\n::: {.cell-output-display}\n![](30_glm_files/figure-html/glm_validateModelaglmw1-1.png){width=768}\n:::\n\n```{.r .cell-code}\ndat.glmw |> performance::check_outliers()\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nOK: No outliers detected.\n- Based on the following method and threshold: cook (0.8).\n- For variable: (Whole model)\n```\n\n\n:::\n:::\n\n\n\n**Conclusions**:\n\n- these diagnostics are broadly acceptable given the small nature of the\n  data\n\n\n##### DHARMa (simulated) residuals\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\ndat.resid <- dat.glmw |> \n  simulateResiduals(plot = TRUE)\n```\n\n::: {.cell-output-display}\n![](30_glm_files/figure-html/glm_validateModelbglmw1-1.png){width=768}\n:::\n:::\n\n\n\n**Conclusions**\n\n- no obvious issues with these diagnostics\n\n##### Summarise model\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\ndat.glmw |> summary()\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n\nCall:\nglm(formula = y ~ x, data = dat)\n\nCoefficients:\n            Estimate Std. Error t value Pr(>|t|)    \n(Intercept)   2.6507     4.2299   0.627 0.548349    \nx             4.5746     0.6817   6.710 0.000151 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n(Dispersion parameter for gaussian family taken to be 38.34014)\n\n    Null deviance: 2033.20  on 9  degrees of freedom\nResidual deviance:  306.72  on 8  degrees of freedom\nAIC: 68.612\n\nNumber of Fisher Scoring iterations: 2\n```\n\n\n:::\n\n```{.r .cell-code}\ndat.glmw |> confint()\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n                2.5 %    97.5 %\n(Intercept) -5.639787 10.941121\nx            3.238478  5.910734\n```\n\n\n:::\n\n```{.r .cell-code}\ndat.glmw |> performance::r2()\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n  R2: 0.849\n```\n\n\n:::\n:::\n\n\n\n**Interpretation**:\n\n- when $x=0$ (e.g. the average $x$ value since centered), $y$ is\n  expected to be 2.651 (the\n  y-intercept).\n- for every one unit change in $x$, the expected value of $y$\n  increases by 4.575 (the slope)\n- the slope could be as low as 3.238 or as high as \n  5.911 (95% confidence interval of the slope)\n- as the above interval does not include the value of 0, the linear\n  relationship (slope) can be considered significant\n- we would reject the null hypothesis of no relationship (p-value for\n  slope is less than 0.05)\n- 84.914% of the variance in $y$ is\n  explained by its linear relationship with $x$ (R squared value)\n\n:::::\n\n#### Centered predictor\n::::: {.panel-tabset}\n\n##### Fit the model\n$$\n\\begin{align}\ny_i \\sim{}& N(\\mu_i, \\sigma^2)\\\\\n\\mu_i =& \\beta_0 + \\beta_1 (x_i - \\bar{x})\\\\\n\\end{align}\n$$\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\ndat1b.glmw <- glm(y ~ scale(x, scale = FALSE), data = dat)\ndat1b.glmw\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n\nCall:  glm(formula = y ~ scale(x, scale = FALSE), data = dat)\n\nCoefficients:\n            (Intercept)  scale(x, scale = FALSE)  \n                 27.811                    4.575  \n\nDegrees of Freedom: 9 Total (i.e. Null);  8 Residual\nNull Deviance:\t    2033 \nResidual Deviance: 306.7 \tAIC: 68.61\n```\n\n\n:::\n:::\n\n\n\nAnd to explore the diagnostics\n\n\n\n##### Performance model checking\n\n\n::: {.cell}\n\n```{.r .cell-code}\ndat1b.glmw |> performance::check_model()\n```\n\n::: {.cell-output-display}\n![](30_glm_files/figure-html/glm_validateModelaglmw1b-1.png){width=768}\n:::\n\n```{.r .cell-code}\ndat1b.glmw |> performance::check_outliers()\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nOK: No outliers detected.\n- Based on the following method and threshold: cook (0.8).\n- For variable: (Whole model)\n```\n\n\n:::\n:::\n\n\n\n**Conclusions**:\n\n- these diagnostics are broadly acceptable given the small nature of the\n  data\n\n\n##### DHARMa (simulated) residuals\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\ndat.resid <- dat1b.glmw |> \n  simulateResiduals(plot = TRUE)\n```\n\n::: {.cell-output-display}\n![](30_glm_files/figure-html/glm_validateModelbglmw1b-1.png){width=768}\n:::\n:::\n\n\n\n**Conclusions**\n\n- no obvious issues with these diagnostics\n\n##### Summarise model\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\ndat1b.glmw |> summary()\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n\nCall:\nglm(formula = y ~ scale(x, scale = FALSE), data = dat)\n\nCoefficients:\n                        Estimate Std. Error t value Pr(>|t|)    \n(Intercept)              27.8110     1.9581   14.20 5.88e-07 ***\nscale(x, scale = FALSE)   4.5746     0.6817    6.71 0.000151 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n(Dispersion parameter for gaussian family taken to be 38.34014)\n\n    Null deviance: 2033.20  on 9  degrees of freedom\nResidual deviance:  306.72  on 8  degrees of freedom\nAIC: 68.612\n\nNumber of Fisher Scoring iterations: 2\n```\n\n\n:::\n\n```{.r .cell-code}\ndat1b.glmw |> confint()\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n                            2.5 %    97.5 %\n(Intercept)             23.973266 31.648734\nscale(x, scale = FALSE)  3.238478  5.910734\n```\n\n\n:::\n\n```{.r .cell-code}\ndat1b.glmw |> performance::r2()\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n`r2()` does not support models of class `glm`.\n```\n\n\n:::\n\n::: {.cell-output .cell-output-stdout}\n\n```\nNULL\n```\n\n\n:::\n:::\n\n\n\n**Interpretation**:\n\n- when $x=0$ (e.g. the average $x$ value since centered), $y$ is\n  expected to be 27.811 (the\n  y-intercept).\n- for every one unit change in $x$ (which represents a span of approximately 34% of the range of $x$), the expected value of $y$\n  increases by 4.575 (the slope)\n- the slope could be as low as 3.238 or as high as \n  5.911 (95% confidence interval of the slope)\n- as the above interval does not include the value of 0, the linear\n  relationship (slope) can be considered significant\n- we would reject the null hypothesis of no relationship (p-value for\n  slope is less than 0.05)\n- % of the variance in $y$ is\n  explained by its linear relationship with $x$ (R squared value)\n\n:::::\n\n#### Standardised predictor\n\n::::: {.panel-tabset}\n\n##### Fit the model\n\n$$\n\\begin{align}\ny_i \\sim{}& N(\\mu_i, \\sigma^2)\\\\\n\\mu_i =& \\beta_0 + \\beta_1 (x_i - \\bar{x})/\\sigma_{x}\\\\\n\\end{align}\n$$\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\ndat1c.glmw <- glm(y ~ scale(x), data = dat)\ndat1c.glmw\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n\nCall:  glm(formula = y ~ scale(x), data = dat)\n\nCoefficients:\n(Intercept)     scale(x)  \n      27.81        13.85  \n\nDegrees of Freedom: 9 Total (i.e. Null);  8 Residual\nNull Deviance:\t    2033 \nResidual Deviance: 306.7 \tAIC: 68.61\n```\n\n\n:::\n:::\n\n\n\nAnd to explore the diagnostics\n\n\n##### Performance model checking\n\n\n::: {.cell}\n\n```{.r .cell-code}\ndat1c.glmw |> performance::check_model()\n```\n\n::: {.cell-output-display}\n![](30_glm_files/figure-html/glm_validateModelaglmw1c-1.png){width=768}\n:::\n\n```{.r .cell-code}\ndat1c.glmw |> performance::check_outliers()\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nOK: No outliers detected.\n- Based on the following method and threshold: cook (0.8).\n- For variable: (Whole model)\n```\n\n\n:::\n:::\n\n\n\n**Conclusions**:\n\n- these diagnostics are broadly acceptable given the small nature of the\n  data\n\n\n##### DHARMa (simulated) residuals\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\ndat.resid <- dat1c.glmw |> \n  simulateResiduals(plot = TRUE)\n```\n\n::: {.cell-output-display}\n![](30_glm_files/figure-html/glm_validateModelbglmw1c-1.png){width=768}\n:::\n:::\n\n\n\n**Conclusions**\n\n- no obvious issues with these diagnostics\n\n##### Summarise model\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\ndat1c.glmw |> summary()\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n\nCall:\nglm(formula = y ~ scale(x), data = dat)\n\nCoefficients:\n            Estimate Std. Error t value Pr(>|t|)    \n(Intercept)   27.811      1.958   14.20 5.88e-07 ***\nscale(x)      13.850      2.064    6.71 0.000151 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n(Dispersion parameter for gaussian family taken to be 38.34014)\n\n    Null deviance: 2033.20  on 9  degrees of freedom\nResidual deviance:  306.72  on 8  degrees of freedom\nAIC: 68.612\n\nNumber of Fisher Scoring iterations: 2\n```\n\n\n:::\n\n```{.r .cell-code}\ndat1c.glmw |> confint()\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n               2.5 %   97.5 %\n(Intercept) 23.97327 31.64873\nscale(x)     9.80498 17.89563\n```\n\n\n:::\n\n```{.r .cell-code}\ndat1c.glmw |> performance::r2()\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n`r2()` does not support models of class `glm`.\n```\n\n\n:::\n\n::: {.cell-output .cell-output-stdout}\n\n```\nNULL\n```\n\n\n:::\n:::\n\n\n\n**Interpretation**:\n\n- when $x=0$ (e.g. the average $x$ value since centered), $y$ is\n  expected to be 27.811 (the\n  y-intercept).\n- for every one unit change in $x$ (which represents a span of\n  approximately 34% of the range of $x$ since standardised), the\n  expected value of $y$ increases by `r\n  round(fixef(dat1c.glmw)[2], 3)` (the slope)\n- the slope could be as low as 9.805 or as high as \n  17.896 (95% confidence interval of the slope)\n- as the above interval does not include the value of 0, the linear\n  relationship (slope) can be considered significant\n- we would reject the null hypothesis of no relationship (p-value for\n  slope is less than 0.05)\n- % of the variance in $y$ is\n  explained by its linear relationship with $x$ (R squared value)\n\n:::::\n:::::::\n\n### Example 3 (Poisson data)\n\n::::::: {.panel-tabset}\n#### Raw predictor\n::::: {.panel-tabset}\n##### Fit the model\nGiven that exploratory data analysis suggested that the assumptions\nwere not likely to be met for a simple gaussian model and that this\nwas subsequently confirmed when we explored the diagnostics resulting\nfrom the OLS model of these data, we will instead entertain a poisson\nregression model. The model will be of the form:\n\n$$\n\\begin{align}\ny_i \\sim{}& Pois(\\lambda_i)\\\\\nlog(\\lambda_i) =& \\beta_0 + \\beta_1 x_i\\\\\n\\end{align}\n$$\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\ndat3.glmw <- glm(y~x, data = dat3, family = poisson(link = \"log\"))\ndat3.glmw\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n\nCall:  glm(formula = y ~ x, family = poisson(link = \"log\"), data = dat3)\n\nCoefficients:\n(Intercept)            x  \n    0.05136      0.34263  \n\nDegrees of Freedom: 9 Total (i.e. Null);  8 Residual\nNull Deviance:\t    89.83 \nResidual Deviance: 8.879 \tAIC: 50.35\n```\n\n\n:::\n:::\n\n\n\nAnd to explore the diagnostics\n\n\n\n##### Performance model checking\n\n\n::: {.cell}\n\n```{.r .cell-code}\ndat3.glmw |> performance::check_model()\n```\n\n::: {.cell-output-display}\n![](30_glm_files/figure-html/glmw_validateModel3a1-1.png){width=768}\n:::\n\n```{.r .cell-code}\ndat3.glmw |> performance::check_outliers()\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nOK: No outliers detected.\n- Based on the following method and threshold: cook (0.8).\n- For variable: (Whole model)\n```\n\n\n:::\n:::\n\n\n\n**Conclusions**:\n\n- these diagnostics are broadly acceptable given the small nature of the\n  data\n\n\n##### DHARMa (simulated) residuals\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\ndat.resid <- dat3.glmw |> \n  simulateResiduals(plot = TRUE)\n```\n\n::: {.cell-output-display}\n![](30_glm_files/figure-html/glmw_validateModel3b1-1.png){width=768}\n:::\n:::\n\n\n\n**Conclusions**\n\n- no obvious issues with these diagnostics\n\n##### Summarise model\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\ndat3.glmw |> summary()\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n\nCall:\nglm(formula = y ~ x, family = poisson(link = \"log\"), data = dat3)\n\nCoefficients:\n            Estimate Std. Error z value Pr(>|z|)    \n(Intercept)  0.05136    0.35408   0.145    0.885    \nx            0.34263    0.04319   7.932 2.15e-15 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n(Dispersion parameter for poisson family taken to be 1)\n\n    Null deviance: 89.8290  on 9  degrees of freedom\nResidual deviance:  8.8787  on 8  degrees of freedom\nAIC: 50.355\n\nNumber of Fisher Scoring iterations: 4\n```\n\n\n:::\n\n```{.r .cell-code}\ndat3.glmw |> confint()\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n                 2.5 %    97.5 %\n(Intercept) -0.6834618 0.7077688\nx            0.2608235 0.4305322\n```\n\n\n:::\n\n```{.r .cell-code}\ndat3.glmw |> performance::r2()\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n# R2 for Generalized Linear Regression\n  Nagelkerke's R2: 1.000\n```\n\n\n:::\n:::\n\n\n:::::::: {.callout-tip}\n\nSince this model used a log link, in order to return the estimates to\nthe scale of the response, we need to backtransform by exponentiation.\n\nImportantly, if using confidence intervals for the purpose of\ninference testsing:\n\n- if using estimates on the link (log) scale, intervals that do not include 0\n  are \"significant\"\n- if using estimates on the response scale, intervals that do not\n  include 1 are \"significant\"\n  \n::::::::\n\n**Interpretation**:\n\n- when $x=0$, $y$ is expected to be exp(0.051) = \n  1.053 (the y-intercept).\n- for every one unit change in $x$, the expected value of $y$\n  increases by exp(0.343) =  \n  1.409 (the slope)\n- this is equivalent to a 40.865% \n  increase in the response per one unit change in $x$\n- the slope (on the link scale) could be as low as \n  0.261 or\n  as high as 0.431 (95% confidence\n  interval of the slope)\n- as the above interval does not include the value of 0, the linear\n  relationship (slope) can be considered significant\n- the slope (on the response scale) could be as low as \n  1.298 or\n  as high as 1.538 (95% confidence\n  interval of the slope)\n- as the above interval does not include the value of 1, the linear\n  relationship (slope) can be considered significant\n- we would reject the null hypothesis of no relationship (p-value for\n  slope is less than 0.05)\n- 99.982% of the variance in $y$ is\n  explained by its linear relationship with $x$ (R squared value)\n\n:::::\n\n#### Centered predictor\n\n::::: {.panel-tabset}\n\n##### Fit the model\n\nGiven that exploratory data analysis suggested that the assumptions\nwere not likely to be met for a simple gaussian model and that this\nwas subsequently confirmed when we explored the diagnostics resulting\nfrom the OLS model of these data, we will instead entertain a poisson\nregression model. The model will be of the form:\n\n$$\n\\begin{align}\ny_i \\sim{}& Pois(\\lambda_i)\\\\\nlog(\\lambda_i) =& \\beta_0 + \\beta_1 (x_i - \\bar{x})\\\\\n\\end{align}\n$$\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\ndat3b.glmw <- glm(y ~ scale(x, scale = FALSE), data = dat3, family = poisson(link = \"log\"))\ndat3b.glmw\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n\nCall:  glm(formula = y ~ scale(x, scale = FALSE), family = poisson(link = \"log\"), \n    data = dat3)\n\nCoefficients:\n            (Intercept)  scale(x, scale = FALSE)  \n                 1.9358                   0.3426  \n\nDegrees of Freedom: 9 Total (i.e. Null);  8 Residual\nNull Deviance:\t    89.83 \nResidual Deviance: 8.879 \tAIC: 50.35\n```\n\n\n:::\n:::\n\n\n\nAnd to explore the diagnostics\n\n\n\n##### Performance model checking\n\n\n::: {.cell}\n\n```{.r .cell-code}\ndat3b.glmw |> performance::check_model()\n```\n\n::: {.cell-output-display}\n![](30_glm_files/figure-html/glmw_validateMode3a1b-1.png){width=768}\n:::\n\n```{.r .cell-code}\ndat3b.glmw |> performance::check_outliers()\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nOK: No outliers detected.\n- Based on the following method and threshold: cook (0.8).\n- For variable: (Whole model)\n```\n\n\n:::\n:::\n\n\n\n**Conclusions**:\n\n- these diagnostics are broadly acceptable given the small nature of the\n  data\n\n\n##### DHARMa (simulated) residuals\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\ndat.resid <- dat3b.glmw |> \n  simulateResiduals(plot = TRUE)\n```\n\n::: {.cell-output-display}\n![](30_glm_files/figure-html/glmw_validateModel3b1b-1.png){width=768}\n:::\n:::\n\n\n\n**Conclusions**\n\n- no obvious issues with these diagnostics\n\n##### Summarise model\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\ndat3b.glmw |> summary()\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n\nCall:\nglm(formula = y ~ scale(x, scale = FALSE), family = poisson(link = \"log\"), \n    data = dat3)\n\nCoefficients:\n                        Estimate Std. Error z value Pr(>|z|)    \n(Intercept)              1.93581    0.14109  13.720  < 2e-16 ***\nscale(x, scale = FALSE)  0.34263    0.04319   7.932 2.15e-15 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n(Dispersion parameter for poisson family taken to be 1)\n\n    Null deviance: 89.8290  on 9  degrees of freedom\nResidual deviance:  8.8787  on 8  degrees of freedom\nAIC: 50.355\n\nNumber of Fisher Scoring iterations: 4\n```\n\n\n:::\n\n```{.r .cell-code}\ndat3b.glmw |> confint()\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n                            2.5 %    97.5 %\n(Intercept)             1.6421890 2.1970557\nscale(x, scale = FALSE) 0.2608235 0.4305322\n```\n\n\n:::\n\n```{.r .cell-code}\ndat3b.glmw |> performance::r2()\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n# R2 for Generalized Linear Regression\n  Nagelkerke's R2: 1.000\n```\n\n\n:::\n:::\n\n\n\n:::::::: {.callout-tip}\n\nSince this model used a log link, in order to return the estimates to\nthe scale of the response, we need to backtransform by exponentiation.\n\nImportantly, if using confidence intervals for the purpose of\ninference testsing:\n\n- if using estimates on the link (log) scale, intervals that do not include 0\n  are \"significant\"\n- if using estimates on the response scale, intervals that do not\n  include 1 are \"significant\"\n  \n::::::::\n\n**Interpretation**:\n\n- when $x=0$ (e.g. the average $x$ value since centered), $y$ is\n  expected to be exp(1.936) = \n  6.93 (the y-intercept).\n- for every one unit change in $x$, the expected value of $y$\n  increases by exp(0.343) =  \n  1.409 (the slope)\n- this is equivalent to a 40.865% \n  increase in the response per one unit change in $x$\n- the slope (on the link scale) could be as low as \n  0.261 or\n  as high as 0.431 (95% confidence\n  interval of the slope)\n- as the above interval does not include the value of 0, the linear\n  relationship (slope) can be considered significant\n- the slope (on the response scale) could be as low as \n  1.298 or\n  as high as 1.538 (95% confidence\n  interval of the slope)\n- as the above interval does not include the value of 1, the linear\n  relationship (slope) can be considered significant\n- we would reject the null hypothesis of no relationship (p-value for\n  slope is less than 0.05)\n- 99.982% of the variance in $y$ is\n  explained by its linear relationship with $x$ (R squared value)\n\n:::::\n\n#### Standardised predictor\n\n::::: {.panel-tabset}\n\n##### Fit the model\n\nGiven that exploratory data analysis suggested that the assumptions\nwere not likely to be met for a simple gaussian model and that this\nwas subsequently confirmed when we explored the diagnostics resulting\nfrom the OLS model of these data, we will instead entertain a poisson\nregression model. The model will be of the form:\n\n$$\n\\begin{align}\ny_i \\sim{}& Pois(\\lambda_i)\\\\\nlog(\\lambda_i) =& \\beta_0 + \\beta_1 (x_i - \\bar{x})/\\sigma_{x}\\\\\n\\end{align}\n$$\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\ndat3c.glmw <- glm(y ~ scale(x), data = dat3, family = poisson(link = \"log\"))\ndat3c.glmw\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n\nCall:  glm(formula = y ~ scale(x), family = poisson(link = \"log\"), data = dat3)\n\nCoefficients:\n(Intercept)     scale(x)  \n      1.936        1.037  \n\nDegrees of Freedom: 9 Total (i.e. Null);  8 Residual\nNull Deviance:\t    89.83 \nResidual Deviance: 8.879 \tAIC: 50.35\n```\n\n\n:::\n:::\n\n\n\nAnd to explore the diagnostics\n\n##### Performance model checking\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\ndat3c.glmw |> performance::check_model()\n```\n\n::: {.cell-output-display}\n![](30_glm_files/figure-html/glmw_validateMode3a1c-1.png){width=768}\n:::\n\n```{.r .cell-code}\ndat3c.glmw |> performance::check_outliers()\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nOK: No outliers detected.\n- Based on the following method and threshold: cook (0.8).\n- For variable: (Whole model)\n```\n\n\n:::\n:::\n\n\n\n**Conclusions**:\n\n- these diagnostics are broadly acceptable given the small nature of the\n  data\n\n\n##### DHARMa (simulated) residuals\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\ndat.resid <- dat3c.glmw |> \n  simulateResiduals(plot = TRUE)\n```\n\n::: {.cell-output-display}\n![](30_glm_files/figure-html/glmw_validateModel3b1c-1.png){width=768}\n:::\n:::\n\n\n\n**Conclusions**\n\n- no obvious issues with these diagnostics\n\n##### Summarise model\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\ndat3c.glmw |> summary()\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n\nCall:\nglm(formula = y ~ scale(x), family = poisson(link = \"log\"), data = dat3)\n\nCoefficients:\n            Estimate Std. Error z value Pr(>|z|)    \n(Intercept)   1.9358     0.1411  13.720  < 2e-16 ***\nscale(x)      1.0374     0.1308   7.932 2.15e-15 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n(Dispersion parameter for poisson family taken to be 1)\n\n    Null deviance: 89.8290  on 9  degrees of freedom\nResidual deviance:  8.8787  on 8  degrees of freedom\nAIC: 50.355\n\nNumber of Fisher Scoring iterations: 4\n```\n\n\n:::\n\n```{.r .cell-code}\ndat3c.glmw |> confint()\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n                2.5 %   97.5 %\n(Intercept) 1.6421890 2.197056\nscale(x)    0.7896823 1.303501\n```\n\n\n:::\n\n```{.r .cell-code}\ndat3c.glmw |> performance::r2()\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n# R2 for Generalized Linear Regression\n  Nagelkerke's R2: 1.000\n```\n\n\n:::\n:::\n\n\n\n:::::::: {.callout-tip}\n\nSince this model used a log link, in order to return the estimates to\nthe scale of the response, we need to backtransform by exponentiation.\n\nImportantly, if using confidence intervals for the purpose of\ninference testsing:\n\n- if using estimates on the link (log) scale, intervals that do not include 0\n  are \"significant\"\n- if using estimates on the response scale, intervals that do not\n  include 1 are \"significant\"\n  \n::::::::\n\n**Interpretation**:\n\n- when $x=0$ (e.g. the average $x$ value since centered), $y$ is\n  expected to be exp(1.936) = \n  6.93 (the y-intercept).\n- for every one unit change in $x$ (which represents a span of approximately 34% of the \n  range of $x$ since standardised), the expected value of $y$\n  increases by exp(1.037) =\n  2.822 (the slope)\n- this is equivalent to a 182.176% \n  increase in the response per one unit change in (standardised) $x$\n- the slope (on the link scale) could be as low as \n  0.79 or\n  as high as 1.304 (95% confidence\n  interval of the slope)\n- as the above interval does not include the value of 0, the linear\n  relationship (slope) can be considered significant\n- the slope (on the response scale) could be as low as \n  2.203 or\n  as high as 3.682 (95% confidence\n  interval of the slope)\n- as the above interval does not include the value of 1, the linear\n  relationship (slope) can be considered significant\n- we would reject the null hypothesis of no relationship (p-value for\n  slope is less than 0.05)\n- 99.982% of the variance in $y$ is\n  explained by its linear relationship with $x$ (R squared value)\n\n:::::\n\n:::::::\n\n\n### Example 4 (NB data)\n\n::::::: {.panel-tabset}\n\n#### Raw predictor\n\n::::: {.panel-tabset}\n\n##### Fit the model\n\nGiven that exploratory data analysis suggested that the assumptions\nwere not likely to be met for a simple gaussian model and that this\nwas subsequently confirmed when we explored the diagnostics resulting\nfrom the OLS model of these data, we will instead entertain a Negative\nBinomial regression model. The model will be of the form:\n\n$$\n\\begin{align}\ny_i \\sim{}& NB(\\lambda_i, \\phi)\\\\\nlog(\\lambda_i) =& \\beta_0 + \\beta_1 x_i\\\\\n\\end{align}\n$$\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\ndat4.glmw <- MASS::glm.nb(y~x, data = dat4)\n```\n\n::: {.cell-output .cell-output-stderr}\n\n```\nWarning in theta.ml(Y, mu, sum(w), w, limit = control$maxit, trace =\ncontrol$trace > : iteration limit reached\nWarning in theta.ml(Y, mu, sum(w), w, limit = control$maxit, trace =\ncontrol$trace > : iteration limit reached\n```\n\n\n:::\n\n```{.r .cell-code}\ndat4.glmw\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n\nCall:  MASS::glm.nb(formula = y ~ x, data = dat4, init.theta = 107501.5977, \n    link = log)\n\nCoefficients:\n(Intercept)            x  \n     0.3913       0.2792  \n\nDegrees of Freedom: 9 Total (i.e. Null);  8 Residual\nNull Deviance:\t    59.77 \nResidual Deviance: 9.712 \tAIC: 51.39\n```\n\n\n:::\n:::\n\n\n\nAnd to explore the diagnostics\n\n\n\n##### Performance model checking\n\n\n::: {.cell}\n\n```{.r .cell-code}\ndat4.glmw |> performance::check_model()\n```\n\n::: {.cell-output-display}\n![](30_glm_files/figure-html/glmw_validateMode4a1-1.png){width=768}\n:::\n\n```{.r .cell-code}\ndat4.glmw |> performance::check_outliers()\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nOK: No outliers detected.\n- Based on the following method and threshold: cook (0.8).\n- For variable: (Whole model)\n```\n\n\n:::\n:::\n\n\n\n**Conclusions**:\n\n- these diagnostics are broadly acceptable given the small nature of the\n  data\n\n\n##### DHARMa (simulated) residuals\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\ndat.resid <- dat4.glmw |> \n  simulateResiduals(plot = TRUE)\n```\n\n::: {.cell-output-display}\n![](30_glm_files/figure-html/glmw_validateModel4b1-1.png){width=768}\n:::\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\ndat.resid |> testDispersion()\n```\n\n::: {.cell-output-display}\n![](30_glm_files/figure-html/glmw_validateModel4b2-1.png){width=384}\n:::\n\n::: {.cell-output .cell-output-stdout}\n\n```\n\n\tDHARMa nonparametric dispersion test via sd of residuals fitted vs.\n\tsimulated\n\ndata:  simulationOutput\ndispersion = 0.5987, p-value = 0.56\nalternative hypothesis: two.sided\n```\n\n\n:::\n:::\n\n\n**Conclusions**\n\n- no obvious issues with these diagnostics\n\n##### Summarise model\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\ndat4.glmw |> summary()\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n\nCall:\nMASS::glm.nb(formula = y ~ x, data = dat4, init.theta = 107501.5977, \n    link = log)\n\nCoefficients:\n            Estimate Std. Error z value Pr(>|z|)    \n(Intercept)   0.3913     0.3415   1.146    0.252    \nx             0.2792     0.0431   6.479 9.26e-11 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n(Dispersion parameter for Negative Binomial(107501.6) family taken to be 1)\n\n    Null deviance: 59.7734  on 9  degrees of freedom\nResidual deviance:  9.7121  on 8  degrees of freedom\nAIC: 51.395\n\nNumber of Fisher Scoring iterations: 1\n\n              Theta:  107502 \n          Std. Err.:  2840765 \nWarning while fitting theta: iteration limit reached \n\n 2 x log-likelihood:  -45.395 \n```\n\n\n:::\n\n```{.r .cell-code}\ndat4.glmw |> confint()\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n                 2.5 %   97.5 %\n(Intercept) -0.3177550 1.024170\nx            0.1972806 0.366662\n```\n\n\n:::\n\n```{.r .cell-code}\ndat4.glmw |> performance::r2()\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n# R2 for Generalized Linear Regression\n  Nagelkerke's R2: 0.996\n```\n\n\n:::\n:::\n\n\n\n:::::::: {.callout-tip}\n\nSince this model used a log link, in order to return the estimates to\nthe scale of the response, we need to backtransform by exponentiation.\n\nImportantly, if using confidence intervals for the purpose of\ninference testsing:\n\n- if using estimates on the link (log) scale, intervals that do not include 0\n  are \"significant\"\n- if using estimates on the response scale, intervals that do not\n  include 1 are \"significant\"\n  \n::::::::\n\n**Interpretation**:\n\n- when $x=0$, $y$ is expected to be exp(0.391) = \n  1.479 (the y-intercept).\n- for every one unit change in $x$, the expected value of $y$\n  increases by exp(0.279) = \n  1.322 (the slope)\n- this is equivalent to a 32.213% \n  increase in the response per one unit change in $x$\n- the slope (on the link scale) could be as low as \n  0.197 or\n  as high as 0.367 (95% confidence\n  interval of the slope)\n- as the above interval does not include the value of 0, the linear\n  relationship (slope) can be considered significant\n- the slope (on the response scale) could be as low as \n  1.218 or\n  as high as 1.443 (95% confidence\n  interval of the slope)\n- as the above interval does not include the value of 1, the linear\n  relationship (slope) can be considered significant\n- we would reject the null hypothesis of no relationship (p-value for\n  slope is less than 0.05)\n- 99.583% of the variance in $y$ is\n  explained by its linear relationship with $x$ (R squared value)\n\n:::::\n\n#### Centered predictor\n\n::::: {.panel-tabset}\n\n##### Fit the model\n\nGiven that exploratory data analysis suggested that the assumptions\nwere not likely to be met for a simple gaussian model and that this\nwas subsequently confirmed when we explored the diagnostics resulting\nfrom the OLS model of these data, we will instead entertain a poisson\nregression model. The model will be of the form:\n\n$$\n\\begin{align}\ny_i \\sim{}& NB(\\lambda_i, \\phi)\\\\\nlog(\\lambda_i) =& \\beta_0 + \\beta_1 (x_i - \\bar{x})\\\\\n\\end{align}\n$$\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\ndat4b.glmw <- MASS::glm.nb(y ~ scale(x, scale = FALSE), data = dat4)\n```\n\n::: {.cell-output .cell-output-stderr}\n\n```\nWarning in theta.ml(Y, mu, sum(w), w, limit = control$maxit, trace =\ncontrol$trace > : iteration limit reached\nWarning in theta.ml(Y, mu, sum(w), w, limit = control$maxit, trace =\ncontrol$trace > : iteration limit reached\n```\n\n\n:::\n\n```{.r .cell-code}\ndat4b.glmw\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n\nCall:  MASS::glm.nb(formula = y ~ scale(x, scale = FALSE), data = dat4, \n    init.theta = 107501.5853, link = log)\n\nCoefficients:\n            (Intercept)  scale(x, scale = FALSE)  \n                 1.9272                   0.2792  \n\nDegrees of Freedom: 9 Total (i.e. Null);  8 Residual\nNull Deviance:\t    59.77 \nResidual Deviance: 9.712 \tAIC: 51.39\n```\n\n\n:::\n:::\n\n\n\nAnd to explore the diagnostics\n\n\n\n##### Performance model checking\n\n\n::: {.cell}\n\n```{.r .cell-code}\ndat4b.glmw |> performance::check_model()\n```\n\n::: {.cell-output-display}\n![](30_glm_files/figure-html/glmw_validateMode4a1b-1.png){width=768}\n:::\n\n```{.r .cell-code}\ndat4b.glmw |> performance::check_outliers()\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nOK: No outliers detected.\n- Based on the following method and threshold: cook (0.8).\n- For variable: (Whole model)\n```\n\n\n:::\n:::\n\n\n\n**Conclusions**:\n\n- these diagnostics are broadly acceptable given the small nature of the\n  data\n\n\n##### DHARMa (simulated) residuals\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\ndat.resid <- dat4b.glmw |> \n  simulateResiduals(plot = TRUE)\n```\n\n::: {.cell-output-display}\n![](30_glm_files/figure-html/glmw_validateModel4b1b-1.png){width=768}\n:::\n:::\n\n\n\n**Conclusions**\n\n- no obvious issues with these diagnostics\n\n##### Summarise model\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\ndat4b.glmw |> summary()\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n\nCall:\nMASS::glm.nb(formula = y ~ scale(x, scale = FALSE), data = dat4, \n    init.theta = 107501.5853, link = log)\n\nCoefficients:\n                        Estimate Std. Error z value Pr(>|z|)    \n(Intercept)               1.9272     0.1362  14.150  < 2e-16 ***\nscale(x, scale = FALSE)   0.2792     0.0431   6.479 9.26e-11 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n(Dispersion parameter for Negative Binomial(107501.6) family taken to be 1)\n\n    Null deviance: 59.7734  on 9  degrees of freedom\nResidual deviance:  9.7121  on 8  degrees of freedom\nAIC: 51.395\n\nNumber of Fisher Scoring iterations: 1\n\n              Theta:  107502 \n          Std. Err.:  2840767 \nWarning while fitting theta: iteration limit reached \n\n 2 x log-likelihood:  -45.395 \n```\n\n\n:::\n\n```{.r .cell-code}\ndat4b.glmw |> confint()\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n                            2.5 %   97.5 %\n(Intercept)             1.6442791 2.179941\nscale(x, scale = FALSE) 0.1972806 0.366662\n```\n\n\n:::\n\n```{.r .cell-code}\ndat4b.glmw |> performance::r2()\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n# R2 for Generalized Linear Regression\n  Nagelkerke's R2: 0.996\n```\n\n\n:::\n:::\n\n\n\n:::::::: {.callout-tip}\n\nSince this model used a log link, in order to return the estimates to\nthe scale of the response, we need to backtransform by exponentiation.\n\nImportantly, if using confidence intervals for the purpose of\ninference testsing:\n\n- if using estimates on the link (log) scale, intervals that do not include 0\n  are \"significant\"\n- if using estimates on the response scale, intervals that do not\n  include 1 are \"significant\"\n  \n::::::::\n\n**Interpretation**:\n\n- when $x=0$ (e.g. the average $x$ value since centered), $y$ is\n  expected to be exp(1.927) = \n  6.87 (the y-intercept).\n- for every one unit change in $x$, the expected value of $y$\n  increases by exp(0.279) = \n  1.322 (the slope)\n- this is equivalent to a 32.213% \n  increase in the response per one unit change in $x$\n- the slope (on the link scale) could be as low as \n  0.197 or\n  as high as 0.367 (95% confidence\n  interval of the slope)\n- as the above interval does not include the value of 0, the linear\n  relationship (slope) can be considered significant\n- the slope (on the response scale) could be as low as \n  1.218 or\n  as high as 1.443 (95% confidence\n  interval of the slope)\n- as the above interval does not include the value of 1, the linear\n  relationship (slope) can be considered significant\n- we would reject the null hypothesis of no relationship (p-value for\n  slope is less than 0.05)\n- 99.583% of the variance in $y$ is\n  explained by its linear relationship with $x$ (R squared value)\n\n:::::\n\n#### Standardised predictor\n\n::::: {.panel-tabset}\n\n##### Fit the model\n\nGiven that exploratory data analysis suggested that the assumptions\nwere not likely to be met for a simple gaussian model and that this\nwas subsequently confirmed when we explored the diagnostics resulting\nfrom the OLS model of these data, we will instead entertain a poisson\nregression model. The model will be of the form:\n\n$$\n\\begin{align}\ny_i \\sim{}& NB(\\lambda_i, \\phi)\\\\\nlog(\\lambda_i) =& \\beta_0 + \\beta_1 (x_i - \\bar{x})/\\sigma_{x}\\\\\n\\end{align}\n$$\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\ndat4c.glmw <- MASS::glm.nb(y ~ scale(x), data = dat4)\n```\n\n::: {.cell-output .cell-output-stderr}\n\n```\nWarning in theta.ml(Y, mu, sum(w), w, limit = control$maxit, trace =\ncontrol$trace > : iteration limit reached\nWarning in theta.ml(Y, mu, sum(w), w, limit = control$maxit, trace =\ncontrol$trace > : iteration limit reached\n```\n\n\n:::\n\n```{.r .cell-code}\ndat4c.glmw\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n\nCall:  MASS::glm.nb(formula = y ~ scale(x), data = dat4, init.theta = 107501.6077, \n    link = log)\n\nCoefficients:\n(Intercept)     scale(x)  \n     1.9272       0.8455  \n\nDegrees of Freedom: 9 Total (i.e. Null);  8 Residual\nNull Deviance:\t    59.77 \nResidual Deviance: 9.712 \tAIC: 51.39\n```\n\n\n:::\n:::\n\n\n\nAnd to explore the diagnostics\n\n##### Performance model checking\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\ndat4c.glmw |> performance::check_model()\n```\n\n::: {.cell-output-display}\n![](30_glm_files/figure-html/glmw_validateMode4a1c-1.png){width=768}\n:::\n\n```{.r .cell-code}\ndat4c.glmw |> performance::check_outliers()\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nOK: No outliers detected.\n- Based on the following method and threshold: cook (0.8).\n- For variable: (Whole model)\n```\n\n\n:::\n:::\n\n\n\n**Conclusions**:\n\n- these diagnostics are broadly acceptable given the small nature of the\n  data\n\n\n##### DHARMa (simulated) residuals\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\ndat.resid <- dat4c.glmw |> \n  simulateResiduals(plot = TRUE)\n```\n\n::: {.cell-output-display}\n![](30_glm_files/figure-html/glmw_validateModel4b1c-1.png){width=768}\n:::\n:::\n\n\n\n**Conclusions**\n\n- no obvious issues with these diagnostics\n\n##### Summarise model\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\ndat4c.glmw |> summary()\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n\nCall:\nMASS::glm.nb(formula = y ~ scale(x), data = dat4, init.theta = 107501.6077, \n    link = log)\n\nCoefficients:\n            Estimate Std. Error z value Pr(>|z|)    \n(Intercept)   1.9272     0.1362  14.150  < 2e-16 ***\nscale(x)      0.8455     0.1305   6.479 9.26e-11 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n(Dispersion parameter for Negative Binomial(107501.6) family taken to be 1)\n\n    Null deviance: 59.7734  on 9  degrees of freedom\nResidual deviance:  9.7121  on 8  degrees of freedom\nAIC: 51.395\n\nNumber of Fisher Scoring iterations: 1\n\n              Theta:  107502 \n          Std. Err.:  2840768 \nWarning while fitting theta: iteration limit reached \n\n 2 x log-likelihood:  -45.395 \n```\n\n\n:::\n\n```{.r .cell-code}\ndat4c.glmw |> confint()\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n                2.5 %   97.5 %\n(Intercept) 1.6442791 2.179941\nscale(x)    0.5972968 1.110124\n```\n\n\n:::\n\n```{.r .cell-code}\ndat4c.glmw |> performance::r2()\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n# R2 for Generalized Linear Regression\n  Nagelkerke's R2: 0.996\n```\n\n\n:::\n:::\n\n\n\n:::::::: {.callout-tip}\n\nSince this model used a log link, in order to return the estimates to\nthe scale of the response, we need to backtransform by exponentiation.\n\nImportantly, if using confidence intervals for the purpose of\ninference testsing:\n\n- if using estimates on the link (log) scale, intervals that do not include 0\n  are \"significant\"\n- if using estimates on the response scale, intervals that do not\n  include 1 are \"significant\"\n  \n::::::::\n\n**Interpretation**:\n\n- when $x=0$ (e.g. the average $x$ value since centered), $y$ is\n  expected to be exp(1.927) = \n  6.87 (the y-intercept).\n- for every one unit change in $x$ (which represents a span of approximately 34% of the \n  range of $x$ since standardised), the expected value of $y$\n  increases by exp(0.845) =\n  2.329 (the slope)\n- this is equivalent to a 132.905% \n  increase in the response per one unit change in (standardised) $x$\n- the slope (on the link scale) could be as low as \n  0.597 or\n  as high as 1.11 (95% confidence\n  interval of the slope)\n- as the above interval does not include the value of 0, the linear\n  relationship (slope) can be considered significant\n- the slope (on the response scale) could be as low as \n  1.817 or\n  as high as 3.035 (95% confidence\n  interval of the slope)\n- as the above interval does not include the value of 1, the linear\n  relationship (slope) can be considered significant\n- we would reject the null hypothesis of no relationship (p-value for\n  slope is less than 0.05)\n- 99.583% of the variance in $y$ is\n  explained by its linear relationship with $x$ (R squared value)\n\n:::::\n\n:::::::\n\n\n### Example  5 (Binary data)\n\n::::::: {.panel-tabset}\n\n#### Raw predictor\n\n::::: {.panel-tabset}\n\n##### Fit model\n\nGiven that exploratory data analysis suggested that the assumptions\nwere not likely to be met for a simple gaussian model and that this\nwas subsequently confirmed when we explored the diagnostics resulting\nfrom the OLS model of these data, we will instead entertain a\nBernoulli (Binomial with number of trials = 1) regression model. The\nmodel will be of the form:\n\n$$\n\\begin{align}\ny_i \\sim{}& Bin(\\pi, 1)\\\\\nlogit(\\frac{\\pi}{1-\\pi}) =& \\beta_0 + \\beta_1 x_i\\\\\n\\end{align}\n$$\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\ndat5.glmw <- glm(y ~ x, data = dat5, family = binomial(link = \"logit\"))\ndat5.glmw\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n\nCall:  glm(formula = y ~ x, family = binomial(link = \"logit\"), data = dat5)\n\nCoefficients:\n(Intercept)            x  \n     -5.825        1.295  \n\nDegrees of Freedom: 9 Total (i.e. Null);  8 Residual\nNull Deviance:\t    13.46 \nResidual Deviance: 5.014 \tAIC: 9.014\n```\n\n\n:::\n:::\n\n\n\nAnd to explore the diagnostics\n\n\n\n##### Performance model checking\n\n\n::: {.cell}\n\n```{.r .cell-code}\ndat5.glmw |> performance::check_model()\n```\n\n::: {.cell-output-display}\n![](30_glm_files/figure-html/glmw_validateMode5a1-1.png){width=768}\n:::\n\n```{.r .cell-code}\ndat5.glmw |> performance::check_outliers()\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nOK: No outliers detected.\n- Based on the following method and threshold: cook (0.8).\n- For variable: (Whole model)\n```\n\n\n:::\n:::\n\n\n\n**Conclusions**:\n\n- these diagnostics are broadly acceptable given the small nature of the\n  data\n\n\n##### DHARMa (simulated) residuals\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\ndat.resid <- dat5.glmw |> \n  simulateResiduals(plot = TRUE)\n```\n\n::: {.cell-output-display}\n![](30_glm_files/figure-html/glmw_validateModel5b1-1.png){width=768}\n:::\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\ndat.resid |> testDispersion()\n```\n\n::: {.cell-output-display}\n![](30_glm_files/figure-html/glmw_validateModel5b2-1.png){width=384}\n:::\n\n::: {.cell-output .cell-output-stdout}\n\n```\n\n\tDHARMa nonparametric dispersion test via sd of residuals fitted vs.\n\tsimulated\n\ndata:  simulationOutput\ndispersion = 1.3257, p-value = 0.76\nalternative hypothesis: two.sided\n```\n\n\n:::\n:::\n\n\n**Conclusions**\n\n- no obvious issues with these diagnostics\n\n##### Summarise model\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\ndat5.glmw |> summary()\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n\nCall:\nglm(formula = y ~ x, family = binomial(link = \"logit\"), data = dat5)\n\nCoefficients:\n            Estimate Std. Error z value Pr(>|z|)\n(Intercept)   -5.825      3.986  -1.461    0.144\nx              1.295      0.845   1.533    0.125\n\n(Dispersion parameter for binomial family taken to be 1)\n\n    Null deviance: 13.4602  on 9  degrees of freedom\nResidual deviance:  5.0138  on 8  degrees of freedom\nAIC: 9.0138\n\nNumber of Fisher Scoring iterations: 6\n```\n\n\n:::\n\n```{.r .cell-code}\ndat5.glmw |> confint()\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n                  2.5 %     97.5 %\n(Intercept) -19.3257223 -0.7627791\nx             0.2736857  4.1921925\n```\n\n\n:::\n\n```{.r .cell-code}\ndat5.glmw |> performance::r2()\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n# R2 for Logistic Regression\n  Tjur's R2: 0.653\n```\n\n\n:::\n:::\n\n\n\n:::::::: {.callout-tip}\n\nSince this model used a logit link ($log(\\frac{\\pi}{1-\\pi})$), in\norder to return the estimates to the scale of the response, we can\neither:\n\n- for the y-intercept:\n  - backtransform by exponentiation to odds ratio ($\\frac{\\pi}{1-\\pi}$).\n  - backtransform to probability by exponentiation of the odds ratio\n    ($\\pi$).\n- for the slopes:\n  - backtransform by exponentiation to odds ratio.\n\nImportantly, if using confidence intervals for the purpose of\ninference testsing:\n\n- if using estimates on the link (logit) scale, intervals that do not include 0\n  are \"significant\"\n- if using estimates on the response scale, intervals that do not\n  include 1 are \"significant\"\n  \n::::::::\n\n**Interpretation**:\n\n- when $x=0$:\n  - the odds of $y$ being 1 vs 0 is expected to be \n    exp(-5.825) = \n    0.003 (the y-intercept).\n  - the probability of $y$ being 1 is expected to be \n    plogis(-5.825) = \n    0.003 (the y-intercept).\n- for every one unit change in $x$, the odds of $y$\n  increases by exp(1.295) =  \n  3.653 (the slope)\n- this is equivalent to a 265.259% \n  increase in the odds of the response being 1 per one unit change in $x$\n- the slope (on the link scale) could be as low as \n  0.274 or\n  as high as 4.192 (95% confidence\n  interval of the slope)\n- as the above interval does not include the value of 0, the linear\n  relationship (slope) can be considered significant\n- the slope (on the response scale) could be as low as \n  1.315 or\n  as high as 66.168 (95% confidence\n  interval of the slope)\n- as the above interval does not include the value of 1, the linear\n  relationship (slope) can be considered significant\n- we would reject the null hypothesis of no relationship (p-value for\n  slope is less than 0.05)\n- 65.333% of the variance in $y$ is\n  explained by its linear relationship with $x$ (R squared value)\n\n\n:::::\n\n#### Centered predictor\n\n::::: {.panel-tabset}\n\n##### Fit the model\n\nGiven that exploratory data analysis suggested that the assumptions\nwere not likely to be met for a simple gaussian model and that this\nwas subsequently confirmed when we explored the diagnostics resulting\nfrom the OLS model of these data, we will instead entertain a poisson\nregression model. The model will be of the form:\n\n$$\n\\begin{align}\ny_i \\sim{}& Bin(\\pi_i, 1)\\\\\nlog(\\frac{\\pi_i}{1-\\pi_i}) =& \\beta_0 + \\beta_1 (x_i - \\bar{x})\\\\\n\\end{align}\n$$\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\ndat5b.glmw <- glm(y ~ scale(x, scale = FALSE), data = dat5, family = binomial(link = \"logit\"))\ndat5b.glmw\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n\nCall:  glm(formula = y ~ scale(x, scale = FALSE), family = binomial(link = \"logit\"), \n    data = dat5)\n\nCoefficients:\n            (Intercept)  scale(x, scale = FALSE)  \n                  1.300                    1.295  \n\nDegrees of Freedom: 9 Total (i.e. Null);  8 Residual\nNull Deviance:\t    13.46 \nResidual Deviance: 5.014 \tAIC: 9.014\n```\n\n\n:::\n:::\n\n\n\nAnd to explore the diagnostics\n\n\n\n##### Performance model checking\n\n\n::: {.cell}\n\n```{.r .cell-code}\ndat5b.glmw |> performance::check_model()\n```\n\n::: {.cell-output-display}\n![](30_glm_files/figure-html/glmw_validateMode5a1b-1.png){width=768}\n:::\n\n```{.r .cell-code}\ndat5b.glmw |> performance::check_outliers()\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nOK: No outliers detected.\n- Based on the following method and threshold: cook (0.8).\n- For variable: (Whole model)\n```\n\n\n:::\n:::\n\n\n\n**Conclusions**:\n\n- these diagnostics are broadly acceptable given the small nature of the\n  data\n\n\n##### DHARMa (simulated) residuals\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\ndat.resid <- dat5b.glmw |> \n  simulateResiduals(plot = TRUE)\n```\n\n::: {.cell-output-display}\n![](30_glm_files/figure-html/glmw_validateModel5b1b-1.png){width=768}\n:::\n:::\n\n\n\n**Conclusions**\n\n- no obvious issues with these diagnostics\n\n##### Summarise model\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\ndat5b.glmw |> summary()\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n\nCall:\nglm(formula = y ~ scale(x, scale = FALSE), family = binomial(link = \"logit\"), \n    data = dat5)\n\nCoefficients:\n                        Estimate Std. Error z value Pr(>|z|)\n(Intercept)                1.300      1.411   0.922    0.357\nscale(x, scale = FALSE)    1.295      0.845   1.533    0.125\n\n(Dispersion parameter for binomial family taken to be 1)\n\n    Null deviance: 13.4602  on 9  degrees of freedom\nResidual deviance:  5.0138  on 8  degrees of freedom\nAIC: 9.0138\n\nNumber of Fisher Scoring iterations: 6\n```\n\n\n:::\n\n```{.r .cell-code}\ndat5b.glmw |> confint()\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n                             2.5 %   97.5 %\n(Intercept)             -0.9433976 5.567602\nscale(x, scale = FALSE)  0.2736857 4.192193\n```\n\n\n:::\n\n```{.r .cell-code}\ndat5b.glmw |> performance::r2()\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n# R2 for Logistic Regression\n  Tjur's R2: 0.653\n```\n\n\n:::\n:::\n\n\n\n:::::::: {.callout-tip}\n\nSince this model used a logit link ($log(\\frac{\\pi}{1-\\pi})$), in\norder to return the estimates to the scale of the response, we can\neither:\n\n- for the y-intercept:\n  - backtransform by exponentiation to odds ratio ($\\frac{\\pi}{1-\\pi}$).\n  - backtransform to probability by exponentiation of the odds ratio\n    ($\\pi$).\n- for the slopes:\n  - backtransform by exponentiation to odds ratio.\n\nImportantly, if using confidence intervals for the purpose of\ninference testsing:\n\n- if using estimates on the link (logit) scale, intervals that do not include 0\n  are \"significant\"\n- if using estimates on the response scale, intervals that do not\n  include 1 are \"significant\"\n  \n::::::::\n\n**Interpretation**:\n\n- when $x=0$ (e.g. the average $x$ value since centered):\n  - the odds of $y$ being 1 vs 0 is expected to be \n    exp(1.3) = \n    3.67 (the y-intercept).\n  - the probability of $y$ being 1 is expected to be \n    plogis(1.3) = \n    0.786 (the y-intercept).\n- for every one unit change in $x$, the odds of $y$\n  increases by exp(1.295) = \n  3.653 (the slope)\n- this is equivalent to a 265.259% \n  increase in the odds of the response being 1 per one unit change in $x$\n- the slope (on the link scale) could be as low as \n  0.274 or\n  as high as 4.192 (95% confidence\n  interval of the slope)\n- as the above interval does not include the value of 0, the linear\n  relationship (slope) can be considered significant\n- the slope (on the response scale) could be as low as \n  1.315 or\n  as high as 66.168 (95% confidence\n  interval of the slope)\n- as the above interval does not include the value of 1, the linear\n  relationship (slope) can be considered significant\n- we would reject the null hypothesis of no relationship (p-value for\n  slope is less than 0.05)\n- 65.333% of the variance in $y$ is\n  explained by its linear relationship with $x$ (R squared value)\n\n:::::\n\n#### Standardised predictor\n\n::::: {.panel-tabset}\n\n##### Fit the model\n\nGiven that exploratory data analysis suggested that the assumptions\nwere not likely to be met for a simple gaussian model and that this\nwas subsequently confirmed when we explored the diagnostics resulting\nfrom the OLS model of these data, we will instead entertain a poisson\nregression model. The model will be of the form:\n\n$$\n\\begin{align}\ny_i \\sim{}& Bin(\\pi_i, \\phi)\\\\\nlog(\\frac{\\pi_i}{1-\\pi}) =& \\beta_0 + \\beta_1 (x_i - \\bar{x})/\\sigma_{x}\\\\\n\\end{align}\n$$\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\ndat5c.glmw <- glm(y ~ scale(x), data = dat5, family = binomial(link = \"logit\"))\ndat5c.glmw\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n\nCall:  glm(formula = y ~ scale(x), family = binomial(link = \"logit\"), \n    data = dat5)\n\nCoefficients:\n(Intercept)     scale(x)  \n      1.300        3.922  \n\nDegrees of Freedom: 9 Total (i.e. Null);  8 Residual\nNull Deviance:\t    13.46 \nResidual Deviance: 5.014 \tAIC: 9.014\n```\n\n\n:::\n:::\n\n\n\nAnd to explore the diagnostics\n\n##### Performance model checking\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\ndat5c.glmw |> performance::check_model()\n```\n\n::: {.cell-output-display}\n![](30_glm_files/figure-html/glmw_validateMode5a1c-1.png){width=768}\n:::\n\n```{.r .cell-code}\ndat5c.glmw |> performance::check_outliers()\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nOK: No outliers detected.\n- Based on the following method and threshold: cook (0.8).\n- For variable: (Whole model)\n```\n\n\n:::\n:::\n\n\n\n**Conclusions**:\n\n- these diagnostics are broadly acceptable given the small nature of the\n  data\n\n\n##### DHARMa (simulated) residuals\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\ndat.resid <- dat5c.glmw |> \n  simulateResiduals(plot = TRUE)\n```\n\n::: {.cell-output-display}\n![](30_glm_files/figure-html/glmw_validateModel5b1c-1.png){width=768}\n:::\n:::\n\n\n\n**Conclusions**\n\n- no obvious issues with these diagnostics\n\n##### Summarise model\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\ndat5c.glmw |> summary()\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n\nCall:\nglm(formula = y ~ scale(x), family = binomial(link = \"logit\"), \n    data = dat5)\n\nCoefficients:\n            Estimate Std. Error z value Pr(>|z|)\n(Intercept)    1.300      1.410   0.922    0.357\nscale(x)       3.922      2.558   1.533    0.125\n\n(Dispersion parameter for binomial family taken to be 1)\n\n    Null deviance: 13.4602  on 9  degrees of freedom\nResidual deviance:  5.0138  on 8  degrees of freedom\nAIC: 9.0138\n\nNumber of Fisher Scoring iterations: 6\n```\n\n\n:::\n\n```{.r .cell-code}\ndat5c.glmw |> confint()\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n                 2.5 %    97.5 %\n(Intercept) -0.9433976  5.567602\nscale(x)     0.8286247 12.692493\n```\n\n\n:::\n\n```{.r .cell-code}\ndat5c.glmw |> performance::r2()\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n# R2 for Logistic Regression\n  Tjur's R2: 0.653\n```\n\n\n:::\n:::\n\n\n\n:::::::: {.callout-tip}\n\nSince this model used a logit link ($log(\\frac{\\pi}{1-\\pi})$), in\norder to return the estimates to the scale of the response, we can\neither:\n\n- for the y-intercept:\n  - backtransform by exponentiation to odds ratio ($\\frac{\\pi}{1-\\pi}$).\n  - backtransform to probability by exponentiation of the odds ratio\n    ($\\pi$).\n- for the slopes:\n  - backtransform by exponentiation to odds ratio.\n\nImportantly, if using confidence intervals for the purpose of\ninference testsing:\n\n- if using estimates on the link (logit) scale, intervals that do not include 0\n  are \"significant\"\n- if using estimates on the response scale, intervals that do not\n  include 1 are \"significant\"\n  \n::::::::\n\n**Interpretation**:\n\n- when $x=0$ (e.g. the average $x$ value since centered):\n  - the odds of $y$ being 1 vs 0 is expected to be \n    exp(1.3) = \n    3.67 (the y-intercept).\n  - the probability of $y$ being 1 is expected to be \n    plogis(1.3) = \n    0.786 (the y-intercept).\n- for every one unit change in $x$ (which represents a span of approximately 34% of the \n  range of $x$ since standardised), the odds of $y$\n  increases by exp(3.922) = \n  50.508 (the slope)\n- this is equivalent to a 4950.794% \n  increase in the odds of the response being 1 per one unit change in (standardised) $x$\n- the slope (on the link scale) could be as low as \n  0.829 or\n  as high as 12.692 (95% confidence\n  interval of the slope)\n- as the above interval does not include the value of 0, the linear\n  relationship (slope) can be considered significant\n- the slope (on the response scale) could be as low as \n  2.29 or\n  as high as 3.2529677\\times 10^{5} (95% confidence\n  interval of the slope)\n- as the above interval does not include the value of 1, the linear\n  relationship (slope) can be considered significant\n- we would reject the null hypothesis of no relationship (p-value for\n  slope is less than 0.05)\n- 65.333% of the variance in $y$ is\n  explained by its linear relationship with $x$ (R squared value)\n\n:::::\n\n:::::::\n \n### Example  6 (Binomial data)\n\n::::::: {.panel-tabset}\n\n#### Raw predictor\n\n::::: {.panel-tabset}\n\n##### Fit model\n\nGiven that exploratory data analysis suggested that the assumptions\nwere not likely to be met for a simple gaussian model and that this\nwas subsequently confirmed when we explored the diagnostics resulting\nfrom the OLS model of these data, we will instead entertain a Binomial\nregression model. The model will be of the form:\n\n$$\n\\begin{align}\ny_i \\sim{}& Bin(\\pi, n)\\\\\nlogit(\\frac{\\pi}{1-\\pi}) =& \\beta_0 + \\beta_1 x_i\\\\\n\\end{align}\n$$\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\ndat6.glmw <- glm(cbind(count, total - count) ~ x, data = dat6, family = binomial(link = \"logit\"))\ndat6.glmw\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n\nCall:  glm(formula = cbind(count, total - count) ~ x, family = binomial(link = \"logit\"), \n    data = dat6)\n\nCoefficients:\n(Intercept)            x  \n    -3.3295       0.8234  \n\nDegrees of Freedom: 9 Total (i.e. Null);  8 Residual\nNull Deviance:\t    38.6 \nResidual Deviance: 9.669 \tAIC: 22.93\n```\n\n\n:::\n:::\n\n\n\nAnd to explore the diagnostics\n\n\n\n##### Performance model checking\n\n\n::: {.cell}\n\n```{.r .cell-code}\ndat6.glmw |> performance::check_model()\n```\n\n::: {.cell-output-display}\n![](30_glm_files/figure-html/glmw_validateMode6a1-1.png){width=768}\n:::\n\n```{.r .cell-code}\ndat6.glmw |> performance::check_outliers()\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nOK: No outliers detected.\n- Based on the following method and threshold: cook (0.9).\n- For variable: (Whole model)\n```\n\n\n:::\n:::\n\n\n\n**Conclusions**:\n\n- these diagnostics are broadly acceptable given the small nature of the\n  data\n\n\n##### DHARMa (simulated) residuals\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\ndat.resid <- dat6.glmw |> \n  simulateResiduals(plot = TRUE)\n```\n\n::: {.cell-output-display}\n![](30_glm_files/figure-html/glmw_validateModel6b1-1.png){width=768}\n:::\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\ndat.resid |> testDispersion()\n```\n\n::: {.cell-output-display}\n![](30_glm_files/figure-html/glmw_validateModel6b2-1.png){width=384}\n:::\n\n::: {.cell-output .cell-output-stdout}\n\n```\n\n\tDHARMa nonparametric dispersion test via sd of residuals fitted vs.\n\tsimulated\n\ndata:  simulationOutput\ndispersion = 1.0614, p-value = 0.76\nalternative hypothesis: two.sided\n```\n\n\n:::\n:::\n\n\n**Conclusions**\n\n- no obvious issues with these diagnostics\n\n##### Summarise model\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\ndat6.glmw |> summary()\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n\nCall:\nglm(formula = cbind(count, total - count) ~ x, family = binomial(link = \"logit\"), \n    data = dat6)\n\nCoefficients:\n            Estimate Std. Error z value Pr(>|z|)    \n(Intercept)  -3.3295     1.0441  -3.189 0.001429 ** \nx             0.8234     0.2246   3.667 0.000246 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n(Dispersion parameter for binomial family taken to be 1)\n\n    Null deviance: 38.5956  on 9  degrees of freedom\nResidual deviance:  9.6688  on 8  degrees of freedom\nAIC: 22.934\n\nNumber of Fisher Scoring iterations: 5\n```\n\n\n:::\n\n```{.r .cell-code}\ndat6.glmw |> confint()\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n                 2.5 %    97.5 %\n(Intercept) -5.7410373 -1.537283\nx            0.4517374  1.355764\n```\n\n\n:::\n\n```{.r .cell-code}\ndat6.glmw |> performance::r2()\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nNULL\n```\n\n\n:::\n:::\n\n\n\n:::::::: {.callout-tip}\n\nSince this model used a logit link ($log(\\frac{\\pi}{1-\\pi})$), in\norder to return the estimates to the scale of the response, we can\neither:\n\n- for the y-intercept:\n  - backtransform by exponentiation to odds ratio ($\\frac{\\pi}{1-\\pi}$).\n  - backtransform to probability by exponentiation of the odds ratio\n    ($\\pi$).\n- for the slopes:\n  - backtransform by exponentiation to odds ratio.\n\nImportantly, if using confidence intervals for the purpose of\ninference testsing:\n\n- if using estimates on the link (logit) scale, intervals that do not include 0\n  are \"significant\"\n- if using estimates on the response scale, intervals that do not\n  include 1 are \"significant\"\n  \n::::::::\n\n**Interpretation**:\n\n- when $x=0$:\n  - the odds of $y$ being 1 vs 0 is expected to be \n    exp(-3.329) = \n    0.036 (the y-intercept).\n  - the probability of $y$ being 1 is expected to be \n    plogis(-3.329) = \n    0.035 (the y-intercept).\n- for every one unit change in $x$, the odds of $y$\n  increases by exp(0.823) =  \n  2.278 (the slope)\n- this is equivalent to a 127.826% \n  increase in the odds of the response being 1 per one unit change in $x$\n- the slope (on the link scale) could be as low as \n  0.452 or\n  as high as 1.356 (95% confidence\n  interval of the slope)\n- as the above interval does not include the value of 0, the linear\n  relationship (slope) can be considered significant\n- the slope (on the response scale) could be as low as \n  1.571 or\n  as high as 3.88 (95% confidence\n  interval of the slope)\n- as the above interval does not include the value of 1, the linear\n  relationship (slope) can be considered significant\n- we would reject the null hypothesis of no relationship (p-value for\n  slope is less than 0.05)\n- % of the variance in $y$ is\n  explained by its linear relationship with $x$ (R squared value)\n\n:::::\n\n#### Centered predictor\n\n::::: {.panel-tabset}\n\n##### Fit the model\n\nGiven that exploratory data analysis suggested that the assumptions\nwere not likely to be met for a simple gaussian model and that this\nwas subsequently confirmed when we explored the diagnostics resulting\nfrom the OLS model of these data, we will instead entertain a poisson\nregression model. The model will be of the form:\n\n$$\n\\begin{align}\ny_i \\sim{}& Bin(\\pi_i, n)\\\\\nlog(\\frac{\\pi_i}{1-\\pi_i}) =& \\beta_0 + \\beta_1 (x_i - \\bar{x})\\\\\n\\end{align}\n$$\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\ndat6b.glmw <- glm(cbind(count, total - count) ~ scale(x, scale = FALSE), data = dat6, family = binomial(link = \"logit\"))\ndat6b.glmw\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n\nCall:  glm(formula = cbind(count, total - count) ~ scale(x, scale = FALSE), \n    family = binomial(link = \"logit\"), data = dat6)\n\nCoefficients:\n            (Intercept)  scale(x, scale = FALSE)  \n                 1.1993                   0.8234  \n\nDegrees of Freedom: 9 Total (i.e. Null);  8 Residual\nNull Deviance:\t    38.6 \nResidual Deviance: 9.669 \tAIC: 22.93\n```\n\n\n:::\n:::\n\n\n\nAnd to explore the diagnostics\n\n\n\n##### Performance model checking\n\n\n::: {.cell}\n\n```{.r .cell-code}\ndat6b.glmw |> performance::check_model()\n```\n\n::: {.cell-output-display}\n![](30_glm_files/figure-html/glmw_validateMode6a1b-1.png){width=768}\n:::\n\n```{.r .cell-code}\ndat6b.glmw |> performance::check_outliers()\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nOK: No outliers detected.\n- Based on the following method and threshold: cook (0.9).\n- For variable: (Whole model)\n```\n\n\n:::\n:::\n\n\n\n**Conclusions**:\n\n- these diagnostics are broadly acceptable given the small nature of the\n  data\n\n\n##### DHARMa (simulated) residuals\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\ndat.resid <- dat6b.glmw |> \n  simulateResiduals(plot = TRUE)\n```\n\n::: {.cell-output-display}\n![](30_glm_files/figure-html/glmw_validateModel6b1b-1.png){width=768}\n:::\n:::\n\n\n\n**Conclusions**\n\n- no obvious issues with these diagnostics\n\n##### Summarise model\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\ndat6b.glmw |> summary()\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n\nCall:\nglm(formula = cbind(count, total - count) ~ scale(x, scale = FALSE), \n    family = binomial(link = \"logit\"), data = dat6)\n\nCoefficients:\n                        Estimate Std. Error z value Pr(>|z|)    \n(Intercept)               1.1993     0.5016   2.391 0.016800 *  \nscale(x, scale = FALSE)   0.8234     0.2246   3.667 0.000246 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n(Dispersion parameter for binomial family taken to be 1)\n\n    Null deviance: 38.5956  on 9  degrees of freedom\nResidual deviance:  9.6688  on 8  degrees of freedom\nAIC: 22.934\n\nNumber of Fisher Scoring iterations: 5\n```\n\n\n:::\n\n```{.r .cell-code}\ndat6b.glmw |> confint()\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n                            2.5 %   97.5 %\n(Intercept)             0.3199488 2.343090\nscale(x, scale = FALSE) 0.4517374 1.355764\n```\n\n\n:::\n\n```{.r .cell-code}\ndat6b.glmw |> performance::r2()\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nNULL\n```\n\n\n:::\n:::\n\n\n\n:::::::: {.callout-tip}\n\nSince this model used a logit link ($log(\\frac{\\pi}{1-\\pi})$), in\norder to return the estimates to the scale of the response, we can\neither:\n\n- for the y-intercept:\n  - backtransform by exponentiation to odds ratio ($\\frac{\\pi}{1-\\pi}$).\n  - backtransform to probability by exponentiation of the odds ratio\n    ($\\pi$).\n- for the slopes:\n  - backtransform by exponentiation to odds ratio.\n\nImportantly, if using confidence intervals for the purpose of\ninference testsing:\n\n- if using estimates on the link (logit) scale, intervals that do not include 0\n  are \"significant\"\n- if using estimates on the response scale, intervals that do not\n  include 1 are \"significant\"\n  \n::::::::\n\n**Interpretation**:\n\n- when $x=0$ (e.g. the average $x$ value since centered):\n  - the odds of $y$ being 1 vs 0 is expected to be \n    exp(1.199) = \n    3.318 (the y-intercept).\n  - the probability of $y$ being 1 is expected to be \n    plogis(1.199) = \n    0.768 (the y-intercept).\n- for every one unit change in $x$, the odds of $y$\n  increases by exp(0.823) = \n  2.278 (the slope)\n- this is equivalent to a 127.826% \n  increase in the odds of the response being 1 per one unit change in $x$\n- the slope (on the link scale) could be as low as \n  0.452 or\n  as high as 1.356 (95% confidence\n  interval of the slope)\n- as the above interval does not include the value of 0, the linear\n  relationship (slope) can be considered significant\n- the slope (on the response scale) could be as low as \n  1.571 or\n  as high as 3.88 (95% confidence\n  interval of the slope)\n- as the above interval does not include the value of 1, the linear\n  relationship (slope) can be considered significant\n- we would reject the null hypothesis of no relationship (p-value for\n  slope is less than 0.05)\n- % of the variance in $y$ is\n  explained by its linear relationship with $x$ (R squared value)\n\n:::::\n\n#### Standardised predictor\n\n::::: {.panel-tabset}\n\n##### Fit the model\n\nGiven that exploratory data analysis suggested that the assumptions\nwere not likely to be met for a simple gaussian model and that this\nwas subsequently confirmed when we explored the diagnostics resulting\nfrom the OLS model of these data, we will instead entertain a poisson\nregression model. The model will be of the form:\n\n$$\n\\begin{align}\ny_i \\sim{}& Bin(\\pi_i, n)\\\\\nlog(\\frac{\\pi_i}{1-\\pi}) =& \\beta_0 + \\beta_1 (x_i - \\bar{x})/\\sigma_{x}\\\\\n\\end{align}\n$$\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\ndat6c.glmw <- glm(cbind(count, total - count) ~ scale(x), data = dat6, family = binomial(link = \"logit\"))\ndat6c.glmw\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n\nCall:  glm(formula = cbind(count, total - count) ~ scale(x), family = binomial(link = \"logit\"), \n    data = dat6)\n\nCoefficients:\n(Intercept)     scale(x)  \n      1.199        2.493  \n\nDegrees of Freedom: 9 Total (i.e. Null);  8 Residual\nNull Deviance:\t    38.6 \nResidual Deviance: 9.669 \tAIC: 22.93\n```\n\n\n:::\n:::\n\n\n\nAnd to explore the diagnostics\n\n##### Performance model checking\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\ndat6c.glmw |> performance::check_model()\n```\n\n::: {.cell-output-display}\n![](30_glm_files/figure-html/glmw_validateMode6a1c-1.png){width=768}\n:::\n\n```{.r .cell-code}\ndat6c.glmw |> performance::check_outliers()\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nOK: No outliers detected.\n- Based on the following method and threshold: cook (0.9).\n- For variable: (Whole model)\n```\n\n\n:::\n:::\n\n\n\n**Conclusions**:\n\n- these diagnostics are broadly acceptable given the small nature of the\n  data\n\n\n##### DHARMa (simulated) residuals\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\ndat.resid <- dat6c.glmw |> \n  simulateResiduals(plot = TRUE)\n```\n\n::: {.cell-output-display}\n![](30_glm_files/figure-html/glmw_validateModel6b1c-1.png){width=768}\n:::\n:::\n\n\n\n**Conclusions**\n\n- no obvious issues with these diagnostics\n\n##### Summarise model\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\ndat6c.glmw |> summary()\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n\nCall:\nglm(formula = cbind(count, total - count) ~ scale(x), family = binomial(link = \"logit\"), \n    data = dat6)\n\nCoefficients:\n            Estimate Std. Error z value Pr(>|z|)    \n(Intercept)   1.1993     0.5016   2.391 0.016800 *  \nscale(x)      2.4930     0.6799   3.667 0.000246 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n(Dispersion parameter for binomial family taken to be 1)\n\n    Null deviance: 38.5956  on 9  degrees of freedom\nResidual deviance:  9.6688  on 8  degrees of freedom\nAIC: 22.934\n\nNumber of Fisher Scoring iterations: 5\n```\n\n\n:::\n\n```{.r .cell-code}\ndat6c.glmw |> confint()\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n                2.5 %   97.5 %\n(Intercept) 0.3199488 2.343090\nscale(x)    1.3677029 4.104779\n```\n\n\n:::\n\n```{.r .cell-code}\ndat6c.glmw |> performance::r2()\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nNULL\n```\n\n\n:::\n:::\n\n\n\n:::::::: {.callout-tip}\n\nSince this model used a logit link ($log(\\frac{\\pi}{1-\\pi})$), in\norder to return the estimates to the scale of the response, we can\neither:\n\n- for the y-intercept:\n  - backtransform by exponentiation to odds ratio ($\\frac{\\pi}{1-\\pi}$).\n  - backtransform to probability by exponentiation of the odds ratio\n    ($\\pi$).\n- for the slopes:\n  - backtransform by exponentiation to odds ratio.\n\nImportantly, if using confidence intervals for the purpose of\ninference testsing:\n\n- if using estimates on the link (logit) scale, intervals that do not include 0\n  are \"significant\"\n- if using estimates on the response scale, intervals that do not\n  include 1 are \"significant\"\n  \n::::::::\n\n**Interpretation**:\n\n- when $x=0$ (e.g. the average $x$ value since centered):\n  - the odds of $y$ being 1 vs 0 is expected to be \n    exp(1.199) = \n    3.318 (the y-intercept).\n  - the probability of $y$ being 1 is expected to be \n    plogis(1.199) = \n    0.768 (the y-intercept).\n- for every one unit change in $x$ (which represents a span of approximately 34% of the \n  range of $x$ since standardised), the odds of $y$\n  increases by exp(2.493) =\n  12.098 (the slope)\n- this is equivalent to a 1109.753% \n  increase in the odds of the response being 1 per one unit change in (standardised) $x$\n- the slope (on the link scale) could be as low as \n  1.368 or\n  as high as 4.105 (95% confidence\n  interval of the slope)\n- as the above interval does not include the value of 0, the linear\n  relationship (slope) can be considered significant\n- the slope (on the response scale) could be as low as \n  3.926 or\n  as high as 60.629 (95% confidence\n  interval of the slope)\n- as the above interval does not include the value of 1, the linear\n  relationship (slope) can be considered significant\n- we would reject the null hypothesis of no relationship (p-value for\n  slope is less than 0.05)\n- % of the variance in $y$ is\n  explained by its linear relationship with $x$ (R squared value)\n\n:::::\n\n:::::::\n::::\n\n\n\n",
    "supporting": [],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}